<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>学习计算机视觉，你必须了解的基础概念 | CrazyJums</title><meta name="description" content="1 图像的高频和低频成分 形象一点说：亮度或灰度变化激烈的地方对应高频成分，如边缘；变化不大的地方对于低频成分，如大片色块区画个直方图，大块区域是低频，小块或离散的是高频把图像看成二维函数，变化剧烈的地方就对应高频，反之低频。举个通俗易懂的例子：一幅图象，你戴上眼镜，盯紧了一个地方看到的是高频分量摘掉眼镜，眯起眼睛，模模糊糊看到的就是低频分量。图像的高低频是对图像各个位置之间强度变化的一种度量方法"><meta name="keywords" content="basic knowledge,cv,glossary"><meta name="author" content="CrazyJums"><meta name="copyright" content="CrazyJums"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://jums.club/images/favicon_64.ico"><link rel="canonical" href="http://jums.club/cv-concept-you-must-know/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin="crossorigin"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="preconnect" href="//zz.bdstatic.com"/><meta name="msvalidate.01" content="88688A1E5B9FE1F1F5EDAA94C73CD07D"/><meta name="baidu-site-verification" content="yiOH4yHRf0eeVuko"/><meta name="360-site-verification" content="d182b3f28525f2db83acfaaf6e696dba"/><meta property="og:type" content="article"><meta property="og:title" content="学习计算机视觉，你必须了解的基础概念"><meta property="og:url" content="http://jums.club/cv-concept-you-must-know/"><meta property="og:site_name" content="CrazyJums"><meta property="og:description" content="1 图像的高频和低频成分 形象一点说：亮度或灰度变化激烈的地方对应高频成分，如边缘；变化不大的地方对于低频成分，如大片色块区画个直方图，大块区域是低频，小块或离散的是高频把图像看成二维函数，变化剧烈的地方就对应高频，反之低频。举个通俗易懂的例子：一幅图象，你戴上眼镜，盯紧了一个地方看到的是高频分量摘掉眼镜，眯起眼睛，模模糊糊看到的就是低频分量。图像的高低频是对图像各个位置之间强度变化的一种度量方法"><meta property="og:image" content="https://jums.club/images/article/cv.jpg"><meta property="article:published_time" content="2019-11-18T07:26:31.000Z"><meta property="article:modified_time" content="2021-09-22T01:48:22.857Z"><meta name="twitter:card" content="summary"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="prev" title="Markdown语法中锚点的使用方法" href="http://jums.club/archor-for-markdown/"><link rel="next" title="手把手教你玩转hexo个人博客，自定义主题，博客发布，GitHub部署" href="http://jums.club/conclusion-hexo-1/"><script async="async" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(adsbygoogle = window.adsbygoogle || []).push({
  google_ad_client: '9335780214',
  enable_page_level_ads: 'true'
});</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?109416411ccef2c884dd6e0306467b1d";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-153513094-1', 'auto');
ga('send', 'pageview');
</script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: true,
  copyright: {"languages":{"author":"Author: CrazyJums","link":"Link: ","source":"Source: CrazyJums","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: true,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: true    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><script data-ad-client="ca-pub-7924394983086399" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><meta name="generator" content="Hexo 5.4.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://jums.club/images/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">228</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">62</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/leetcode/"><i class="fa-fw fa fa-code"></i><span> LeetCode</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fa fa-comments"></i><span> Comments</span></a></div><div class="menus_item"><a class="site-page" href="/kbooks/"><i class="fa-fw fa fa-book"></i><span> Kbooks</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/media/"><i class="fa-fw fa fa-play"></i><span> Media</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-user"></i><span> About</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%9B%BE%E5%83%8F%E7%9A%84%E9%AB%98%E9%A2%91%E5%92%8C%E4%BD%8E%E9%A2%91%E6%88%90%E5%88%86"><span class="toc-number">1.</span> <span class="toc-text">1 图像的高频和低频成分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E4%BD%8E%E9%80%9A%E6%BB%A4%E6%B3%A2"><span class="toc-number">2.</span> <span class="toc-text">2 低通滤波</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-bounding-box"><span class="toc-number">3.</span> <span class="toc-text">3 bounding-box</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-R-CNN"><span class="toc-number">4.</span> <span class="toc-text">4 R-CNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-IoU"><span class="toc-number">5.</span> <span class="toc-text">5 IoU</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-%E5%8D%B7%E7%A7%AF"><span class="toc-number">6.</span> <span class="toc-text">6 卷积</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-%E6%B1%A0%E5%8C%96-%E4%B8%8B%E9%87%87%E6%A0%B7%EF%BC%88pooling%EF%BC%89"><span class="toc-number">7.</span> <span class="toc-text">7 池化&#x2F;下采样（pooling）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#7-1-General-pooling"><span class="toc-number">7.1.</span> <span class="toc-text">7.1 General pooling</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-2-Overlapping-pooling"><span class="toc-number">7.2.</span> <span class="toc-text">7.2 Overlapping pooling</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-3-Spatial-Pyramid-Pooling"><span class="toc-number">7.3.</span> <span class="toc-text">7.3 Spatial Pyramid Pooling</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-4-Rol-pooling"><span class="toc-number">7.4.</span> <span class="toc-text">7.4 Rol pooling</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-RPN%EF%BC%88Region-Proposal-Network%EF%BC%89"><span class="toc-number">8.</span> <span class="toc-text">8 RPN（Region Proposal Network）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="toc-number">9.</span> <span class="toc-text">9 梯度下降</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">10.</span> <span class="toc-text">10 损失函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">11.</span> <span class="toc-text">11 激活函数</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#11-1-sigmoid%E5%87%BD%E6%95%B0"><span class="toc-number">11.1.</span> <span class="toc-text">11.1 sigmoid函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-2-ReLU%E5%87%BD%E6%95%B0"><span class="toc-number">11.2.</span> <span class="toc-text">11.2 ReLU函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-3-LeakyReLU%E5%87%BD%E6%95%B0"><span class="toc-number">11.3.</span> <span class="toc-text">11.3 LeakyReLU函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-4-PReLU%E5%87%BD%E6%95%B0"><span class="toc-number">11.4.</span> <span class="toc-text">11.4 PReLU函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-5-ELU%E5%87%BD%E6%95%B0"><span class="toc-number">11.5.</span> <span class="toc-text">11.5 ELU函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-6-tan-h-%E5%87%BD%E6%95%B0"><span class="toc-number">11.6.</span> <span class="toc-text">11.6 tan(h)函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-7-softmax%E5%87%BD%E6%95%B0"><span class="toc-number">11.7.</span> <span class="toc-text">11.7 softmax函数</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-%E6%AE%8B%E5%B7%AE%EF%BC%88Residual%EF%BC%89"><span class="toc-number">12.</span> <span class="toc-text">12 残差（Residual）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-%E6%AE%8B%E5%B7%AE-Residual-%E5%92%8C%E6%8D%9F%E5%A4%B1-loss-%E5%87%BD%E6%95%B0%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">13.</span> <span class="toc-text">13 残差(Residual)和损失(loss)函数的区别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#14-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%EF%BC%88GAN%EF%BC%89"><span class="toc-number">14.</span> <span class="toc-text">14 生成对抗网络（GAN）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E6%9C%80%E5%90%8E"><span class="toc-number"></span> <span class="toc-text">写在最后</span></a></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://jums.club/images/article/cv.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">CrazyJums</a></span><span class="pull-right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/leetcode/"><i class="fa-fw fa fa-code"></i><span> LeetCode</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fa fa-comments"></i><span> Comments</span></a></div><div class="menus_item"><a class="site-page" href="/kbooks/"><i class="fa-fw fa fa-book"></i><span> Kbooks</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/media/"><i class="fa-fw fa fa-play"></i><span> Media</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-user"></i><span> About</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">学习计算机视觉，你必须了解的基础概念</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="Created 2019-11-18 15:26:31"><i class="far fa-calendar-alt fa-fw"></i> Created 2019-11-18</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="Updated 2021-09-22 09:48:22"><i class="fas fa-history fa-fw"></i> Updated 2021-09-22</span></time></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta__icon"></i><span>Word count:</span><span class="word-count">5k</span><span class="post-meta__separator">|</span><i class="far fa-clock fa-fw post-meta__icon"></i><span>Reading time: 16 min</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="far fa-eye fa-fw post-meta__icon"></i><span>Post View:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h4 id="1-图像的高频和低频成分"><a href="#1-图像的高频和低频成分" class="headerlink" title="1 图像的高频和低频成分"></a>1 图像的高频和低频成分</h4><blockquote>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>形象一点说：亮度或灰度变化激烈的地方对应高频成分，如边缘；变化不大的地方对于低频成分，如大片色块区画个直方图，大块区域是低频，小块或离散的是高频把图像看成二维函数，变化剧烈的地方就对应高频，反之低频。<br>举个通俗易懂的例子：<br>一幅图象，你戴上眼镜，盯紧了一个地方看到的是高频分量<br>摘掉眼镜，眯起眼睛，模模糊糊看到的就是低频分量。<br>图像的高低频是对图像各个位置之间强度变化的一种度量方法.<br>低频分量:主要对整副图像的强度的综合度量.<br>高频分量:主要是对图像边缘和轮廓的度量.<br>如果一副图像的各个位置的强度大小相等,则图像只存在低频分量,从图像的频谱图上看,只有一个主峰,且位于频率为零的位置.<br>如果一副图像的各个位置的强度变化剧烈,则图像不仅存在低频分量,同时也存在多种高频分量,从图像的频谱上看,不仅有一个主峰,同时也存在多个旁峰.<br>以上的现象可以通过对傅里叶变换的公式分析得出.<br>以下所说的积分是对x进行的.<br>exp(-jwx)的数值变化是均匀的,如果对exp(-jwx)进行积分,则积分值为零.如果对exp(-jwx)乘以一个加权函数f(x),则在对f(x)exp(-jwx)进行积分,积分值不一定为零.如果exp(-jwx)的取值为1时,则对f(x)exp(-jwx)积分,既为对f(x)积分,此时f(x)exp(-jwx)最大,既频谱中的主峰.如果f(x) 是常数则, 除w=0处f(x)exp(-jwx)的积分不为零外,在w不为零的其它处,f(x)exp(-jwx)的积分都为零.</p>
</blockquote>
<hr>
<h4 id="2-低通滤波"><a href="#2-低通滤波" class="headerlink" title="2 低通滤波"></a>2 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E4%BD%8E%E9%80%9A%E6%BB%A4%E6%B3%A2/3506429?fr=aladdin">低通滤波</a></h4><blockquote>
<p>低通滤波(Low-pass filter) 是一种过滤方式，规则为低频信号能正常通过，而超过设定临界值的高频信号则被阻隔、减弱。但是阻隔、减弱的幅度则会依据不同的频率以及不同的滤波程序（目的）而改变。它有的时候也被叫做高频去除过滤（high-cut filter）或者最高去除过滤（treble-cut filter)。低通过滤是高通过滤的对立。</p>
</blockquote>
<hr>
<h4 id="3-bounding-box"><a href="#3-bounding-box" class="headerlink" title="3 bounding-box"></a>3 <a target="_blank" rel="noopener" href="https://blog.csdn.net/love1055259415/article/details/80041936">bounding-box</a></h4><blockquote>
<p>如图所示，绿色的框为飞机的Ground Truth，红色的框是提取的Region Proposal。那么即便红色的框被分类器识别为飞机，但是由于红色的框定位不准(IoU&lt;0.5)，那么这张图相当于没有正确的检测出飞机。如果我们能对红色的框进行微调，使得经过微调后的窗口跟Ground Truth更接近，这样岂不是定位会更准确。确实，Bounding-box regression 就是用来微调这个窗口的。<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/20161020131820060.png" alt="image"></p>
</blockquote>
<hr>
<h4 id="4-R-CNN"><a href="#4-R-CNN" class="headerlink" title="4 R-CNN"></a>4 <a target="_blank" rel="noopener" href="https://blog.csdn.net/ture_dream/article/details/52896452">R-CNN</a></h4><p>R-CNN的论文原文是《<a href="https://jums.club/pdf/Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation.pdf">Rich feature hierarchies for accurate object detection and semantic segmentation</a>》全是英文，有兴趣的可以读一读<br>R-CNN是计算机视觉中目标检测算法的鼻祖，很多的目标检测算法都是基于R-CNN的改进，这里有一篇<a target="_blank" rel="noopener" href="https://blog.csdn.net/ture_dream/article/details/52896452">很好的博客</a>，介绍了R-CNN,Fast R-CNN,Faster R-CNN的一个工作原理<br><a target="_blank" rel="noopener" href="https://space.bilibili.com/209599371?from=search&seid=7888318736309109130">B站目标检测大牛</a><br><strong>关于R-CNN的一个入门视频</strong></p>
<iframe src="//player.bilibili.com/player.html?aid=24795835&cid=41764245&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="720" height="480"> </iframe>

<p><a id="R-CNN的工作原理"><strong>R-CNN的工作原理：</strong></a>   </p>
<blockquote>
<p>R-CNN利用<strong>网络</strong>将特征提取和特征分类合并到一起，大大提升了特征的提取效率。但是无论是<em>传统方式</em>还是R-CNN，<strong>目标检测和目标识别的最大区别就是需要提取候选区域</strong>（region proposals） R-CNN采用<strong>选择性搜索（selective search）</strong>算法，又称区域合并算法，selective search会将对图片暴力生成多个候选区域   </p>
</blockquote>
<p>R-CNN算法的计算过程：   </p>
<blockquote>
<ul>
<li>首先输入图像会被分为R个初始候选集，</li>
<li>然后通过贪心策略去计算相邻候选集之前的相似度，通过相似度的大小去合并候选集，直到产生目标个数的候选集,</li>
<li>候选集的相似度计算有多种方式，有颜色、纹理、而枳和吻合相似度计算。</li>
<li><strong>最后生成的L个Region Proposal与CNN相结合，这就是R-CNN名字的由来</strong>,    </li>
</ul>
</blockquote>
<p><em>R-CNN作者证明了在当前任务下SVM的分类效果要比神经网络分类器好。最后每个SNM分类器都会得到图像对于该类别的得分和置信度，置信度最高的类别为改图像区域对应的预测类别</em></p>
<p><a id="总结一下R-CNN存在的两个问题"><strong>总结一下R-CNN存在的两个问题：</strong></a></p>
<ul>
<li>R-CNN在生成了候选区域后，需要对每个区域进行统一尺寸的压缩或放大，当候选集的长与宽差别较大时强行压缩至比例为1:1时会使图像产生变形和丢失图像的原始特征</li>
<li>R-CNN生成了多个候选集后需要全部输入到CNN中，当生成了2000个候选集时，就需要对图片进行2000次单模型特征提取，这无疑是效率低下的</li>
</ul>
<p>针对上述的两个问题，Kaiming He等人提出了SSPNet（空间金字塔池化网络）来解决。<a target="_blank" rel="noopener" href="https://crazyjums.github.io/2019/11/21/SSPNet/">详细了解什么是SSPNet</a></p>
<hr>
<h4 id="5-IoU"><a href="#5-IoU" class="headerlink" title="5 IoU"></a>5 <a target="_blank" rel="noopener" href="https://blog.csdn.net/u014061630/article/details/82818112">IoU</a></h4><blockquote>
<p>IoU 的全称为交并比（Intersection over Union），通过这个名称我们大概可以猜到 IoU 的计算方法。IoU 计算的是 “预测的边框” 和 “真实的边框” 的交集和并集的比值。<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/20180922220708895.png" alt="IoU计算公式"></p>
</blockquote>
<hr>
<h4 id="6-卷积"><a href="#6-卷积" class="headerlink" title="6 卷积"></a>6 卷积</h4><p>卷积在图像识别中的概念是提取一幅图像的特征，通常对一幅图像进行卷积会有一个卷积核，该卷积核是一个正方形矩阵。一般是奇数矩阵，这样做的目的是为了卷积核总是有一个中心。大部分情况使用的3x3或者5x5等</p>
<p><a target="_blank" rel="noopener" href="https://crazyjums.github.io/2019/11/21/cnn/">详细了解什么是卷积神经网络</a></p>
<hr>
<h4 id="7-池化-下采样（pooling）"><a href="#7-池化-下采样（pooling）" class="headerlink" title="7 池化/下采样（pooling）"></a>7 池化/下采样（pooling）</h4><p>上面介绍了卷积操作，卷积的目的是提取一幅图像的特征，也就是边缘部分。但是一幅图像往往很大，有的甚至几百万的像素，每一个像素对应一个参数，那就意味着会有几百万个参数，这对于计算机的内存处理来讲是一个很大的问题。那么为了减少参数，提升计算机的运行效率，这里提出一个pooling的概念，也就是较少一部分对图像影响较小的参数，从而使得计算机的运行效率能够提升。池化操作一般在卷积之后。  </p>
<blockquote>
<p><img src= "/img/loading.gif" data-src="https://jums.club/images/article/pIYBAFreggyACO9FAABorvOb-GE402.png" alt="池化操作"><br>如上图所示，池化就是对特征图进行特征压缩，池化也叫做下采样。选择原来某个区域的max或mean代替那个区域，整体就浓缩了</p>
</blockquote>
<p>pooling有很多种，这里<a target="_blank" rel="noopener" href="https://blog.csdn.net/danieljianfeng/article/details/42433475">介绍几种</a>：   </p>
<ul>
<li>一般池化（general pooling）</li>
<li>重叠池化（OverlappingPooling）</li>
<li>空金字塔池化（Spatial Pyramid Pooling）<br>还有一些池化，这篇<a target="_blank" rel="noopener" href="https://blog.csdn.net/nwu_NBL/article/details/80901427">博客</a>有介绍</li>
</ul>
<p><strong>pooling layer视频介绍</strong></p>
<iframe src="//player.bilibili.com/player.html?aid=16022575&cid=26141211&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="720" height="480"> </iframe>

<h5 id="7-1-General-pooling"><a href="#7-1-General-pooling" class="headerlink" title="7.1 General pooling"></a>7.1 General pooling</h5><blockquote>
<p>池化作用于图像中不重合的区域（这与卷积操作不同），过程如下图<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/Pooling_schematic.gif" alt="一般池化"><br>我们定义池化窗口的大小为sizeX，即下图中红色正方形的边长，定义两个相邻池化窗口的水平位移/竖直位移为stride。一般池化由于每一池化窗口都是不重复的，所以sizeX=stride。<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/20150105213214237.png" alt="步长等于尺寸">   </p>
</blockquote>
<blockquote>
<p>最常见的池化操作为平均池化mean pooling和最大池化max pooling：   </p>
<ul>
<li>平均池化：计算图像区域的平均值作为该区域池化后的值。   </li>
<li>最大池化：选图像区域的最大值作为该区域池化后的值。</li>
</ul>
</blockquote>
<h5 id="7-2-Overlapping-pooling"><a href="#7-2-Overlapping-pooling" class="headerlink" title="7.2 Overlapping pooling"></a>7.2 Overlapping pooling</h5><blockquote>
<p>重叠池化正如其名字所说的，相邻池化窗口之间会有重叠区域，此时sizeX&gt;stride</p>
</blockquote>
<h5 id="7-3-Spatial-Pyramid-Pooling"><a href="#7-3-Spatial-Pyramid-Pooling" class="headerlink" title="7.3 Spatial Pyramid Pooling"></a>7.3 Spatial Pyramid Pooling</h5><blockquote>
<p>空间金字塔池化可以把任何尺度的图像的卷积特征转化成相同维度，这不仅可以让CNN处理任意尺度的图像，还能避免cropping和warping操作，导致一些信息的丢失，具有非常重要的意义</p>
</blockquote>
<blockquote>
<p>一般的CNN都需要输入图像的大小是固定的，这是因为全连接层的输入需要固定输入维度，但在卷积操作是没有对图像尺度有限制，所有作者提出了空间金字塔池化，先让图像进行卷积操作，然后转化成维度相同的特征输入到全连接层，这个可以把CNN扩展到任意大小的图像。<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/20150105213450046.png" alt=""><br>空间金字塔池化的思想来自于Spatial Pyramid Model，它一个pooling变成了多个scale的pooling。用不同大小池化窗口作用于卷积特征，我们可以得到1X1,2X2,4X4的池化结果，由于conv5中共有256个过滤器，所以得到1个256维的特征，4个256个特征，以及16个256维的特征，然后把这21个256维特征链接起来输入全连接层，通过这种方式把不同大小的图像转化成相同维度的特征。<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/20150105213522578.png" alt="">   </p>
</blockquote>
<h5 id="7-4-Rol-pooling"><a href="#7-4-Rol-pooling" class="headerlink" title="7.4 Rol pooling"></a>7.4 <a target="_blank" rel="noopener" href="https://blog.csdn.net/auto1993/article/details/78514071">Rol pooling</a></h5><p>Rol(Region of Interest)是图像中我们感兴趣的区域的意思，也可以理解为region proposal（候选区域）。<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/20191118150551.png" alt=""><br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/20191118150631.png" alt=""><br>ROI pooling总结：<br>（1）用于目标检测任务；<br>（2）允许我们对CNN中的feature map进行reuse；<br>（3）可以显著加速training和testing速度；<br>（4）允许end-to-end的形式训练目标检测系统。   </p>
<hr>
<h4 id="8-RPN（Region-Proposal-Network）"><a href="#8-RPN（Region-Proposal-Network）" class="headerlink" title="8 RPN（Region Proposal Network）"></a>8 <a target="_blank" rel="noopener" href="https://blog.csdn.net/ture_dream/article/details/52896452">RPN</a>（Region Proposal Network）</h4><blockquote>
<p>目前最先进的目标检测网络需要先用区域建议(region proposal)算法推测目标位置，像SPPnet[7]和Fast R-CNN[5]这些网络已经减少了检测网络的运行时间，这时计算区域建议(region proposal)就成了瓶颈问题。本文中，我们介绍一种区域建议网络（Region Proposal Network, RPN），<strong>它和检测网络共享全图的卷积特征(共享卷积核)</strong>，使得区域建议几乎不花时间。<strong>RPN是一个全卷积网络</strong>，在每个位置同时预测目标边界和objectness得分。RPN是端到端训练的，生成高质量区域建议框，用于Fast R-CNN来检测。通过一种简单的交替运行优化方法，RPN和Fast R-CNN可以在训练时共享卷积特征。对于非常深的VGG-16模型[19]，我们的检测系统在GPU上的帧率为5fps（包含所有步骤），在PASCAL VOC 2007和PASCAL VOC 2012上实现了最高的目标检测准确率（2007是73.2%mAP，2012是70.4%mAP），每个图像用了300个建议框。<a target="_blank" rel="noopener" href="https://github.com/ShaoqingRen/faster_rcnn">代码</a>已公开</p>
</blockquote>
<hr>
<h4 id="9-梯度下降"><a href="#9-梯度下降" class="headerlink" title="9 梯度下降"></a>9 <a id="梯度下降"><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/c7e642877b0e">梯度下降</a></a></h4><blockquote>
<p>百度百科解释：梯度下降是迭代法的一种,可以用于求解最小二乘问题(线性和非线性都可以)。在求解机器学习算法的模型参数，即无约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一，另一种常用的方法是最小二乘法。在求解损失函数的最小值时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数和模型参数值。反过来，如果我们需要求解损失函数的最大值，这时就需要用梯度上升法来迭代了。在机器学习中，基于基本的梯度下降法发展了两种梯度下降方法，分别为随机梯度下降法和批量梯度下降法</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://crazyjums.github.io/2019/11/21/gradient-descent">详细了解什么是梯度下降</a></p>
<hr>
<h4 id="10-损失函数"><a href="#10-损失函数" class="headerlink" title="10 损失函数"></a>10 <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_24753293/article/details/78788844">损失函数</a></h4><blockquote>
<p>损失函数（loss function）或代价函数（cost function）是将随机事件或其有关随机变量的取值映射为非负实数以表示该随机事件的“风险”或“损失”的函数。在应用中，损失函数通常作为学习准则与优化问题相联系，即通过最小化损失函数求解和评估模型。</p>
</blockquote>
<p><strong>损失函数的作用：衡量模型模型预测的好坏</strong></p>
<blockquote>
<p>比如你做一个线性回归，实际值和你的 预测值肯定会有误差，那么我们找到一个函数表达这个误差就是损失函数  </p>
</blockquote>
<p>损失函数与鲁棒性的关系：   </p>
<blockquote>
<p>损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。</p>
</blockquote>
<p>常用的损失函数：<br>(1) 0-1损失函数(0-1 lossfunction):<br>L(Y,f(X))={1,0,Y≠f(X)Y=f(X)<br>(2)平方损失函数(quadraticloss function)<br>L(Y,f(X))=(Y−f(X))2<br>(3)绝对损失函数(absoluteloss function)<br>L(Y,f(X))=|Y−f(X)|<br>(4)对数损失函数(logarithmicloss function)或对数似然损失函数(log-likelihood loss function)<br>L(Y,P(Y|X))=−logP(Y|X)</p>
<hr>
<h4 id="11-激活函数"><a href="#11-激活函数" class="headerlink" title="11 激活函数"></a>11 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/激活函数/2520792?fr=aladdin">激活函数</a></h4><blockquote>
<p>实际上．激活函数也是在模拟神经元的特点。人体的祌经元不是接收到输入就会全部输出的，是当输入达到一定的阈值后，线性或非线性的将输入转化成输出，这也就是激活函数的原理,在人工神经网络中，<a target="_blank" rel="noopener" href="https://blog.csdn.net/edogawachia/article/details/80043673">激活函数</a>就在神经元的连接形式中，以非线性的映射关系而存在，是神经网络能表达复杂非线性关系的关键所在。</p>
</blockquote>
<h5 id="11-1-sigmoid函数"><a href="#11-1-sigmoid函数" class="headerlink" title="11.1 sigmoid函数"></a>11.1 <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/506595ec4b58">sigmoid函数</a></h5><blockquote>
<p>Sigmoid函数是一个在生物学中常见的S型函数，也称为S型生长曲线。 在信息科学中，由于其单增以及反函数单增等性质，Sigmoid函数常被用作神经网络的激活函数，将变量映射到0,1之间<br>sigmoid公式如下：<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/o_191114110431111.png" alt="image"><br>sigmoid函数图像如下：<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/c9fcc3cec3fdfc03f23fbf16d73f8794a5c226dc.jpg" alt="image"></p>
</blockquote>
<p><strong>sigmoid函数的缺点：</strong>   </p>
<ul>
<li>计算量很大</li>
<li>会带来梯度（函数图像中某一点的斜率，即导数）消失的问题</li>
<li>输入的范围基本在[-6,6]之间，当输入的数的绝对值大于6时，效果和6差不多</li>
</ul>
<p>sigmoid函数的Python实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line"> </span><br><span class="line">sigmoid_inputs = np.arange(-<span class="number">10</span>,<span class="number">10</span>,<span class="number">0.1</span>)</span><br><span class="line">sigmoid_outputs = sigmoid(sigmoid_inputs)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sigmoid Function Input :: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(sigmoid_inputs))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sigmoid Function Output :: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(sigmoid_outputs))</span><br><span class="line"> </span><br><span class="line">plt.plot(sigmoid_inputs,sigmoid_outputs)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Sigmoid Inputs&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Sigmoid Outputs&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h5 id="11-2-ReLU函数"><a href="#11-2-ReLU函数" class="headerlink" title="11.2 ReLU函数"></a>11.2 <a id="ReLU函数"><a target="_blank" rel="noopener" href="https://www.cnblogs.com/adong7639/p/9213038.html">ReLU函数</a></a></h5><blockquote>
<p>ReLU函数：为了避免sigmoid函数梯度趋于０产生的梯度饱和问题，线性整流函数（Rectified Linear Unit, ReLU),被提出并在卷积神经网络中取得了不错的效果。<br>当输入取值小于0时ReLU不会被激活，特别是在后向传播计算中梯度很容易变为0，这是ReLU函数本身存在的硬饱和，又会带来梯度消失的问题。而且ReLU函数的输出值是不存在负数的，这代表了ReLU也不是以0为均值的函数<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/d788d43f8794a4c25b5e4dd902f41bd5ac6e39c6.jpg" alt="image"><br>CNN中常用。对正数原样输出，负数直接置零。在正数不饱和，在负数硬饱和。<strong>ReLU计算上比sigmoid或者tanh更省计算量</strong>，因为不用exp，因而收敛较快。但是还是非zero-centered。<br>ReLU在负数区域被kill的现象叫做dead ReLU，这样的情况下，有人通过初始化的时候用一个稍微大于零的数比如0.01来初始化神经元，从而使得ReLU更偏向于激活而不是死掉，但是这个方法是否有效有争议。</p>
</blockquote>
<p><strong>ReLU的好处：</strong>   </p>
<ul>
<li>计算量很小，吗，速度很快   </li>
<li>图像本身就没有负的像素值   </li>
<li>解决了梯度消失的问题    </li>
</ul>
<h5 id="11-3-LeakyReLU函数"><a href="#11-3-LeakyReLU函数" class="headerlink" title="11.3 LeakyReLU函数"></a>11.3 <a id="LeakyReLU函数">LeakyReLU函数</a></h5><blockquote>
<p>为了解决上述的dead ReLU现象。这里选择一个数，让负数区域不在饱和死掉。这里的斜率都是确定的。<img src= "/img/loading.gif" data-src="https://jums.club/images/article/dfbsdfgsdfg.png" alt="image"></p>
</blockquote>
<h5 id="11-4-PReLU函数"><a href="#11-4-PReLU函数" class="headerlink" title="11.4 PReLU函数"></a>11.4 <a id="PReLU函数">PReLU函数</a></h5><blockquote>
<p>PReLU(Parametric Rectified Linear Unit)顾名思义：带参数的ReLU,<a target="_blank" rel="noopener" href="https://blog.csdn.net/shuzfan/article/details/51345832#prelu%E6%BF%80%E6%B4%BB">PReLU函数</a>是为了解决ReLU的硬饱和问题产生的激活函数，在LeakyReLU函数中，斜率是固定的，这里的PRelu函数的斜率a是不固定的一个值，这个值可以在运算过程中不算学习改变原来的值。<strong>计算量不是很大，因为不用计算exp</strong><img src= "/img/loading.gif" data-src="https://jums.club/images/article/20160508143448263.png" alt="image"></p>
</blockquote>
<h5 id="11-5-ELU函数"><a href="#11-5-ELU函数" class="headerlink" title="11.5 ELU函数"></a>11.5 <a id="ELU函数">ELU函数</a></h5><blockquote>
<p>ELU函数是Sigmoid函数和ReLU函数的结合体，它的提出主要是为了解决ReLUＵ函数输入负值时陷入卡死的问题<img src= "/img/loading.gif" data-src="https://jums.club/images/article/20180422215147575.png" alt="image"><br>具有ReLU的优势，且输出均值接近零，实际上PReLU和LeakyReLU都有这一优点。有负数饱和区域，从而对噪声有一些鲁棒性。可以看做是介于ReLU和LeakyReLU之间的一个东西。当然，这个函数也需要计算exp，从而<strong>计算量上更大一些</strong>。<br>ELU的优点：<br>和PReLU一样，ELU也引入了可学习的斜率a，使得激活函数在负半段是存在输出值的。但是和PReLU不一样的是，当输入值小于０时ELU的结构为非线性单元，这使得ELU具有良好的鲁棒性和抗干扰能力，但是还是具有一定程度的软饱和性</p>
</blockquote>
<h5 id="11-6-tan-h-函数"><a href="#11-6-tan-h-函数" class="headerlink" title="11.6 tan(h)函数"></a>11.6 tan(h)函数</h5><blockquote>
<p>tanh是双曲函数中的一个，tanh()为双曲正切。在数学中，双曲正切“tanh”是由双曲正弦和双曲余弦这两种基本双曲函数推导而来。<br>tan(h)函数的公式为：<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/5366d0160924ab188eed6a943dfae6cd7a890b9d.png" alt="image"><br>tan(h)函数的图像为：<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/29381f30e924b8994bb77cac64061d950b7bf69f.png" alt="image"></p>
</blockquote>
<h5 id="11-7-softmax函数"><a href="#11-7-softmax函数" class="headerlink" title="11.7 softmax函数"></a>11.7 softmax函数</h5><blockquote>
<p>softmax逻辑回归模型是logistic回归模型在多分类问题上的推广，在多分类问题中，类标签y可以取两个以上的值。 Softmax回归模型对于诸如MNIST手写数字分类等问题是很有用的，该问题的目的是辨识10个不同的单个数字。Softmax回归是有监督的，不过后面也会介绍它与深度学习无监督学习方法的结合。<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/asdfsdaffasdf.jpg" alt="softmax function"><br>公式：<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/20191128170755.png" alt="softmax 公式"></p>
</blockquote>
<h4 id="12-残差（Residual）"><a href="#12-残差（Residual）" class="headerlink" title="12 残差（Residual）"></a>12 残差（Residual）</h4><blockquote>
<p>残差在数理统计中是指实际观察值与估计值（拟合值）之间的差。“残差”蕴含了有关模型基本假设的重要信息。如果回归模型正确的话， 我们可以将残差看作误差的观测值。</p>
</blockquote>
<p>比如：<br>y_true=10,y^=9.8,residual=y_true-y^=0.2</p>
<h4 id="13-残差-Residual-和损失-loss-函数的区别"><a href="#13-残差-Residual-和损失-loss-函数的区别" class="headerlink" title="13 残差(Residual)和损失(loss)函数的区别"></a>13 残差(Residual)和损失(loss)函数的区别</h4><p><strong>什么是残差：</strong>   </p>
<blockquote>
<p>残差在数理统计中是指实际观察值与估计值（拟合值）之间的差。“残差”蕴含了有关模型基本假设的重要信息。如果回归模型正确的话， 我们可以将残差看作误差的观测值。</p>
</blockquote>
<blockquote>
<p>比如：<br>y_true=10,y^=9.8,re</p>
<p>sidual=y_true-y^=0.2</p>
</blockquote>
<p><strong>什么是损失：</strong>   </p>
<blockquote>
<p>损失函数（loss function）或代价函数（cost function）是将随机事件或其有关随机变量的取值映射为非负实数以表示该随机事件的“风险”或“损失”的函数。在应用中，损失函数通常作为学习准则与优化问题相联系，即通过最小化损失函数求解和评估模型。</p>
</blockquote>
<h4 id="14-生成对抗网络（GAN）"><a href="#14-生成对抗网络（GAN）" class="headerlink" title="14 生成对抗网络（GAN）"></a>14 生成对抗网络（GAN）</h4><blockquote>
<p>生成式对抗网络（GAN, Generative Adversarial Networks ）是一种深度学习模型，是近年来复杂分布上无监督学习最具前景的方法之一。模型通过框架中（至少）两个模块：生成模型（Generative Model）和判别模型（Discriminative Model）的互相博弈学习产生相当好的输出。原始 GAN 理论中，并不要求 G 和 D 都是神经网络，只需要是能拟合相应生成和判别的函数即可。但实用中一般均使用深度神经网络作为 G 和 D 。一个优秀的GAN应用需要有良好的训练方法，否则可能由于神经网络模型的自由性而导致输出不理想。</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/bonelee/p/9166084.html">详细了解生成对抗网络</a></p>
<h3 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h3><p>欢迎大家关注鄙人的公众号【麦田里的守望者zhg】，让我们一起成长，谢谢。<br><img src= "/img/loading.gif" data-src="https://jums.club/images/wechataccount.jpg" alt="微信公众号"></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">CrazyJums</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://jums.club/cv-concept-you-must-know/">http://jums.club/cv-concept-you-must-know/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/basic-knowledge/">basic knowledge</a><a class="post-meta__tags" href="/tags/cv/">cv</a><a class="post-meta__tags" href="/tags/glossary/">glossary</a></div><div class="post_share"><div class="social-share" data-image="https://jums.club/images/article2/array_map_walk.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><button class="reward-button"><i class="fas fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="https://jums.club/images/wechatpay.jpg" alt="微信" onclick="window.open('https://jums.club/images/wechatpay.jpg')"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="https://jums.club/images/alipay.jpg" alt="支付宝" onclick="window.open('https://jums.club/images/alipay.jpg')"/><div class="post-qr-code__desc">支付宝</div></li></ul></div></button></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/archor-for-markdown/"><img class="prev-cover" data-src="https://jums.club/images/article/md.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Markdown语法中锚点的使用方法</div></div></a></div><div class="next-post pull-right"><a href="/conclusion-hexo-1/"><img class="next-cover" data-src="https://jums.club/images/article/hexo.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">手把手教你玩转hexo个人博客，自定义主题，博客发布，GitHub部署</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/gradient-descent/" title="关于深度学习中的梯度下降，了解一下"><img class="relatedPosts_cover" data-src="https://jums.club/images/article/1234352-6ae594f795406b8b.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2019-11-21</div><div class="relatedPosts_title">关于深度学习中的梯度下降，了解一下</div></div></a></div><div class="relatedPosts_item"><a href="/archor-for-markdown/" title="Markdown语法中锚点的使用方法"><img class="relatedPosts_cover" data-src="https://jums.club/images/article/md.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2019-11-19</div><div class="relatedPosts_title">Markdown语法中锚点的使用方法</div></div></a></div><div class="relatedPosts_item"><a href="/java-class-method/" title="java中类和函数、方法、属性，以及对象的区别"><img class="relatedPosts_cover" data-src="https://jums.club/images/article/java.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-03-30</div><div class="relatedPosts_title">java中类和函数、方法、属性，以及对象的区别</div></div></a></div><div class="relatedPosts_item"><a href="/java-interface-abstract/" title="java中的接口(interface)和抽象类(abstract)的区别"><img class="relatedPosts_cover" data-src="https://jums.club/images/article/java.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-03-30</div><div class="relatedPosts_title">java中的接口(interface)和抽象类(abstract)的区别</div></div></a></div><div class="relatedPosts_item"><a href="/redirecting-forword/" title="web开发中转发和重定向的区别"><img class="relatedPosts_cover" data-src="https://jums.club/images/article/redirecting.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-02-09</div><div class="relatedPosts_title">web开发中转发和重定向的区别</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var requestSetting = function (from,set) {
  var from = from
  var setting = set.split(',').filter(function(item){
  return from.indexOf(item) > -1
  });
  setting = setting.length == 0 ? from :setting;
  return setting
}

var guestInfo = requestSetting(['nick','mail','link'],'nick,mail,link')
var requiredFields = requestSetting(['nick','mail'],'false')

window.valine = new Valine({
  el:'#vcomment',
  appId: '2lPeEraOnOk7GF6ou1WWs6BP-gzGzoHsz',
  appKey: 'nXeW1bmcRE4TDrorjmdqj0ML',
  placeholder: 'Please leave your footprints',
  avatar: 'monsterid',
  meta: guestInfo,
  pageSize: '10',
  lang: 'en',
  recordIP: false,
  serverURLs: '',
  emojiCDN: '',
  emojiMaps: "",
  enableQQ: false,
  requiredFields: requiredFields
});</script></div></article></main><footer id="footer" style="background-image: url(https://jums.club/images/article/cv.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2022 By CrazyJums</div><div class="footer_custom_text">独立思考、不盲从、不撒谎</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font_plus" title="Increase Font Size"><i class="fas fa-plus"></i></button><button id="font_minus" title="Decrease Font Size"><i class="fas fa-minus"></i></button><button class="translate_chn_to_cht" id="translateLink" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="Setting"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="scroll_to_comment fas fa-comments"></i></a><button class="close" id="mobile-toc-button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script id="ribbon_piao" mobile="true" src="/js/third-party/piao.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="/js/search/local-search.js"></script><script>if (document.getElementsByClassName('mermaid').length) {
  loadScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js',function () {
    mermaid.initialize({
      theme: 'default',
  })
})
}</script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({{ JSON.stringify(config) }});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="{{ src }}">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>