<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><title>硕士论文笔记 | CrazyJums</title><meta name="description" content="硕士论文笔记"><meta name="keywords" content="计算机视觉,论文笔记,航拍识别"><meta name="author" content="Crazy Jums"><meta name="copyright" content="Crazy Jums"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/favicon_64.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><meta name="msvalidate.01" content="88688A1E5B9FE1F1F5EDAA94C73CD07D"><meta name="baidu-site-verification" content="yiOH4yHRf0eeVuko"><meta name="360-site-verification" content="d182b3f28525f2db83acfaaf6e696dba"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="硕士论文笔记"><meta name="twitter:description" content="硕士论文笔记"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/master.jpg"><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script></script><meta property="og:type" content="article"><meta property="og:title" content="硕士论文笔记"><meta property="og:url" content="https://jums.club/note-master-1/"><meta property="og:site_name" content="CrazyJums"><meta property="og:description" content="硕士论文笔记"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/master.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = '2'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="../css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://jums.club/note-master-1/"><link rel="prev" title="手把手教你玩转hexo个人博客，自定义主题，博客发布，GitHub部署" href="https://jums.club/conclusion-hexo-1/"><link rel="next" title="视频test" href="https://jums.club/video-1/"><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?109416411ccef2c884dd6e0306467b1d";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>!function(e,a,t,n,g,c,o){e.GoogleAnalyticsObject=g,e.ga=e.ga||function(){(e.ga.q=e.ga.q||[]).push(arguments)},e.ga.l=1*new Date,c=a.createElement(t),o=a.getElementsByTagName(t)[0],c.async=1,c.src="https://www.google-analytics.com/analytics.js",o.parentNode.insertBefore(c,o)}(window,document,"script",0,"ga"),ga("create","UA-153513094-1","auto"),ga("send","pageview")</script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"search.xml",languages:{hits_empty:"We didn't find any results for the search: ${query}"}},translate:{defaultEncoding:2,translateDelay:0,cookieDomain:"https://jums.club",msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"简"},highlight_copy:"true",highlight_lang:"true",highlight_shrink:"false",copy:{success:"Copy successfully",error:"Copy error",noSupport:"The browser does not support"},bookmark:{title:"Snackbar.bookmark.title",message_prev:"Press",message_next:"to bookmark this page"},runtime_unit:"days",copyright:{languages:{author:"Author: Crazy Jums",link:"Link: https://jums.club/note-master-1/",source:"Source: CrazyJums",info:"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},copy_copyright_js:!0,ClickShowText:{text:"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善",fontSize:"15px"},medium_zoom:"false",Snackbar:void 0}</script></head><body><div id="header"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="../index.html">CrazyJums</a></span><i class="fa fa-bars fa-fw toggle-menu pull_right close" aria-hidden="true"></i><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i> <span>Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i> <span>Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i> <span>Tags</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fa fa-commenting"></i> <span>Comments</span></a></div><div class="menus_item"><a class="site-page" href="/share/"><i class="fa-fw fa fa-gift"></i> <span>Share</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i> <span>Link</span></a></div><div class="menus_item"><a class="site-page" href="/media/"><i class="fa-fw fa fa-youtube-play"></i> <span>Media</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-user"></i> <span>About</span></a></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i> <span>Search</span></a></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lazyload avatar_img" src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/avatar.jpg" onerror='onerror=null,src="/img/friend_404.gif"'></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="../archives/"><div class="headline">Articles</div><div class="length_num">117</div></a></div></div><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="../tags/"><div class="headline">Tags</div><div class="length_num">57</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i> <span>Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i> <span>Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i> <span>Tags</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fa fa-commenting"></i> <span>Comments</span></a></div><div class="menus_item"><a class="site-page" href="/share/"><i class="fa-fw fa fa-gift"></i> <span>Share</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i> <span>Link</span></a></div><div class="menus_item"><a class="site-page" href="/media/"><i class="fa-fw fa fa-youtube-play"></i> <span>Media</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-user"></i> <span>About</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">Catalog</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#1-《智能交通图像识别系统的研究》from"><span class="toc_mobile_items-text">1.《智能交通图像识别系统的研究》from</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#1-1人工神经网络进行字符识别"><span class="toc_mobile_items-text">1.1人工神经网络进行字符识别</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#1-2图像预处理"><span class="toc_mobile_items-text">1.2图像预处理</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#1-2-1灰度图化"><span class="toc_mobile_items-text">1.2.1灰度图化</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#1-2-1-1平均法"><span class="toc_mobile_items-text">1.2.1.1平均法</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#1-2-1-2最大最小平均法"><span class="toc_mobile_items-text">1.2.1.2最大最小平均法</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#1-2-1-3加权平均法"><span class="toc_mobile_items-text">1.2.1.3加权平均法</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#1-2-1-4二值图像"><span class="toc_mobile_items-text">1.2.1.4二值图像</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#1-2-1-4反转图像"><span class="toc_mobile_items-text">1.2.1.4反转图像</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#1-2-2中值滤波"><span class="toc_mobile_items-text">1.2.2中值滤波</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#1-2-3边缘检测"><span class="toc_mobile_items-text">1.2.3边缘检测</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#1-2-3-1检测方法"><span class="toc_mobile_items-text">1.2.3.1检测方法</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#1-3车牌定位"><span class="toc_mobile_items-text">1.3车牌定位</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#1-4改进之处"><span class="toc_mobile_items-text">1.4改进之处</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#2-《基于卷积神经网络的无人机侦察图像识别》from"><span class="toc_mobile_items-text">2.《基于卷积神经网络的无人机侦察图像识别》from</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-1特征降维"><span class="toc_mobile_items-text">2.1特征降维</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-2灰度共生矩阵"><span class="toc_mobile_items-text">2.2灰度共生矩阵</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-3特征抽取"><span class="toc_mobile_items-text">2.3特征抽取</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-4激活函数"><span class="toc_mobile_items-text">2.4激活函数</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-4-1sigmoid函数"><span class="toc_mobile_items-text">2.4.1sigmoid函数</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-4-2ReLU函数"><span class="toc_mobile_items-text">2.4.2ReLU函数</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-4-3LeakyReLU函数"><span class="toc_mobile_items-text">2.4.3LeakyReLU函数</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-4-4PReLU函数"><span class="toc_mobile_items-text">2.4.4PReLU函数</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-4-5ELU函数"><span class="toc_mobile_items-text">2.4.5ELU函数</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-5卷积神经网络"><span class="toc_mobile_items-text">2.5卷积神经网络</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-5-1池化层（pooling）"><span class="toc_mobile_items-text">2.5.1池化层（pooling）</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-5-1全连接层"><span class="toc_mobile_items-text">2.5.1全连接层</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-6卷积神经网络的训练方法"><span class="toc_mobile_items-text">2.6卷积神经网络的训练方法</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-6-1最小均方误差"><span class="toc_mobile_items-text">2.6.1最小均方误差</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-6-2最小分类误差"><span class="toc_mobile_items-text">2.6.2最小分类误差</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-7基于卷积神经网络的目标检测算法"><span class="toc_mobile_items-text">2.7基于卷积神经网络的目标检测算法</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-7-1R-CNN"><span class="toc_mobile_items-text">2.7.1R-CNN</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#2-7-1-1R-CNN工作原理"><span class="toc_mobile_items-text">2.7.1.1R-CNN工作原理</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-7-2金字塔池化网络"><span class="toc_mobile_items-text">2.7.2金字塔池化网络</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-7-3Fast-R-CNN"><span class="toc_mobile_items-text">2.7.3Fast R-CNN</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-8对Faster-R-CNN目标检测算法的改进"><span class="toc_mobile_items-text">2.8对Faster R-CNN目标检测算法的改进</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-8-1RPN网络"><span class="toc_mobile_items-text">2.8.1RPN网络</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-8-2Fast-R-CNN-特征提取与-RolP"><span class="toc_mobile_items-text">2.8.2Fast R-CNN 特征提取与 RｏｌＰ</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-8-3基于Faster-R-CNN的航拍图像分析"><span class="toc_mobile_items-text">2.8.3基于Faster R-CNN的航拍图像分析</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-8-4基于改进Faster-R-CNN算法的目标检测"><span class="toc_mobile_items-text">2.8.4基于改进Faster R-CNN算法的目标检测</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-8-6RPN网络改进"><span class="toc_mobile_items-text">2.8.6RPN网络改进</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#2-8-7OHEM算法模型嵌入"><span class="toc_mobile_items-text">2.8.7OHEM算法模型嵌入</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-9本轮文的结构"><span class="toc_mobile_items-text">2.9本轮文的结构</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#2-10未来展望"><span class="toc_mobile_items-text">2.10未来展望</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#3-《智能交通图像识别系统的研究》from"><span class="toc_mobile_items-text">3.《智能交通图像识别系统的研究》from</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#3-1人工神经网络进行字符识别"><span class="toc_mobile_items-text">3.1人工神经网络进行字符识别</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#3-2图像预处理"><span class="toc_mobile_items-text">3.2图像预处理</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#3-2-1灰度图化"><span class="toc_mobile_items-text">3.2.1灰度图化</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#3-2-1-1平均法"><span class="toc_mobile_items-text">3.2.1.1平均法</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-6"><a class="toc_mobile_items-link" href="#3-2-1-2最大最小平均法"><span class="toc_mobile_items-text">3.2.1.2最大最小平均法</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#3-2-1-3加权平均法"><span class="toc_mobile_items-text">3.2.1.3加权平均法</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#3-2-1-4二值图像"><span class="toc_mobile_items-text">3.2.1.4二值图像</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#3-2-1-5反转图像"><span class="toc_mobile_items-text">3.2.1.5反转图像</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#3-2-2中值滤波"><span class="toc_mobile_items-text">3.2.2中值滤波</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#3-2-3边缘检测"><span class="toc_mobile_items-text">3.2.3边缘检测</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#3-2-3-1检测方法"><span class="toc_mobile_items-text">3.2.3.1检测方法</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#3-3车牌定位"><span class="toc_mobile_items-text">3.3车牌定位</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#3-4改进之处"><span class="toc_mobile_items-text">3.4改进之处</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#写在最后"><span class="toc_mobile_items-text">写在最后</span></a></li></ol></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-《智能交通图像识别系统的研究》from"><span class="toc-text">1.《智能交通图像识别系统的研究》from</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1人工神经网络进行字符识别"><span class="toc-text">1.1人工神经网络进行字符识别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2图像预处理"><span class="toc-text">1.2图像预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-2-1灰度图化"><span class="toc-text">1.2.1灰度图化</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-2-1-1平均法"><span class="toc-text">1.2.1.1平均法</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#1-2-1-2最大最小平均法"><span class="toc-text">1.2.1.2最大最小平均法</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#1-2-1-3加权平均法"><span class="toc-text">1.2.1.3加权平均法</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#1-2-1-4二值图像"><span class="toc-text">1.2.1.4二值图像</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#1-2-1-4反转图像"><span class="toc-text">1.2.1.4反转图像</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-2-2中值滤波"><span class="toc-text">1.2.2中值滤波</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-2-3边缘检测"><span class="toc-text">1.2.3边缘检测</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#1-2-3-1检测方法"><span class="toc-text">1.2.3.1检测方法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3车牌定位"><span class="toc-text">1.3车牌定位</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4改进之处"><span class="toc-text">1.4改进之处</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-《基于卷积神经网络的无人机侦察图像识别》from"><span class="toc-text">2.《基于卷积神经网络的无人机侦察图像识别》from</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1特征降维"><span class="toc-text">2.1特征降维</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2灰度共生矩阵"><span class="toc-text">2.2灰度共生矩阵</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3特征抽取"><span class="toc-text">2.3特征抽取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4激活函数"><span class="toc-text">2.4激活函数</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-4-1sigmoid函数"><span class="toc-text">2.4.1sigmoid函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-4-2ReLU函数"><span class="toc-text">2.4.2ReLU函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-4-3LeakyReLU函数"><span class="toc-text">2.4.3LeakyReLU函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-4-4PReLU函数"><span class="toc-text">2.4.4PReLU函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-4-5ELU函数"><span class="toc-text">2.4.5ELU函数</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-5卷积神经网络"><span class="toc-text">2.5卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-5-1池化层（pooling）"><span class="toc-text">2.5.1池化层（pooling）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-5-1全连接层"><span class="toc-text">2.5.1全连接层</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-6卷积神经网络的训练方法"><span class="toc-text">2.6卷积神经网络的训练方法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-6-1最小均方误差"><span class="toc-text">2.6.1最小均方误差</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-6-2最小分类误差"><span class="toc-text">2.6.2最小分类误差</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-7基于卷积神经网络的目标检测算法"><span class="toc-text">2.7基于卷积神经网络的目标检测算法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-7-1R-CNN"><span class="toc-text">2.7.1R-CNN</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#2-7-1-1R-CNN工作原理"><span class="toc-text">2.7.1.1R-CNN工作原理</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-7-2金字塔池化网络"><span class="toc-text">2.7.2金字塔池化网络</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-7-3Fast-R-CNN"><span class="toc-text">2.7.3Fast R-CNN</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-8对Faster-R-CNN目标检测算法的改进"><span class="toc-text">2.8对Faster R-CNN目标检测算法的改进</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-8-1RPN网络"><span class="toc-text">2.8.1RPN网络</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-8-2Fast-R-CNN-特征提取与-RolP"><span class="toc-text">2.8.2Fast R-CNN 特征提取与 RｏｌＰ</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-8-3基于Faster-R-CNN的航拍图像分析"><span class="toc-text">2.8.3基于Faster R-CNN的航拍图像分析</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-8-4基于改进Faster-R-CNN算法的目标检测"><span class="toc-text">2.8.4基于改进Faster R-CNN算法的目标检测</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-8-6RPN网络改进"><span class="toc-text">2.8.6RPN网络改进</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-8-7OHEM算法模型嵌入"><span class="toc-text">2.8.7OHEM算法模型嵌入</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-9本轮文的结构"><span class="toc-text">2.9本轮文的结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-10未来展望"><span class="toc-text">2.10未来展望</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-《智能交通图像识别系统的研究》from"><span class="toc-text">3.《智能交通图像识别系统的研究》from</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1人工神经网络进行字符识别"><span class="toc-text">3.1人工神经网络进行字符识别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2图像预处理"><span class="toc-text">3.2图像预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#3-2-1灰度图化"><span class="toc-text">3.2.1灰度图化</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#3-2-1-1平均法"><span class="toc-text">3.2.1.1平均法</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#3-2-1-2最大最小平均法"><span class="toc-text">3.2.1.2最大最小平均法</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-2-1-3加权平均法"><span class="toc-text">3.2.1.3加权平均法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-2-1-4二值图像"><span class="toc-text">3.2.1.4二值图像</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-2-1-5反转图像"><span class="toc-text">3.2.1.5反转图像</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-2中值滤波"><span class="toc-text">3.2.2中值滤波</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-3边缘检测"><span class="toc-text">3.2.3边缘检测</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#3-2-3-1检测方法"><span class="toc-text">3.2.3.1检测方法</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3车牌定位"><span class="toc-text">3.3车牌定位</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4改进之处"><span class="toc-text">3.4改进之处</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#写在最后"><span class="toc-text">写在最后</span></a></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image:url(https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/master.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">硕士论文笔记</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> Created 2019-11-18<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> Updated 2020-02-16</time><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon" aria-hidden="true"></i><span>Word count:</span> <span class="word-count">9k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon" aria-hidden="true"></i><span>Reading time: 28 min</span><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"></i> <span>Post View:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h3 id="1-《智能交通图像识别系统的研究》from"><a href="#1-《智能交通图像识别系统的研究》from" class="headerlink" title="1.《智能交通图像识别系统的研究》from"></a>1.《智能交通图像识别系统的研究》<a href="https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD9904&filename=2003041026.nh&uid=WEEvREdxOWJmbC9oM1NjYkZCbDdrNXcwaGROd1Z6Qmo3emF5S1A3SnV3QjE=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!&v=MzA1NzVUcldNMUZyQ1VSTE9lWitWdUZpSGhVN3ZCVjEyN0hiTzhIOUhPcVpFYlBJUjhlWDFMdXhZUzdEaDFUM3E=" target="_blank" rel="noopener">from</a></h3><h4 id="1-1人工神经网络进行字符识别"><a href="#1-1人工神经网络进行字符识别" class="headerlink" title="1.1人工神经网络进行字符识别"></a>1.1人工神经网络进行字符识别</h4><blockquote><p>主要有两种方法:<strong>一种方法</strong>是<strong>先对待识别字符进行特征提取</strong>,然后用所获得的特征来训练神经网络分类器。这种网络的识别效果与字符特征的提取有关,而字符的特征提取往往比较耗时。因此,字符特征的提取就成为研究的关键。文献四中使用由6个多层感知器构成的神经网络来进行车牌字符识别,在特征提取上提出二值线性变换方法以减少输入特征向量,另外改善网络结构以提高识别速度。另<strong>一种方法</strong>则充分利用神经网络的特点,直接把待处理图像输入网络,由网络自动实现特征提取直至识别。这种网络互连较多、待处理信息量大。</p></blockquote><p>神经网络在并行非线性处理及大容量计算方面存在着巨大潜力,<br>且神经元状态是二值的</p><h4 id="1-2图像预处理"><a href="#1-2图像预处理" class="headerlink" title="1.2图像预处理"></a>1.2图像预处理</h4><blockquote><p>预处理相当于对获取的原始图像数据进行整理加工、去伪存真的过程。由于原始图像信号中存在着许多噪声和畸变,一般要进行<strong>滤波、平滑、增强、复原、提取边缘、图像分割</strong>等预处理,以便提高图像质量,并<strong>为下一步特征提取提供必要的基础</strong>。</p></blockquote><p><strong>决策分类</strong><br>根据具体问题的性质,提出一个反映分类好坏的标准,从而找到最符合这一标准的分类方一法。 从数学观点来看,决策分类就是找出决策函数(边界函数)。</p><h5 id="1-2-1灰度图化"><a href="#1-2-1灰度图化" class="headerlink" title="1.2.1灰度图化"></a>1.2.1<a href="https://baike.baidu.com/item/%E7%81%B0%E5%BA%A6%E5%8C%96/3206969?fr=aladdin" target="_blank" rel="noopener">灰度图化</a></h5><blockquote><p>灰度化，在RGB模型中，如果R=G=B时，则彩色表示一种灰度颜色，其中R=G=B的值叫灰度值，因此，灰度图像每个像素只需一个字节存放灰度值（又称强度值、亮度值），灰度范围为0-255。一般有分量法<br>最大值法平均值法加权平均法四种方法对彩色图像进行灰度化。</p></blockquote><p><a href="https://blog.csdn.net/saltriver/article/details/79677116" target="_blank" rel="noopener">RGB图像如何转换成灰度图像</a></p><h6 id="1-2-1-1平均法"><a href="#1-2-1-1平均法" class="headerlink" title="1.2.1.1平均法"></a>1.2.1.1平均法</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">lenna = cv2.imread(<span class="string">"lenna.png"</span>)</span><br><span class="line">row, col, channel = lenna.shape</span><br><span class="line">lenna_gray = np.zeros((row, col))</span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> range(row):</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(col):</span><br><span class="line">        lenna_gray[r, l] = <span class="number">1</span> / <span class="number">3</span> * lenna[r, l, <span class="number">0</span>] + <span class="number">1</span> / <span class="number">3</span> * lenna[r, l, <span class="number">1</span>] + <span class="number">1</span> / <span class="number">3</span> * lenna[r, l, <span class="number">2</span>]</span><br><span class="line">cv2.imshow(<span class="string">"lenna_gray"</span>, lenna_gray.astype(<span class="string">"uint8"</span>))</span><br><span class="line">cv2.waitKey()</span><br></pre></td></tr></table></figure><h6 id="1-2-1-2最大最小平均法"><a href="#1-2-1-2最大最小平均法" class="headerlink" title="1.2.1.2最大最小平均法"></a>1.2.1.2最大最小平均法</h6><blockquote><p>取同一个像素位置的RGB中亮度最大的和最小的进行平均</p></blockquote><h6 id="1-2-1-3加权平均法"><a href="#1-2-1-3加权平均法" class="headerlink" title="1.2.1.3加权平均法"></a>1.2.1.3加权平均法</h6><blockquote><p>I(x,y) = 0.3 * I_R(x,y) +0.59 * I_G(x,y)+ 0.11 * I_B(x,y)<br>这是最流行的方法。几个加权系数0.3,0.59,0.11是根据人的亮度感知系统调节出来的参数，是个广泛使用的标准化参数。</p></blockquote><h6 id="1-2-1-4二值图像"><a href="#1-2-1-4二值图像" class="headerlink" title="1.2.1.4二值图像"></a>1.2.1.4二值图像</h6><blockquote><p>图像二值化（ Image Binarization）就是将图像上的像素点的灰度值设置为0或255，也就是将整个图像呈现出明显的黑白效果的过程。<br>在数字图像处理中，二值图像占有非常重要的地位，图像的二值化使图像中数据量大为减少，从而能凸显出目标的轮廓。</p></blockquote><h6 id="1-2-1-4反转图像"><a href="#1-2-1-4反转图像" class="headerlink" title="1.2.1.4反转图像"></a>1.2.1.4反转图像</h6><blockquote><p>反转图像也很简单：s = 255-r。反转图像特别适用于<strong>增强暗色图像中的白色或灰色</strong>细节</p></blockquote><h5 id="1-2-2中值滤波"><a href="#1-2-2中值滤波" class="headerlink" title="1.2.2中值滤波"></a>1.2.2中值滤波</h5><blockquote><p><strong>中值滤波法</strong>是一种非线性平滑技术，它将每一像素点的灰度值设置为该点某邻域窗口内的所有像素点灰度值的中值.<br>中值滤波是基于排序统计理论的一种能有效抑制噪声的非线性信号处理技术，中值滤波的基本原理是把数字图像或数字序列中一点的值用该点的一个邻域中各点值的中值代替，让周围的像素值接近的真实值，从而消除孤立的噪声点。方法是用某种结构的二维滑动模板，将板内像素按照像素值的大小进行排序，生成单调上升（或下降）的为二维数据序列。二维中值滤波输出为g（x,y）=med{f(x-k,y-l),(k,l∈W)} ，其中，f(x,y)，g(x,y)分别为原始图像和处理后图像。W为二维模板，通常为3<em>3，5</em>5区域，也可以是不同的的形状，如线状，圆形，十字形，圆环形等。</p></blockquote><p><strong>中值滤波对于消除孤立点和线段的干扰十分有用,特别是对于二进噪声尤为有效,对于消除高斯噪声则效果不佳</strong></p><h5 id="1-2-3边缘检测"><a href="#1-2-3边缘检测" class="headerlink" title="1.2.3边缘检测"></a>1.2.3<a href="https://blog.csdn.net/tercel_zhang/article/details/79538317" target="_blank" rel="noopener">边缘检测</a></h5><blockquote><p>边缘检测是图像处理和计算机视觉中的基本问题，边缘检测的目的是标识数字图像中亮度变化明显的点。图像属性中的显著变化通常反映了属性的重要事件和变化。 这些包括（i）深度上的不连续、（ii）表面方向不连续、（iii）物质属性变化和（iv）场景照明变化。 边缘检测是图像处理和计算机视觉中，尤其是特征提取中的一个研究领域。</p></blockquote><h6 id="1-2-3-1检测方法"><a href="#1-2-3-1检测方法" class="headerlink" title="1.2.3.1检测方法"></a>1.2.3.1检测方法</h6><p>有许多用于边缘检测的方法, 他们大致可分为两类：<strong>**基于搜索</strong>和基于<strong>零交叉</strong>。<br>基于搜索的边缘检测方法首先计算边缘强度， 通常用一阶导数表示， 例如梯度模，然后，用计算估计边缘的局部方向， 通常采用梯度的方向，并利用此方向找到局部梯度模的最大值。<br>基于零交叉的方法找到由图像得到的二阶导数的零交叉点来定位边缘。 通常用拉普拉斯算子或非线性微分方程的零交叉点。<br>滤波做为边缘检测的预处理通常是必要的，通常采用高斯滤波。<br>已发表的边缘检测方法应用计算边界强度的度量，这与平滑滤波有本质的不同。 正如许多边缘检测方法依赖于图像梯度的计算，他们用不同种类的滤波器来估计x-方向和y-方向的梯度。</p><h4 id="1-3车牌定位"><a href="#1-3车牌定位" class="headerlink" title="1.3车牌定位"></a>1.3车牌定位</h4><blockquote><p>车牌定位的主要方法可分为五种!:①直线边缘检测;②基于域值迭代的方法;③基于神经网络的车牌定位方法;④基于灰度的检测方法;均基于彩色图像的车牌分割方`法。</p></blockquote><p>利用BP神经网络在灰度图像中提取车牌。具体步骤为:先收集一定数量的车牌样本,用BP算法对其进行训练,达到一定正确率后,训练结束,得到一个对牌照敏感的神经网络,提取牌照时,对输入图像进行预处理,然后利用训练出的神经网络来搜索车牌。</p><h4 id="1-4改进之处"><a href="#1-4改进之处" class="headerlink" title="1.4改进之处"></a>1.4改进之处</h4><p>本轮文提出的有待改进的地方：</p><ul><li>目前的车牌号码自动识别系统只能处理单个车牌的汽车图像,对于一幅图像中多个车牌的识别则无能为力,</li><li>如何消除外界因素的干扰仍然是闯红灯系统需要解决的一个问题。</li></ul><h3 id="2-《基于卷积神经网络的无人机侦察图像识别》from"><a href="#2-《基于卷积神经网络的无人机侦察图像识别》from" class="headerlink" title="2.《基于卷积神经网络的无人机侦察图像识别》from"></a>2.《基于卷积神经网络的无人机侦察图像识别》<a href="https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201902&filename=1019042269.nh&v=MjUxODFyQ1VSTE9lWnVkdEZ5bmdVYnZLVkYyNkY3TzhITlBLcHBFYlBJUjhlWDFMdXhZUzdEaDFUM3FUcldNMUY=" target="_blank" rel="noopener">from</a></h3><h4 id="2-1特征降维"><a href="#2-1特征降维" class="headerlink" title="2.1特征降维"></a>2.1特征降维</h4><blockquote><p><a href="https://blog.csdn.net/qq_41455420/article/details/79859622" target="_blank" rel="noopener">特征降维</a>，有时候也称之为特征抽取（用于降维的特征选择方法）或数据压缩，因为现实生活中产生的数据是越来越多，数据压缩技术可以帮助我们对数据进行存储和分析。<br>特征降维是无监督学习的另一个应用，目的有 2：（1）我们会经常在实际项目中遭遇特征维度非常之高的训练样本，而往往又无法借助自己的领域知识人工构建有效特征；（2）在数据表现方面，我们无法用肉眼观测超过三个维度的特征。因此，特征降维不仅仅重构了有效的低纬度特征，同时也为数据展现提供了可能。在特征降维技术中 PCA 主成分分析是最为经典和实用的特征降维技术，在图像识别方面表现的也很突出。</p></blockquote><h4 id="2-2灰度共生矩阵"><a href="#2-2灰度共生矩阵" class="headerlink" title="2.2灰度共生矩阵"></a>2.2灰度共生矩阵</h4><blockquote><p><a href="https://baike.baidu.com/item/%E7%81%B0%E5%BA%A6%E5%85%B1%E7%94%9F%E7%9F%A9%E9%98%B5/1498946?fr=aladdin" target="_blank" rel="noopener">灰度共生矩阵</a>，指的是一种通过研究灰度的空间相关特性来描述纹理的常用方法。 1973年Harali width=”480” height=”720” 等人提出了用灰度共生矩阵来描述纹理特征。<br>由于纹理是由灰度分布在空间位置上反复出现而形成的，因而在图像空间中相隔某距离的两像素之间会存在一定的灰度关系，即图像中灰度的空间相关特性。</p></blockquote><h4 id="2-3特征抽取"><a href="#2-3特征抽取" class="headerlink" title="2.3特征抽取"></a>2.3特征抽取</h4><blockquote><p>特征抽取是将已有的特征变换成新的特征子集的方式，特征变换的方式多种多样，其中线性组合方式最受欢迎。线性组合不仅计算简单，并且解释性强，比如说主成分分析PCA。PCA通过线性变换的方式，将高维的特征映射到了低维空间。特征通过PCA降维后，特征子集可以一定程度的表示原始特征集［1４］，但是特征子集在用于特征分类里效果不一定最好，另一种更好的降维方法是线性判别分析(LDA)。</p></blockquote><h4 id="2-4激活函数"><a href="#2-4激活函数" class="headerlink" title="2.4激活函数"></a>2.4<a href="https://baike.baidu.com/item/激活函数/2520792?fr=aladdin" target="_blank" rel="noopener">激活函数</a></h4><blockquote><p>实际上．激活函数也是在模拟神经元的特点。人体的祌经元不是接收到输入就会全部输出的，是当输入达到一定的阈值后，线性或非线性的将输入转化成输出，这也就是激活函数的原理,在人工神经网络中，<a href="https://blog.csdn.net/edogawachia/article/details/80043673" target="_blank" rel="noopener">激活函数</a>就在神经元的连接形式中，以非线性的映射关系而存在，是神经网络能表达复杂非线性关系的关键所在。</p></blockquote><h5 id="2-4-1sigmoid函数"><a href="#2-4-1sigmoid函数" class="headerlink" title="2.4.1sigmoid函数"></a>2.4.1<a href="https://www.jianshu.com/p/506595ec4b58" target="_blank" rel="noopener">sigmoid函数</a></h5><blockquote><p>Sigmoid函数是一个在生物学中常见的S型函数，也称为S型生长曲线。 在信息科学中，由于其单增以及反函数单增等性质，Sigmoid函数常被用作神经网络的激活函数，将变量映射到0,1之间<br>sigmoid公式如下：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/o_191114110431111.png" class="lazyload"><br>sigmoid函数图像如下：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/c9fcc3cec3fdfc03f23fbf16d73f8794a5c226dc.png" class="lazyload"></p></blockquote><p>sigmoid函数的Python实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line"> </span><br><span class="line">sigmoid_inputs = np.arange(<span class="number">-10</span>,<span class="number">10</span>,<span class="number">0.1</span>)</span><br><span class="line">sigmoid_outputs = sigmoid(sigmoid_inputs)</span><br><span class="line">print(<span class="string">"Sigmoid Function Input :: &#123;&#125;"</span>.format(sigmoid_inputs))</span><br><span class="line">print(<span class="string">"Sigmoid Function Output :: &#123;&#125;"</span>.format(sigmoid_outputs))</span><br><span class="line"> </span><br><span class="line">plt.plot(sigmoid_inputs,sigmoid_outputs)</span><br><span class="line">plt.xlabel(<span class="string">"Sigmoid Inputs"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Sigmoid Outputs"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h5 id="2-4-2ReLU函数"><a href="#2-4-2ReLU函数" class="headerlink" title="2.4.2ReLU函数"></a>2.4.2<a href="https://www.cnblogs.com/adong7639/p/9213038.html" target="_blank" rel="noopener">ReLU函数</a></h5><blockquote><p>ReLU函数：为了避免sigmoid函数梯度趋于0产生的梯度饱和问题，线性整流函数（Rectified Linear Unit, ReLU),被提出并在卷积神经网络中取得了不错的效果。<br>当输入取值小于0时ReLU不会被激活，特别是在后向传播计算中梯度很容易变为0，这是ReLU函数本身存在的硬饱和，又会带来梯度消失的问题。而且ReLU函数的输出值是不存在负数的，这代表了ReLU也不是以0为均值的函数<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/d788d43f8794a4c25b5e4dd902f41bd5ac6e39c6.png" class="lazyload"><br>CNN中常用。对正数原样输出，负数直接置零。在正数不饱和，在负数硬饱和。<strong>ReLU计算上比sigmoid或者tanh更省计算量</strong>，因为不用exp，因而收敛较快。但是还是非zero-centered。<br>ReLU在负数区域被kill的现象叫做dead ReLU，这样的情况下，有人通过初始化的时候用一个稍微大于零的数比如0.01来初始化神经元，从而使得ReLU更偏向于激活而不是死掉，但是这个方法是否有效有争议。</p></blockquote><h5 id="2-4-3LeakyReLU函数"><a href="#2-4-3LeakyReLU函数" class="headerlink" title="2.4.3LeakyReLU函数"></a>2.4.3LeakyReLU函数</h5><blockquote><p>为了解决上述的dead ReLU现象。这里选择一个数，让负数区域不在饱和死掉。这里的斜率都是确定的。<img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20180422215128864.png" class="lazyload"></p></blockquote><h5 id="2-4-4PReLU函数"><a href="#2-4-4PReLU函数" class="headerlink" title="2.4.4PReLU函数"></a>2.4.4PReLU函数</h5><blockquote><p>PReLU(Parametric Rectified Linear Unit)顾名思义：带参数的ReLU,<a href="https://blog.csdn.net/shuzfan/article/details/51345832#prelu%E6%BF%80%E6%B4%BB" target="_blank" rel="noopener">PReLU函数</a>是为了解决ReLU的硬饱和问题产生的激活函数，在LeakyReLU函数中，斜率是固定的，这里的PRelu函数的斜率a是不固定的一个值，这个值可以在运算过程中不算学习改变原来的值。<strong>计算量不是很大，因为不用计算exp</strong><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20160508143448263.jpg" class="lazyload"></p></blockquote><h5 id="2-4-5ELU函数"><a href="#2-4-5ELU函数" class="headerlink" title="2.4.5ELU函数"></a>2.4.5ELU函数</h5><blockquote><p>ELU函数是Sigmoid函数和ReLU函数的结合体，它的提出主要是为了解决ReLUＵ函数输入负值时陷入卡死的问题<img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20180422215147575.png" class="lazyload"><br>具有ReLU的优势，且输出均值接近零，实际上PReLU和LeakyReLU都有这一优点。有负数饱和区域，从而对噪声有一些鲁棒性。可以看做是介于ReLU和LeakyReLU之间的一个东西。当然，这个函数也需要计算exp，从而<strong>计算量上更大一些</strong>。<br>ELU的优点：<br>和PReLU一样，ELU也引入了可学习的斜率a，使得激活函数在负半段是存在输出值的。但是和PReLU不一样的是，当输入值小于0时ELU的结构为非线性单元，这使得ELU具有良好的鲁棒性和抗干扰能力，但是还是具有一定程度的软饱和性</p></blockquote><h4 id="2-5卷积神经网络"><a href="#2-5卷积神经网络" class="headerlink" title="2.5卷积神经网络"></a>2.5卷积神经网络</h4><blockquote><p><a href="https://blog.csdn.net/weixin_41417982/article/details/81412076" target="_blank" rel="noopener">一篇好的介绍卷积神经网络的博客</a></p></blockquote><h5 id="2-5-1池化层（pooling）"><a href="#2-5-1池化层（pooling）" class="headerlink" title="2.5.1池化层（pooling）"></a>2.5.1池化层（pooling）</h5><blockquote><p>当p=1时池化层所采用的方式是均值池化，而p=∞池化层则采用了最大池化操作。池化层和卷积层一样，也会通过非线性的激活函数来连接池化单元。按模型的泛化能力来看，随机池化的效果要好于最大池化和均值池化，其中均值池化的泛化能力最差<br><strong>池化的目的：</strong><br>最直接的目的，就是降低了下一层待处理的数据量。比如说，当卷积层的输出大小是32×32时，如果池化层过滤器的大小为2×2时，那么经过池化层处理后，输出数据的大小为16×16，也就是说现有的数据量一下子减少到池化前的1/4。当池化层最直接的目的达到了，那么它的间接目的也达到了：减少了参数数量，从而可以预防网络过拟合。</p></blockquote><h5 id="2-5-1全连接层"><a href="#2-5-1全连接层" class="headerlink" title="2.5.1全连接层"></a>2.5.1全连接层</h5><blockquote><p><a href="https://baike.baidu.com/item/%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82/22689531?fr=aladdin" target="_blank" rel="noopener"><strong>全连接层</strong></a>在卷积层和池化层之后，全连接层的神经元与所有输入神经元全部相连，这和多层感知机的结构是一样的。通常情况下卷积神经网络会有一到多个全连接层，他们每层之间也是全部相连，直到最后一层全连接层和输出层连接。卷积祌经网络的卷积层和池化层会提取图像的局部信息或区域信息，而全连接层会破坏原始数据的空间结构性，所以CNN采用了卷积池化在前，全连接在后的网络结构。利用全连接层将卷积和池化得到的高维局部特征整合，生成出可以提供给输出层的分类特征，所以全连接层和输出层的组合可以看做是CNN的分类器。<br><strong>全连接层概念：</strong><br>全连接层的每一个结点都与上一层的所有结点相连，用来把前边提取到的特征综合起来。由于其全相连的特性，一般全连接层的参数也是最多的。例如在<a href="https://www.cnblogs.com/lfri/p/10493408.html" target="_blank" rel="noopener">VGG16</a>中，第一个全连接层FC1有4096个节点，上一层POOL2是7<em>7</em>512 = 25088个节点，则该传输需要4096*25088个权值，需要耗很大的内存。</p></blockquote><h4 id="2-6卷积神经网络的训练方法"><a href="#2-6卷积神经网络的训练方法" class="headerlink" title="2.6卷积神经网络的训练方法"></a>2.6卷积神经网络的训练方法</h4><blockquote><p>CNN的训练方法是通过前向传播计算出的样本值与样本的真实比较并计算出损失，再通过反向传播算法调整网络参数结构以最小化损失的有监督学习方法。CNN的优势在于，不需要用无监督学习的方式对网络进行初始化，直接进行有监督学习即可，因为CNN会在训练之前将整体的网络参数通过小随机数初始化。但是通常情况下为了减少网络的学习时间，会将CNN的网络结构按照当前的任务环境或者利用之前相同网络的模型的参数进行初始化。<br>所以CNN的训练分为前向传播和反向传播两个阶段，前向传播在上文的网络结构介绍中己经详细说明，输入层到卷积层的传递、卷积核卷积操作、激活函数计算值、池化操作和全连接计算等等都是属于前向传播。他们通过网络结构的参数将输入值计算为预测值，再将预测值交给BP算法去进行反向传播更新网络结构参数。反向传播算法是经典卷积祌经网络训练方式的核心，在反向传播阶段中，BP算法会与基于梯度的最优化算法相结合。卷积神经网络的误差或者损失会传递到网络各层，在每层网络通过计算梯度的方式迭代更新网络参数并逐层链式计算。<br>当反向传递到输入层时，才会重新开始前向传播计算，直到网络收敛或者达到了迭代轮数。</p></blockquote><h5 id="2-6-1最小均方误差"><a href="#2-6-1最小均方误差" class="headerlink" title="2.6.1最小均方误差"></a>2.6.1最小均方误差</h5><blockquote><p>最小均方差是损失函数的常见形式，在浅层网络中运用较多，能有效地衡量预测值和实际值之间的误差。均方差的计算方式简单，也容易让人理解，所以在较多模型中作为损失函数的一种简单形式</p></blockquote><h5 id="2-6-2最小分类误差"><a href="#2-6-2最小分类误差" class="headerlink" title="2.6.2最小分类误差"></a>2.6.2最小分类误差</h5><blockquote></blockquote><h4 id="2-7基于卷积神经网络的目标检测算法"><a href="#2-7基于卷积神经网络的目标检测算法" class="headerlink" title="2.7基于卷积神经网络的目标检测算法"></a>2.7基于卷积神经网络的目标检测算法</h4><blockquote><p>卷积神经网络对于图像特征的提取能力远远超过人为设计的目标特征提取，这是近年来卷积神经网络在图像领域飞速发展的关键</p></blockquote><h5 id="2-7-1R-CNN"><a href="#2-7-1R-CNN" class="headerlink" title="2.7.1R-CNN"></a>2.7.1R-CNN</h5><blockquote><p><a href="https://www.jianshu.com/p/381ffa6e525a" target="_blank" rel="noopener">一篇好的解析R-CNN的博客</a><br><a href="https://baike.baidu.com/item/AlexNet/22689612?fr=aladdin" target="_blank" rel="noopener">关于AlexNet</a><br>R-CNN网络于2014被Girshi width=”480” height=”720” 等人在论文中被提出，R-CNN的出现标志了目标检测任务从传统方式过渡到了深度学习阶段。<strong>在此之前的十多年内工业级的目标检测几乎都是采用了人工提取图像特征算子例如HOG和SIFT，再将特征输入到分类器进行识别的方式。传统的方式尽管在许多领域取得了不错的效果，但是很难有进一步的提升</strong>。当任务的场景变换时，又不得不去挖掘和发现一些新的特征，目标检测的相关研究进展十分缓慢。R-CNN在VOC2012上直接超越了之前传统方式检测识别最好结果的30%，这代表了CNN从目标识别到目标检测的领域跨越。</p></blockquote><h6 id="2-7-1-1R-CNN工作原理"><a href="#2-7-1-1R-CNN工作原理" class="headerlink" title="2.7.1.1R-CNN工作原理"></a>2.7.1.1R-CNN工作原理</h6><blockquote><p>R-CNN利用网络将特征提取和特征分类合并到一起，大大提升了特征的提取效率。但是无论是传统方式还是R-CNN，目标检测和目标识别的最大区别就是需要提取候选区域（region proposals）<br>R-CNN采用选择性搜索（selective search）算法，又称区域合并算法，selective search会将对图片暴力生成多个候选区域<br>R-CNN算法的计算过程：<br>首先输入图像会被分为R个初始候选集，然后通过贪心策略去计算相邻候选集之前的相似度，通过相似度的大小去合并候选集，直到产生目标个数的候选集。候选集的相似度计算有多种方式，有颜色、纹理、而枳和吻合相似度计算。最后生成的L个Region Proposal与CNN相结合，这就是R-CNN名字的由来。<br>R-CNN作者证明了在当前任务下SVM的分类效果要比神经网络分类器好。最后每个SNM分类器都会得到图像对于该类别的得分和置信度，置信度最高的类别为改图像区域对应的预测类别。</p></blockquote><h5 id="2-7-2金字塔池化网络"><a href="#2-7-2金字塔池化网络" class="headerlink" title="2.7.2金字塔池化网络"></a>2.7.2金字塔池化网络</h5><blockquote><p><a href="https://blog.csdn.net/wsp_1138886114/article/details/81778202" target="_blank" rel="noopener"><strong>金字塔池化网络</strong></a>(Spatial Pyramid Pooling Network)是为了解决R-CNN遗留问题诞生出来的网络模型。回顾一下R-CNN网络，首先R-CNN在生成了候选区域后，需要对每个区域进行统一尺寸的压缩或放大，当候选集的长与宽差别较大时强行压缩至比例为1会使图像产生变形和丢失图像的原始特征，SPPNet提出了…种解决方案可以不用压缩图像候选集而直接做为网络输入。另 外一点是R-CNN生成了多个候选集后需要全部输入到CNN中，当生成了2000个候选集时，就需要对图片进行2000次单模型特征提取，这无疑是效率低下的，同样SPPNet也完美解决了这个问题<br><strong>SPPNet的解决方案：</strong></p><ul><li>SPPNet网络结构图如下所示，在输入时直接输入整张图像，只需要对整张图像做一次卷积操作，同时会生成整张图像的候选集特征映射(Reature Map)，这样候选集对应的特征阁可以直接传递到下－层，这样…来对图像进行2000次的计算就变成了1次，大大增加了网络的效率。</li><li>SPPNet中另一关键模块就是金字塔池化层（Spatial Pyramid Pooling Layer），这一层的设计思路是通过池化操作将任意尺寸的输入都转换成固定大小输出，因为在池化层中只要池化的核结构不变，输入的维度就不会变化。Kaiming He等人正是利用了池化输出固定的原理避免了原始R-CNN模型中需要缩放图片候选集的操作</li></ul><p><strong>SPPNet在R-CNN拥有的区域提取、卷积层、池化层、全连接层、SVM分 类器和Bounding-Box回归网络结构基础上，加入了候选集特征图映射和SPP Pooling层。将R-CNN网络的预测速度提升了数十倍，极大地优化了网络的计算 法复杂度</strong><br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20180817153030153.png" class="lazyload"></p></blockquote><h5 id="2-7-3Fast-R-CNN"><a href="#2-7-3Fast-R-CNN" class="headerlink" title="2.7.3Fast R-CNN"></a>2.7.3Fast R-CNN</h5><blockquote><p>虽然SPPNet网路对R-CNN进行了改进，且效率有提升，但是R-CNN和SPPNet同时还是存在一些缺陷：==<em>网络模型分开训练会产生大量的中间计算量和缓存特征，同时各个模型的独立加大了在线训练的难度</em>==。针对R-CNN和SPPNet两个算法的共同缺陷，Girshi width=”480” height=”720” 提出的Fast R-CNN算法对上述缺陷进行了一些改进。<br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/o_1911140113383940902-7569280b566d0e58.png" class="lazyload"><br>上图是Fast R-CNN的结构图，相比于R-CNN，Fast R-CNN有如下几点改进之处：</p><ul><li>加入了Feature Map，在这里Fast R-CNN和SPPNet的思路是一样的，利用候选集和特征图的映 射来对图像只做一次卷积就能得到所有候选集的特征图。</li><li>卷积后连接Rol Pooling Layer,Fast R-CNN借鉴了SPPNet的池化固定输出维度的思路，是SSP Pooling Layer的精简版，同样也不需要对候选集的尺寸进行缩放。</li><li>分类器和Bounding-Box Regression合并为Multi-Task结构。这是Fast R-CNN相比于SPPNet和R-CNN模型独立的重要改进，Fast R-CNN将<a href="https://baike.baidu.com/item/softmax%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/22689563?fr=aladdin" target="_blank" rel="noopener">Softmax</a>作为网络的分类器，并将全连接输出的一部分输入到了Bounding-Box Regression中。不用像R-CNN一样将CNN、SVM分类器和Bounding-Box Regression中分开成独立的三部分，模型的在线预测成为了可能。</li></ul></blockquote><blockquote><p>++在R-CNN中全连接层的计算特别耗时，Fast R-CNN对全连接层采用了SVD分解，全连接层拆分为两个简单公式计算，加快了计算速度。++</p></blockquote><blockquote><p>综上所述，Fast R-CNN在结合SPPNet的思想下针对R-CNN<strong>候选集统一尺度</strong>、<strong>候选集依次卷积</strong>和<strong>模型结构独立</strong>等问题下提出了诸多改进方式，并沿用了R-CNN的大部分结构。<strong>Fast R-CNN仅在运算速度上超越了R-CNN</strong>，模型<strong>的预测效果</strong>也得到了<strong>不少的提升</strong>。但是Fast R-CNN还是保留了一些<strong>缺陷</strong>，在<a href="https://blog.csdn.net/liuxiaoheng1992/article/details/81843363" target="_blank" rel="noopener"><strong>Faster R-CNN</strong></a>中针对在这些问题得到了改善，为了解决这一问题，Faster R-CNN于2016年被提出，通过引入RPN模块快速完成了proposal的生成</p></blockquote><blockquote><p><strong>注意：</strong>Fast R-CNN在对原始图像卷积后，会串行的对原图进行候选集提取并映射，到特征图上生成多个大小不同的特征图候选集，而Faster R-CNN在卷积之后特征图会并行的进入两个通道，一个是Fast R-CNN的Rol Pooling层，另一个就是Faster R-CNN中引入的RPN结构，所以Faster R-CNN可以看作是RPN和Fast R-CNN的组合模式</p></blockquote><blockquote><p><strong>softmax逻辑回归函数：</strong><br><a href="https://baike.baidu.com/item/softmax%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/22689563?fr=aladdin" target="_blank" rel="noopener">Softmax</a>逻辑回归模型是logistic回归模型在多分类问题上的推广，在多分类问题中，类标签y可以取两个以上的值。 Softmax回归模型对于诸如MNIST手写数字分类等问题是很有用的，该问题的目的是辨识10个不同的单个数字。Softmax回归是有监督的，不过后面也会介绍它与深度学习无监督学习方法的结合。<br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/d62a6059252dd42af3835f580f3b5bb5c8eab8bf.jpg" class="lazyload"></p></blockquote><h4 id="2-8对Faster-R-CNN目标检测算法的改进"><a href="#2-8对Faster-R-CNN目标检测算法的改进" class="headerlink" title="2.8对Faster R-CNN目标检测算法的改进"></a>2.8对Faster R-CNN目标检测算法的改进</h4><h5 id="2-8-1RPN网络"><a href="#2-8-1RPN网络" class="headerlink" title="2.8.1RPN网络"></a>2.8.1<a href="https://blog.csdn.net/qq_36269513/article/details/80421990" target="_blank" rel="noopener">RPN网络</a></h5><blockquote><p>区域提名网络（RegionProposalNetworks，RPN）是Faster R-CNN中的重要 结构，其主要功能是生成带有坐标的感兴趣区域框，和R－CNN或FastR－CNN中 候选集生成算法的作用是一样的。<br><strong>视频介绍RPN</strong></p></blockquote><iframe src="//player.bilibili.com/player.html?aid=29987414&cid=52249531&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen width="720" height="480"></iframe><h5 id="2-8-2Fast-R-CNN-特征提取与-RolP"><a href="#2-8-2Fast-R-CNN-特征提取与-RolP" class="headerlink" title="2.8.2Fast R-CNN 特征提取与 RｏｌＰ"></a>2.8.2Fast R-CNN 特征提取与 RｏｌＰ</h5><blockquote><p>图像特征提取采用的卷积层是<a href="https://www.cnblogs.com/lfri/p/10493408.html" target="_blank" rel="noopener">VGG1６</a>，</p></blockquote><h5 id="2-8-3基于Faster-R-CNN的航拍图像分析"><a href="#2-8-3基于Faster-R-CNN的航拍图像分析" class="headerlink" title="2.8.3基于Faster R-CNN的航拍图像分析"></a>2.8.3基于Faster R-CNN的航拍图像分析</h5><blockquote><p>航拍图像实例的特点：实例多数处于相对位置不变化的状态<br>航拍图像中的一大难点：</p><ul><li>也是基于航拍图像的目标检测研究面临的第一大难点。</li><li>由于航拍图像拍摄的距离不同，同一类别物体在 不冋图像中的差别会很人</li></ul></blockquote><h5 id="2-8-4基于改进Faster-R-CNN算法的目标检测"><a href="#2-8-4基于改进Faster-R-CNN算法的目标检测" class="headerlink" title="2.8.4基于改进Faster R-CNN算法的目标检测"></a>2.8.4基于改进Faster R-CNN算法的目标检测</h5><blockquote><p>从网络结构出发优化目标可主要分为 CNN特征提取层、RPN结构和Fast R-CNN并行的OHEM算法嵌入三部分。<br>Faster R-CNN中的特征提取采用的是VGG1６网络，<br><strong>改论文创新点：本论文 基于ResNet－101的卷积神经网络设计出了一版Faster R-CNN框架</strong></p></blockquote><h5 id="2-8-6RPN网络改进"><a href="#2-8-6RPN网络改进" class="headerlink" title="2.8.6RPN网络改进"></a>2.8.6RPN网络改进</h5><blockquote><p>RPN网络是Faster R-CNN区别于Fast R-CNN的核心，高精度、准确的 Proposal是网络训练和预测的关键。<br>方法：</p><ul><li>调整RPN中Anchors</li><li>修改Proposal输出阈值</li><li>正负采样调整<br>改进结果：通过对RPN网络的优化对小目标的检测有不错提升，但是训练和预测速度 下降不少，在这里并没有对计算性能进行过多的优化</li></ul></blockquote><h5 id="2-8-7OHEM算法模型嵌入"><a href="#2-8-7OHEM算法模型嵌入" class="headerlink" title="2.8.7OHEM算法模型嵌入"></a>2.8.7<a href="https://blog.csdn.net/u012426298/article/details/81773319" target="_blank" rel="noopener">OHEM</a>算法模型嵌入</h5><blockquote><p>OHEM（Online Hard Example Mining）算法在基于机器学习的任务中十分常见，通常用来解决正负样本不均衡的问题。</p></blockquote><h4 id="2-9本轮文的结构"><a href="#2-9本轮文的结构" class="headerlink" title="2.9本轮文的结构"></a>2.9本轮文的结构</h4><blockquote><p><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191118093651.png" class="lazyload"></p></blockquote><h4 id="2-10未来展望"><a href="#2-10未来展望" class="headerlink" title="2.10未来展望"></a>2.10未来展望</h4><blockquote><p><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191118093842.png" class="lazyload"></p></blockquote><h3 id="3-《智能交通图像识别系统的研究》from"><a href="#3-《智能交通图像识别系统的研究》from" class="headerlink" title="3.《智能交通图像识别系统的研究》from"></a>3.《智能交通图像识别系统的研究》from</h3><h4 id="3-1人工神经网络进行字符识别"><a href="#3-1人工神经网络进行字符识别" class="headerlink" title="3.1人工神经网络进行字符识别"></a>3.1人工神经网络进行字符识别</h4><blockquote><p>主要有两种方法:一种方法是先对待识别字符进行特征提取,然后用所获得的特征来训练神经网络分类器。这种网络的识别效果与字符特征的提取有关,而字符的特征提取往往比较耗时。因此,字符特征的提取就成为研究的关键。文献四中使用由6个多层感知器构成的神经网络来进行车牌字符识别,在特征提取上提出二值线性变换方法以减少输入特征向量,另外改善网络结构以提高识别速度。另一种方法则充分利用神经网络的特点,直接把待处理图像输入网络,由网络自动实现特征提取直至识别。这种网络互连较多、待处理信息量大。<br>神经网络在并行非线性处理及大容量计算方面存在着巨大潜力, 且神经元状态是二值的</p></blockquote><h4 id="3-2图像预处理"><a href="#3-2图像预处理" class="headerlink" title="3.2图像预处理"></a>3.2图像预处理</h4><blockquote><p>预处理相当于对获取的原始图像数据进行整理加工、去伪存真的过程。由于原始图像信号中存在着许多噪声和畸变,一般要进行滤波、平滑、增强、复原、提取边缘、图像分割等预处理,以便提高图像质量,并为下一步特征提取提供必要的基础。<br>决策分类<br>根据具体问题的性质,提出一个反映分类好坏的标准,从而找到最符合这一标准的分类方一法。 从数学观点来看,决策分类就是找出决策函数(边界函数)。</p></blockquote><h5 id="3-2-1灰度图化"><a href="#3-2-1灰度图化" class="headerlink" title="3.2.1灰度图化"></a>3.2.1灰度图化</h5><p>灰度化，在RGB模型中，如果R=G=B时，则彩色表示一种灰度颜色，其中R=G=B的值叫灰度值，因此，灰度图像每个像素只需一个字节存放灰度值（又称强度值、亮度值），灰度范围为0-255。一般有分量法 最大值法平均值法加权平均法四种方法对彩色图像进行灰度化。<br>RGB图像如何转换成灰度图像</p><h6 id="3-2-1-1平均法"><a href="#3-2-1-1平均法" class="headerlink" title="3.2.1.1平均法"></a>3.2.1.1平均法</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">lenna = cv2.imread(<span class="string">"lenna.png"</span>)</span><br><span class="line">row, col, channel = lenna.shape</span><br><span class="line">lenna_gray = np.zeros((row, col))</span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> range(row):</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(col):</span><br><span class="line">        lenna_gray[r, l] = <span class="number">1</span> / <span class="number">3</span> * lenna[r, l, <span class="number">0</span>] + <span class="number">1</span> / <span class="number">3</span> * lenna[r, l, <span class="number">1</span>] + <span class="number">1</span> / <span class="number">3</span> * lenna[r, l, <span class="number">2</span>]</span><br><span class="line">cv2.imshow(<span class="string">"lenna_gray"</span>, lenna_gray.astype(<span class="string">"uint8"</span>))</span><br><span class="line">cv2.waitKey()</span><br></pre></td></tr></table></figure><h6 id="3-2-1-2最大最小平均法"><a href="#3-2-1-2最大最小平均法" class="headerlink" title="3.2.1.2最大最小平均法"></a>3.2.1.2最大最小平均法</h6><blockquote><p>取同一个像素位置的RGB中亮度最大的和最小的进行平均</p></blockquote><h5 id="3-2-1-3加权平均法"><a href="#3-2-1-3加权平均法" class="headerlink" title="3.2.1.3加权平均法"></a>3.2.1.3加权平均法</h5><blockquote><p>I(x,y) = 0.3 * I_R(x,y) +0.59 * I_G(x,y)+ 0.11 * I_B(x,y) 这是最流行的方法。几个加权系数0.3,0.59,0.11是根据人的亮度感知系统调节出来的参数，是个广泛使用的标准化参数。</p></blockquote><h5 id="3-2-1-4二值图像"><a href="#3-2-1-4二值图像" class="headerlink" title="3.2.1.4二值图像"></a>3.2.1.4二值图像</h5><blockquote><p>图像二值化（ Image Binarization）就是将图像上的像素点的灰度值设置为0或255，也就是将整个图像呈现出明显的黑白效果的过程。 在数字图像处理中，二值图像占有非常重要的地位，图像的二值化使图像中数据量大为减少，从而能凸显出目标的轮廓。</p></blockquote><h5 id="3-2-1-5反转图像"><a href="#3-2-1-5反转图像" class="headerlink" title="3.2.1.5反转图像"></a>3.2.1.5反转图像</h5><blockquote><p>反转图像也很简单：s = 255-r。反转图像特别适用于增强暗色图像中的白色或灰色细节</p></blockquote><h4 id="3-2-2中值滤波"><a href="#3-2-2中值滤波" class="headerlink" title="3.2.2中值滤波"></a>3.2.2中值滤波</h4><blockquote><p>中值滤波法是一种非线性平滑技术，它将每一像素点的灰度值设置为该点某邻域窗口内的所有像素点灰度值的中值. 中值滤波是基于排序统计理论的一种能有效抑制噪声的非线性信号处理技术，中值滤波的基本原理是把数字图像或数字序列中一点的值用该点的一个邻域中各点值的中值代替，让周围的像素值接近的真实值，从而消除孤立的噪声点。方法是用某种结构的二维滑动模板，将板内像素按照像素值的大小进行排序，生成单调上升（或下降）的为二维数据序列。二维中值滤波输出为g（x,y）=med{f(x-k,y-l),(k,l∈W)} ，其中，f(x,y)，g(x,y)分别为原始图像和处理后图像。W为二维模板，通常为33，55区域，也可以是不同的的形状，如线状，圆形，十字形，圆环形等。<br>中值滤波对于消除孤立点和线段的干扰十分有用,特别是对于二进噪声尤为有效,对于消除高斯噪声则效果不佳</p></blockquote><h4 id="3-2-3边缘检测"><a href="#3-2-3边缘检测" class="headerlink" title="3.2.3边缘检测"></a>3.2.3边缘检测</h4><blockquote><p>边缘检测是图像处理和计算机视觉中的基本问题，边缘检测的目的是标识数字图像中亮度变化明显的点。图像属性中的显著变化通常反映了属性的重要事件和变化。 这些包括（i）深度上的不连续、（ii）表面方向不连续、（iii）物质属性变化和（iv）场景照明变化。 边缘检测是图像处理和计算机视觉中，尤其是特征提取中的一个研究领域。</p></blockquote><h5 id="3-2-3-1检测方法"><a href="#3-2-3-1检测方法" class="headerlink" title="3.2.3.1检测方法"></a>3.2.3.1检测方法</h5><blockquote><p>有许多用于边缘检测的方法, 他们大致可分为两类：基于搜索和基于零交叉**。 基于搜索的边缘检测方法首先计算边缘强度， 通常用一阶导数表示， 例如梯度模，然后，用计算估计边缘的局部方向， 通常采用梯度的方向，并利用此方向找到局部梯度模的最大值。 基于零交叉的方法找到由图像得到的二阶导数的零交叉点来定位边缘。 通常用拉普拉斯算子或非线性微分方程的零交叉点。 滤波做为边缘检测的预处理通常是必要的，通常采用高斯滤波。 已发表的边缘检测方法应用计算边界强度的度量，这与平滑滤波有本质的不同。 正如许多边缘检测方法依赖于图像梯度的计算，他们用不同种类的滤波器来估计x-方向和y-方向的梯度。</p></blockquote><h4 id="3-3车牌定位"><a href="#3-3车牌定位" class="headerlink" title="3.3车牌定位"></a>3.3车牌定位</h4><blockquote><p>车牌定位的主要方法可分为五种!:①直线边缘检测;②基于域值迭代的方法;③基于神经网络的车牌定位方法;④基于灰度的检测方法;均基于彩色图像的车牌分割方`法。<br>利用BP神经网络在灰度图像中提取车牌。具体步骤为:先收集一定数量的车牌样本,用BP算法对其进行训练,达到一定正确率后,训练结束,得到一个对牌照敏感的神经网络,提取牌照时,对输入图像进行预处理,然后利用训练出的神经网络来搜索车牌。</p></blockquote><h4 id="3-4改进之处"><a href="#3-4改进之处" class="headerlink" title="3.4改进之处"></a>3.4改进之处</h4><blockquote><p>本轮文提出的有待改进的地方：<br>目前的车牌号码自动识别系统只能处理单个车牌的汽车图像,对于一幅图像中多个车牌的识别则无能为力,<br>如何消除外界因素的干扰仍然是闯红灯系统需要解决的一个问题。</p></blockquote><h3 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h3><p>欢迎大家关注鄙人的公众号【麦田里的守望者zhg】，让我们一起成长，谢谢。<br><img alt="微信公众号" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/wechataccount.jpg" class="lazyload"></p></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author:</span> <span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">Crazy Jums</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link:</span> <span class="post-copyright-info"><a href="https://jums.club/note-master-1/">https://jums.club/note-master-1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice:</span> <span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="../tags/CVISION/">计算机视觉</a> <a class="post-meta__tags" href="../tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-meta__tags" href="../tags/%E8%88%AA%E6%8B%8D%E8%AF%86%E5%88%AB/">航拍识别</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/master.jpg" data-sites="wechat,weibo"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button"><i class="fa fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/wechatpay.jpg"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/alipay.jpg"><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="../conclusion-hexo-1/"><img class="prev_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/hexo.jpg" onerror='onerror=null,src="/img/404.jpg"'><div class="label">Previous Post</div><div class="prev_info"><span>手把手教你玩转hexo个人博客，自定义主题，博客发布，GitHub部署</span></div></a></div><div class="next-post pull_right"><a href="../video-1/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/IMG_2987.JPG" onerror='onerror=null,src="/img/404.jpg"'><div class="label">Next Post</div><div class="next_info"><span>视频test</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i> <span>Recommend</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/AlexNet/" title="CNN典型模型：AlexNet"><img class="relatedPosts_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/AlexNet.png"><div class="relatedPosts_title">CNN典型模型：AlexNet</div></a></div><div class="relatedPosts_item"><a href="/SSPNet/" title="关于SSPNet（空间金字塔池化网络），了解一下"><img class="relatedPosts_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20150105213522578.png"><div class="relatedPosts_title">关于SSPNet（空间金字塔池化网络），了解一下</div></a></div><div class="relatedPosts_item"><a href="/gradient-descent/" title="关于深度学习中的梯度下降，了解一下"><img class="relatedPosts_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-6ae594f795406b8b.png"><div class="relatedPosts_title">关于深度学习中的梯度下降，了解一下</div></a></div><div class="relatedPosts_item"><a href="/cnn/" title="关于卷积神经网络，了解一下"><img class="relatedPosts_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/48540923dd54564e223d3494bdde9c82d0584fc7.jpg"><div class="relatedPosts_title">关于卷积神经网络，了解一下</div></a></div><div class="relatedPosts_item"><a href="/cv-concept-you-must-know/" title="学习计算机视觉，你必须了解的基础概念"><img class="relatedPosts_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/cv.jpg"><div class="relatedPosts_title">学习计算机视觉，你必须了解的基础概念</div></a></div><div class="relatedPosts_item"><a href="/your-plan/" title="你现在的能力和你需要达到的高度"><img class="relatedPosts_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/deep_learning_object_detection_history.png"><div class="relatedPosts_title">你现在的能力和你需要达到的高度</div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i> <span>Comment</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var notify=!1,verify=!1,GUEST_INFO=["nick","mail","link"],guest_info="nick,mail,link".split(",").filter(function(e){return-1<GUEST_INFO.indexOf(e)});guest_info=0==guest_info.length?GUEST_INFO:guest_info,window.valine=new Valine({el:"#vcomment",notify:notify,verify:verify,appId:"2lPeEraOnOk7GF6ou1WWs6BP-gzGzoHsz",appKey:"nXeW1bmcRE4TDrorjmdqj0ML",placeholder:"Please leave your footprints",avatar:"monsterid",guest_info:guest_info,pageSize:"10",lang:"en",recordIP:!0})</script></div></div></div><footer id="footer" style="background-image:url(https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/master.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2020 By Crazy Jums</div><div class="framework-info"></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="Read Mode"></i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="Traditional Chinese and Simplified Chinese Conversion" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="Dark Mode"></i></div><div id="rightside-config-show"><div id="rightside_config" title="Setting"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="Scroll to comment"><i class="scroll_to_comment fa fa-comments"></i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="Table of Contents" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="Back to top" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="../js/utils.js"></script><script src="../js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="../js/search/local-search.js"></script><script id="ribbon_piao" mobile="true" src="../js/third-party/piao.js"></script><script src="../js/baidupush.js"></script><script src="../js/third-party/activate-power-mode.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!0,document.body.addEventListener("input",POWERMODE)</script><script src="../js/tw_cn.js"></script><script>translateInitilization()</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async></script><script src="../js/third-party/ClickShowText.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49b1f5">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({model:"wanko",bottom:-30,log:!1,pluginJsPath:"lib/",pluginModelPath:"assets/",pluginRootPath:"live2dw/",tagMode:!1})</script><script async>window.onload=function(){var e=document.createElement("script"),t=document.getElementsByTagName("script")[0];e.type="text/javascript",e.async=!0,e.src="/sw-register.js?v="+Date.now(),t.parentNode.insertBefore(e,t)}</script></body></html>