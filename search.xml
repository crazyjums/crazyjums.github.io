<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>hexo绑定个人域名之后，不能访问，已经解决</title>
      <link href="/config-ssh-for-github/"/>
      <url>/config-ssh-for-github/</url>
      
        <content type="html"><![CDATA[<h3 id="1-发现问题"><a href="#1-发现问题" class="headerlink" title="1 发现问题"></a>1 发现问题</h3><p>昨天为了优化SEO，我给我的GitHub page 加了一个三方包，如下：   </p><pre><code class="editorconfig">npm install hexo-abbrlink --save</code></pre><p>但是，当我再次hexo d的时候，发现本地的hexo可用，但是GitHub page就用不了了，因为我用了域名解析，用的腾讯云的域名解析系统，可以参考我的这篇博客，<a href="https://jums.club/personal-domain-for-github-page/">如何用一元开通自己的个性域名</a><br>当我使用<a href="https://jums.club/">https://jums.club/</a>进行访问时，发现出现了下面的界面：<br><img alt="error page" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191124093619.png" class="lazyload">   </p><h3 id="2-解决问题"><a href="#2-解决问题" class="headerlink" title="2 解决问题"></a>2 解决问题</h3><p>发现了问题，当然得解决问题，否则发现问题就没有什么意义了。<br>首先我百度了一下，看了一篇<a href="https://blog.csdn.net/tr1912/article/details/80673610" target="_blank" rel="noopener">博客</a>，看了一下，然后我的问题解决，虽然是百度的，但是问题能解决就行。<br>我发现我的GitHub page 的域名绑定突然好像失效了，所以我又从新绑定了一下，我是用的是IP地址和GitHub page 的域名同时绑定到我的个人域名上，如下所示：<br><img alt="domain photo" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191124095621.png" class="lazyload"><br><strong>如何获取GitHub page的IP地址：</strong><br><img alt="github page ip" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191124095730.png" class="lazyload">   </p><p><strong>最后：</strong>   </p><blockquote><p>最后，问题终于解决，就是域名没有绑定，绑定完之后，渠道GitHub page 的setting界面，可以看到如下配置，即为配置成功。<br><img alt="success config" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191124100230.png" class="lazyload"></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> 解决问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决【Please make sure you have the correct access rights and the repository exists.】</title>
      <link href="/ssh-connect-to-github/"/>
      <url>/ssh-connect-to-github/</url>
      
        <content type="html"><![CDATA[<h3 id="1-发现问题"><a href="#1-发现问题" class="headerlink" title="1 发现问题"></a>1 发现问题</h3><blockquote><p>问题：Please make sure you have the correct access rights and the repository exists.<br>当你使用git工具向GitHub提交代码时，遇到了上述问题，那么没关系，该问题已经解决<br>问题的关键就是没有在GitHub配置ssh key</p></blockquote><h3 id="2-解决问题"><a href="#2-解决问题" class="headerlink" title="2 解决问题"></a>2 解决问题</h3><p>进入到你的GitHub账户的setting中，然后找到ssh key选项，添加自己的公钥即可。<br><strong>第一步：</strong><br>产生自己的公钥,执行如下命令：   </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;your github account&quot;</span><br><span class="line">#比如：我的GitHub账户是123456@qq.com，那么命令如下：</span><br><span class="line">ssh-keygen -t rsa -C &quot;123456@qq.com&quot;</span><br></pre></td></tr></table></figure><p>一路默认即可，然后在cd到存放公钥的文件夹里面，使用cat命令查看，然后将其复制到GitHub的setting中：<br><img alt="ssh key" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191124130021.png" class="lazyload">  </p>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> github </tag>
            
            <tag> 问题解决 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐一个免费图床，了解一下</title>
      <link href="/a-free-tuchuang-site/"/>
      <url>/a-free-tuchuang-site/</url>
      
        <content type="html"><![CDATA[<h3 id="免费图床"><a href="#免费图床" class="headerlink" title="免费图床"></a>免费图床</h3><p><a href="https://www.tuchuang001.com/" target="_blank" rel="noopener">https://www.tuchuang001.com/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何同时将hexo代码部署到GitHub以及coding上</title>
      <link href="/git-to-github-and-coding/"/>
      <url>/git-to-github-and-coding/</url>
      
        <content type="html"><![CDATA[<p><strong>修改hexo根目录下的_config.yml文件，代码如下：</strong>   </p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/deployment.html</span></span><br><span class="line"><span class="attr">deploy:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span> </span><br><span class="line">    <span class="attr">github:</span> <span class="string">git@github.com:crazyjums/crazyjums.github.io.git</span></span><br><span class="line">    <span class="attr">coding:</span> <span class="string">git@git.dev.tencent.com:dtid_f0ed6967903b604b/hexo_blog.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">type:</span> <span class="string">baidu_url_submitter</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何让自己的hexo博客被Google和百度收录</title>
      <link href="/put-your-hexo-blog-to-baidu-sitmap/"/>
      <url>/put-your-hexo-blog-to-baidu-sitmap/</url>
      
        <content type="html"><![CDATA[<h3 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h3><blockquote><p><a href="https://www.jianshu.com/p/25145964abf3" target="_blank" rel="noopener">如何让自己的hexo博客被Google和百度收录</a></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用Python扫描文件夹中所有文件，并将部分文件按要求改名字</title>
      <link href="/change-file-name-by-python/"/>
      <url>/change-file-name-by-python/</url>
      
        <content type="html"><![CDATA[<h3 id="话不多说，直接上代码"><a href="#话不多说，直接上代码" class="headerlink" title="话不多说，直接上代码"></a>话不多说，直接上代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scan_files</span><span class="params">(directory, prefix=None, postfix=None)</span>:</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> files <span class="keyword">in</span> os.walk(directory):</span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files[<span class="number">2</span>]:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">"微信截图_"</span> <span class="keyword">in</span> file:</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">                newname = re.sub(<span class="string">"微信截图_"</span>,<span class="string">""</span>,file)</span><br><span class="line">                os.rename(directory+file,directory+newname)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    print(<span class="string">"改名完成,一共改名&#123;&#125;个文件"</span>.format(count))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    dir = <span class="string">r"xxx/xxx"</span> <span class="comment"># 这里写你的路径，记得加上前面的r，否则容易出错</span></span><br><span class="line">    scan_files(dir)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 编程语言 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>查看hexo已经安装的三方包命令</title>
      <link href="/view-package-of-npm/"/>
      <url>/view-package-of-npm/</url>
      
        <content type="html"><![CDATA[<h3 id="查看命令"><a href="#查看命令" class="headerlink" title="查看命令"></a>查看命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm list --depth 0</span><br></pre></td></tr></table></figure><p><strong>命令解释：</strong>   </p><ul><li>–depth  查看已经三方的深度，默认是显示所有，用0只显示最外层</li></ul><p><strong>显示结果下所示：</strong><br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191123135324.png" class="lazyload"> </p>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo个人博客绑定个人域名</title>
      <link href="/personal-domain-for-github-page/"/>
      <url>/personal-domain-for-github-page/</url>
      
        <content type="html"><![CDATA[<h3 id="1-注册个人域名"><a href="#1-注册个人域名" class="headerlink" title="1 注册个人域名"></a>1 注册个人域名</h3><p>进入到腾讯云平台，自己注册一个账号（微信登录即可），下面是网址：<br><a href="https://cloud.tencent.com/act/domainsales?from=dnspodqcloud" target="_blank" rel="noopener">https://cloud.tencent.com/act/domainsales?from=dnspodqcloud</a><br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191123125246.png" class="lazyload">   </p><h3 id="2-开始域名解析"><a href="#2-开始域名解析" class="headerlink" title="2 开始域名解析"></a>2 开始域名解析</h3><p>自己按照步骤购买域名，第一年是1元，然后进入到控制台，进入域名解析界面，如下：<br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191123125742.png" class="lazyload"><br>点击【解析】进入到域名解析界面，如下：<br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191123125952.png" class="lazyload">   </p><h3 id="3-创建CNAME文件"><a href="#3-创建CNAME文件" class="headerlink" title="3 创建CNAME文件"></a>3 创建CNAME文件</h3><p>创建一个CNAME文件：   </p><ul><li>这几个字母必须是大写</li><li>没有后缀名</li><li>用记事本打开将自己的域名写在里面，如：<br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191123130306.png" class="lazyload">   </li></ul><h3 id="4-部署到GitHub"><a href="#4-部署到GitHub" class="headerlink" title="4 部署到GitHub"></a>4 部署到GitHub</h3><p>将CNAME文件放到publics文件夹里面，然后上传到GitHub，命令如下：   </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow如何控制输出控制台的日志等级</title>
      <link href="/tensorflow-log-level/"/>
      <url>/tensorflow-log-level/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 输出所有 默认等级</span></span><br><span class="line">os.environ[<span class="string">"TF_CPP_MIN_LOG_LEVEL"</span>]=<span class="string">'1'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出warm和error</span></span><br><span class="line">os.environ[<span class="string">"TF_CPP_MIN_LOG_LEVEL"</span>]=<span class="string">'2'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 只输出error</span></span><br><span class="line">os.environ[<span class="string">"TF_CPP_MIN_LOG_LEVEL"</span>]=<span class="string">'3'</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 编程框架 </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN典型模型：AlexNet</title>
      <link href="/AlexNet/"/>
      <url>/AlexNet/</url>
      
        <content type="html"><![CDATA[<p>论文出处：《<a href="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pdf/ImageNet_Classification_with_Deep_Convolutional_Neural_Networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a>》<br><a href="https://blog.csdn.net/luoluonuoyasuolong/article/details/81750190" target="_blank" rel="noopener">一篇很好的理解AlexNet模型的博客</a><br>AlexNet 的网络结构如下所示：<br><img alt="AlexNet 的网络结构" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/AlexNet.png" class="lazyload"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 基础知识 </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于局部响应归一化层（LRN），了解一下</title>
      <link href="/lrn/"/>
      <url>/lrn/</url>
      
        <content type="html"><![CDATA[<h3 id="局部响应归一化层（Local-Response-Normalization）"><a href="#局部响应归一化层（Local-Response-Normalization）" class="headerlink" title="局部响应归一化层（Local Response Normalization）"></a>局部响应归一化层（Local Response Normalization）</h3><p>本篇博客参考自：<a href="https://note.youdao.com/" target="_blank" rel="noopener">https://www.jianshu.com/p/c014f81242e7</a></p><p>局部响应归一化层简称LRN，<strong>是在深度学习中提高准确度的技术方法</strong>。一般是在激活、池化后进行的一种处理方法，因在<a href="https://note.youdao.com/" target="_blank" rel="noopener">Alexnet</a>中运用到，故做一下整理。   </p><blockquote><p><strong>为什么要引入LRN层？</strong><br>首先要引入一个神经生物学的概念：侧抑制（lateral inhibitio），即指被激活的神经元抑制相邻的神经元。归一化（normaliazation）的目的就是“抑制”,LRN就是借鉴这种侧抑制来实现局部抑制，尤其是我们使用RELU的时候，这种“侧抑制”很有效 ，因而在alexnet里使用有较好的效果。</p><p><strong>归一化有什么好处？</strong><br>1.归一化有助于快速收敛；<br>2.对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。<br>【补充：神经网络学习过程本质就是为了学习数据分布，一旦训练数据与测试数据的分布不同，那么网络的泛化能力也大大降低；另外一方面，一旦每批训练数据的分布各不相同(batch 梯度下降)，那么网络就要在每次迭代都去学习适应不同的分布，这样将会大大降低网络的训练速度，这也正是为什么我们需要对数据都要做一个归一化预处理的原因。<br>深度网络的训练是复杂的过程，只要网络的前面几层发生微小的改变，那么后面几层就会被累积放大下去。一旦网络某一层的输入数据的分布发生改变，那么这一层网络就需要去适应学习这个新的数据分布，所以如果训练过程中，训练数据的分布一直在发生变化，那么将会影响网络的训练速度。】</p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>深度学习和机器学习的区别？</title>
      <link href="/machine-learning-different-from-deep-learning/"/>
      <url>/machine-learning-different-from-deep-learning/</url>
      
        <content type="html"><![CDATA[<p>关于深度学习和机器学习，他们有如下几点不同之处：</p><h3 id="1-特征提取方面"><a href="#1-特征提取方面" class="headerlink" title="1 特征提取方面"></a>1 特征提取方面</h3><ul><li>机器学习必须通过人工特征提取之后，才能进行后续的识别等操作</li><li>深度学习则不同，深度学习深刻网络框架可以不需要人工进行特征提取，而是通过网络自动进行提取，那么深度学习就显得更加强大了</li></ul><h3 id="2-数据量和计算性能方面"><a href="#2-数据量和计算性能方面" class="headerlink" title="2 数据量和计算性能方面"></a>2 数据量和计算性能方面</h3><p><img alt="数据量和计算性能方面" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191121140526768.jpg" class="lazyload">   </p><h3 id="算法代表"><a href="#算法代表" class="headerlink" title="算法代表"></a>算法代表</h3><p>机器学习：</p><ul><li>素朴贝叶斯</li><li>决策树<br>…   </li></ul><p>深度学习</p><ul><li>神经网络</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于SSPNet（空间金字塔池化网络），了解一下</title>
      <link href="/SSPNet%20-%20%E5%89%AF%E6%9C%AC/"/>
      <url>/SSPNet%20-%20%E5%89%AF%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<h3 id="1-SSPNet论文出处"><a href="#1-SSPNet论文出处" class="headerlink" title="1 SSPNet论文出处"></a>1 SSPNet论文出处</h3><p>SSPNet（Spatial Pyramid Pooling Network），中文名字是空间金字塔池化网络<br>SSPNet论文出自《<a href="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pdf/Spatial_Pyramid_Pooling_in_Deep_Convolutional_Networks_for_Visual_Recognition.pdf" target="_blank" rel="noopener">Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</a>》<br><a href="https://blog.csdn.net/tinyzhao/article/details/53717136" target="_blank" rel="noopener">一篇较好的解读SSPNet的博客</a></p><h4 id="1-1-为什么会提出SSPNet"><a href="#1-1-为什么会提出SSPNet" class="headerlink" title="1.1 为什么会提出SSPNet"></a>1.1 为什么会提出SSPNet</h4><p>SSPNet的中文名称是空间金字塔池化网络，SSPNet的提出，是为了解决R-CNN遇到的一个拼劲问题，也就是R-CNN在候选区提取时，每张图片都需要经过一次CNN，运行速度很慢。如果你有2000张图片的话，那么你需要经过2000次CNN网络，这样的计算速度是非常慢的。 在了解SSPNet之前，让我们先了解一下<a href="https://crazyjums.github.io/2019/11/18/cv-concept-you-must-know/#R-CNN的工作原理" target="_blank" rel="noopener">R-CNN的工作原理</a>，才能对其进行改进。  </p><p><strong>SSPNet完美解决上述R-CNN遗留的两个问题:</strong>   </p><blockquote><ul><li>R-CNN在生成了候选区域后，需要对每个区域进行统一尺寸的压缩或放大，当候选集的长与宽差别较大时强行压缩至比例为1:1时会使图像产生变形和丢失图像的原始特征</li><li>R-CNN生成了多个候选集后需要全部输入到CNN中，当生成了2000个候选集时，就需要对图片进行2000次单模型特征提取，这无疑是效率低下的</li></ul></blockquote><h4 id="1-2-SSPNet的解决方案"><a href="#1-2-SSPNet的解决方案" class="headerlink" title="1.2 SSPNet的解决方案"></a>1.2 SSPNet的解决方案</h4><p>针对R-CNN遗留的两个问题，SSPNet提出了如下的解决方案：   </p><blockquote><ul><li>SPPNet网络结构图如下所示，在输入时直接输入整张图像，只需要对整张图像做一次卷积操作，同时会生成整张图像的候选集特征映射(Feature Map)，这<strong>样候选集对应的特征图可以直接传递到下一层，这样一来对图像进行2000次的计算就变成了1次</strong>，大大增加了网络的效率。</li><li>SPPNet中另一关键模块就是金字塔池化层（Spatial Pyramid Pooling Layer），这一层的<strong>设计思路是通过池化操作将任意尺寸的输入都转换成固定大小输出</strong>，<strong>因为在池化层中只要池化的核结构不变，输入的维度就不会变化</strong>。Kaiming He等人正是利用了<strong>池化输出固定的原理</strong>避免了<strong>原始R-CNN模型中需要缩放图片候选集</strong>的操作   </li></ul></blockquote><p><strong>SPPNet在R-CNN拥有的区域提取、卷积层、池化层、全连接层、SVM分类器和Bounding-Box回归网络结构基础上，加入了候选集特征图映射和SPP Pooling层。将R-CNN网络的预测速度提升了数十倍，极大地优化了网络的计算法复杂度</strong><br>SSPNet的结构图如下所示：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20150105213522578.png" class="lazyload"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 基础知识 </tag>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于SSPNet（空间金字塔池化网络），了解一下</title>
      <link href="/SSPNet/"/>
      <url>/SSPNet/</url>
      
        <content type="html"><![CDATA[<h3 id="1-SSPNet论文出处"><a href="#1-SSPNet论文出处" class="headerlink" title="1 SSPNet论文出处"></a>1 SSPNet论文出处</h3><p>SSPNet（Spatial Pyramid Pooling Network），中文名字是空间金字塔池化网络<br>SSPNet论文出自《<a href="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pdf/Spatial_Pyramid_Pooling_in_Deep_Convolutional_Networks_for_Visual_Recognition.pdf" target="_blank" rel="noopener">Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</a>》<br><a href="https://blog.csdn.net/tinyzhao/article/details/53717136" target="_blank" rel="noopener">一篇较好的解读SSPNet的博客</a></p><h4 id="1-1-为什么会提出SSPNet"><a href="#1-1-为什么会提出SSPNet" class="headerlink" title="1.1 为什么会提出SSPNet"></a>1.1 为什么会提出SSPNet</h4><p>SSPNet的中文名称是空间金字塔池化网络，SSPNet的提出，是为了解决R-CNN遇到的一个拼劲问题，也就是R-CNN在候选区提取时，每张图片都需要经过一次CNN，运行速度很慢。如果你有2000张图片的话，那么你需要经过2000次CNN网络，这样的计算速度是非常慢的。 在了解SSPNet之前，让我们先了解一下<a href="https://crazyjums.github.io/2019/11/18/cv-concept-you-must-know/#R-CNN的工作原理" target="_blank" rel="noopener">R-CNN的工作原理</a>，才能对其进行改进。  </p><p><strong>SSPNet完美解决上述R-CNN遗留的两个问题:</strong>   </p><blockquote><ul><li>R-CNN在生成了候选区域后，需要对每个区域进行统一尺寸的压缩或放大，当候选集的长与宽差别较大时强行压缩至比例为1:1时会使图像产生变形和丢失图像的原始特征</li><li>R-CNN生成了多个候选集后需要全部输入到CNN中，当生成了2000个候选集时，就需要对图片进行2000次单模型特征提取，这无疑是效率低下的</li></ul></blockquote><h4 id="1-2-SSPNet的解决方案"><a href="#1-2-SSPNet的解决方案" class="headerlink" title="1.2 SSPNet的解决方案"></a>1.2 SSPNet的解决方案</h4><p>针对R-CNN遗留的两个问题，SSPNet提出了如下的解决方案：   </p><blockquote><ul><li>SPPNet网络结构图如下所示，在输入时直接输入整张图像，只需要对整张图像做一次卷积操作，同时会生成整张图像的候选集特征映射(Feature Map)，这<strong>样候选集对应的特征图可以直接传递到下一层，这样一来对图像进行2000次的计算就变成了1次</strong>，大大增加了网络的效率。</li><li>SPPNet中另一关键模块就是金字塔池化层（Spatial Pyramid Pooling Layer），这一层的<strong>设计思路是通过池化操作将任意尺寸的输入都转换成固定大小输出</strong>，<strong>因为在池化层中只要池化的核结构不变，输入的维度就不会变化</strong>。Kaiming He等人正是利用了<strong>池化输出固定的原理</strong>避免了<strong>原始R-CNN模型中需要缩放图片候选集</strong>的操作   </li></ul></blockquote><p><strong>SPPNet在R-CNN拥有的区域提取、卷积层、池化层、全连接层、SVM分类器和Bounding-Box回归网络结构基础上，加入了候选集特征图映射和SPP Pooling层。将R-CNN网络的预测速度提升了数十倍，极大地优化了网络的计算法复杂度</strong><br>SSPNet的结构图如下所示：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20150105213522578.png" class="lazyload"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 基础知识 </tag>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于深度学习中的梯度下降，了解一下</title>
      <link href="/gradient-descent/"/>
      <url>/gradient-descent/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/c7e642877b0e" target="_blank" rel="noopener">一篇让你很容易理解什么是梯度下降的博客</a></p><h3 id="0-什么是梯度下降"><a href="#0-什么是梯度下降" class="headerlink" title="0 什么是梯度下降"></a>0 什么是梯度下降</h3><blockquote><p>梯度下降法的基本思想可以类比为一个下山的过程。假设这样一个场景：一个人被困在山上，需要从山上下来(i.e. 找到山的最低点，也就是山谷)。但此时山上的浓雾很大，导致可视度很低。因此，下山的路径就无法确定，他必须利用自己周围的信息去找到下山的路径。这个时候，他就可以利用梯度下降算法来帮助自己下山。具体来说就是，以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着山的高度下降的地方走，同理，如果我们的目标是上山，也就是爬到山顶，那么此时应该是朝着最陡峭的方向往上走。然后每走一段距离，都反复采用同一个方法，最后就能成功的抵达山谷。<br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-6ae594f795406b8b.png" class="lazyload"><br>我们同时可以假设这座山最陡峭的地方是无法通过肉眼立马观察出来的，而是需要一个复杂的工具来测量，同时，这个人此时正好拥有测量出最陡峭方向的能力。所以，此人每走一段距离，都需要一段时间来测量所在位置最陡峭的方向，这是比较耗时的。那么为了在太阳下山之前到达山底，就要尽可能的减少测量方向的次数。这是一个两难的选择，如果测量的频繁，可以保证下山的方向是绝对正确的，但又非常耗时，如果测量的过少，又有偏离轨道的风险。所以需要找到一个合适的测量方向的频率，来确保下山的方向不错误，同时又不至于耗时太多！</p></blockquote><h3 id="1-1-什么是微分"><a href="#1-1-什么是微分" class="headerlink" title="1.1 什么是微分"></a>1.1 什么是<strong>微分</strong></h3><p>微分的两种数学意义：</p><ul><li>函数图像中，某点的切线的斜率</li><li>函数的变化率<br>单变量微分的例子：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-0eb0f1bfd7de705b.png" class="lazyload"><br>多变量微分的例子：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-4029977524e3b365.png" class="lazyload"></li></ul><h3 id="1-2-什么是梯度"><a href="#1-2-什么是梯度" class="headerlink" title="1.2 什么是梯度"></a>1.2 什么是梯度</h3><blockquote><p>梯度实际上就是多变量微分的一般化。<br>看下面的例子：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-570afdfc6fabf3b6.png" class="lazyload"><br>我们可以看到，梯度就是分别对每个变量进行微分，然后用逗号分割开，梯度是用&lt;&gt;包括起来，说明梯度其实一个向量。</p></blockquote><p>梯度的意义：</p><ul><li>在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率</li><li>在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向</li></ul><p>这也就说明了为什么我们需要千方百计的求取梯度！我们需要到达山底，就需要在每一步观测到此时最陡峭的地方，梯度就恰巧告诉了我们这个方向。梯度的方向是函数在给定点上升最快的方向，那么梯度的反方向就是函数在给定点下降最快的方向，这正是我们所需要的。所以我们只要沿着梯度的方向一直走，就能走到局部的最低点！</p><h3 id="1-3-梯度下降的数学解释"><a href="#1-3-梯度下降的数学解释" class="headerlink" title="1.3 梯度下降的数学解释"></a>1.3 梯度下降的数学解释</h3><blockquote><p>上面我们花了大量的篇幅介绍梯度下降算法的基本思想和场景假设，以及梯度的概念和思想。下面我们就开始从数学上解释梯度下降算法的计算过程和思想！<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-f20521a962005299.png" class="lazyload"><br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191119145602186.jpg" class="lazyload"><br>就想下年的的图中的解释那样：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-af8dd9722c762c13.png" class="lazyload"></p></blockquote><h3 id="1-4-对于公式中的疑问"><a href="#1-4-对于公式中的疑问" class="headerlink" title="1.4 对于公式中的疑问"></a>1.4 对于公式中的疑问</h3><p><strong>1. α是什么含义？</strong><br>α在梯度下降算法中被称作为学习率或者步长，意味着我们可以通过α来控制每一步走的距离，以保证不要步子跨的太大扯着蛋，哈哈，其实就是不要走太快，错过了最低点。同时也要保证不要走的太慢，导致太阳下山了，还没有走到山下。所以α的选择在梯度下降法中往往是很重要的！α不能太大也不能太小，太小的话，可能导致迟迟走不到最低点，太大的话，会导致错过最低点！<br>如下图所示：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-ba3da0b06da97ddb.png" class="lazyload">   </p><p><strong>2. 为什么要梯度要乘以一个负号？</strong><br>梯度前加一个负号，就意味着朝着梯度相反的方向前进！我们在前文提到，梯度的方向实际就是函数在此点上升最快的方向！而我们需要朝着下降最快的方向走，自然就是负的梯度的方向，所以此处需要加上负号</p><h3 id="1-5-梯度下降算法举例"><a href="#1-5-梯度下降算法举例" class="headerlink" title="1.5 梯度下降算法举例"></a>1.5 梯度下降算法举例</h3><ul><li><strong>单变量函数举例</strong><br>首先我们假设有一个单变量的函数，形式如下所示：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-abb73822fb6d2a2c.png" class="lazyload"><br>函数的微分形式如下所示：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-66ce0cdcef5e2686.png" class="lazyload"><br>初始化起点为：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-8ee36cc5ce832b17.png" class="lazyload"><br>学习率为：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-798b134107b6593d.png" class="lazyload"><br>梯度的计算公式如下：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-f20521a962005299.png" class="lazyload"><br>开始计算梯度下降的迭代过程：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-57538d21dbb34e65.png" class="lazyload"><br>经过4次运算之后，基本就到达了谷底，也就是收敛了，计算结果如下图所示：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-57538d21dbb34e65.png" class="lazyload"></li></ul><ul><li><strong>多变量函数举例</strong><br>下面是目标函数：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-a56cfde25c688859.png" class="lazyload">   <blockquote><p>现在要通过梯度下降法计算这个函数的最小值。我们通过观察就能发现最小值其实就是 (0，0)点。但是接下来，我们会从梯度下降算法开始一步步计算到这个最小值！</p></blockquote></li></ul><p>假设初始的起点为：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-8b1b6f1b200fd7b5.png" class="lazyload"><br>初始学习率为：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-ccc1493848871074.png" class="lazyload"><br>目标函数的梯度为：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-3d744d9364a4ba40.png" class="lazyload"><br>进行梯度下降迭代计算：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-b21bf64600c4e32f.png" class="lazyload"><br>梯度下降计算结果如下图所示：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1234352-becdcdfdefb4eab7.png" class="lazyload">   </p><blockquote><p>上述解释来自下面这篇<a href="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pdf/Gradient_Descent.pdf" target="_blank" rel="noopener">PDF</a>，大家可以下载该PDF进行查看，只不过是英文的。</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 基础知识 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于卷积神经网络，了解一下</title>
      <link href="/cnn/"/>
      <url>/cnn/</url>
      
        <content type="html"><![CDATA[<h3 id="1-卷积神经网络"><a href="#1-卷积神经网络" class="headerlink" title="1 卷积神经网络"></a>1 <a href="https://baike.baidu.com/item/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/17541100?fr=aladdin" target="_blank" rel="noopener">卷积神经网络</a></h3><blockquote><p><a href="https://blog.csdn.net/weixin_42451919/article/details/81381294" target="_blank" rel="noopener">一篇很好的关于理解卷积神经网络的博客</a>（博客中的<strong>filter助手</strong>表示的是<strong>卷积核</strong>的意思）<br><a href="https://blog.csdn.net/u013093426/article/details/81086396" target="_blank" rel="noopener">一篇关于如何搭建CNN的博客</a><br><a href="https://www.zhihu.com/question/39022858/answer/224446917" target="_blank" rel="noopener">知乎回答：能否对卷积神经网络工作原理做一个直观的解释？</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650728746&idx=1&sn=61e9cb824501ec7c505eb464e8317915&scene=0#wechat_redirect" target="_blank" rel="noopener">机器视角：长文揭秘图像处理和卷积神经网络架构</a>|<a href="https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/" target="_blank" rel="noopener"><strong>该文原文</strong></a><br>定义：卷积神经网络（Convolutional Neural Network，CNN）是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。 它包括卷积层(convolutional layer)和池化层(pooling layer)    </p></blockquote><h3 id="1-1-卷积神经网络的结构："><a href="#1-1-卷积神经网络的结构：" class="headerlink" title="1.1 卷积神经网络的结构："></a>1.1 <strong>卷积神经网络的结构：</strong></h3><p><strong>卷积神经网络的结构包括：</strong>   </p><ul><li>输入层（input，输入一张全尺寸的黑白或彩色图像）</li><li>卷积层（filter，对ROI(region of interest)进行特征提取，一个CNN可以有很多的卷积核也可以有很多的卷积层）</li><li>池化层（pooling，可选，目的是减少上层的输入参数）</li><li>输出层（也叫全连接层FC，该层可以用来对图像进行分类和识别操作）</li></ul><p><strong>下面这张图是CNN的结构图：</strong>   </p><blockquote><p><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/48540923dd54564e223d3494bdde9c82d0584fc7.jpg" class="lazyload">   </p></blockquote><p><strong>人工神经网络和卷积神经网络的对比：</strong>   </p><blockquote><p><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFreggeAJhflAACFamG9M3o011.png" class="lazyload"><br>左图：全连接神经网络（平面），组成：输入层、激活函数、全连接层<br>右图：卷积神经网络（立体），组成：输入层、卷积层、激活函数、池化层、全连接层<br><strong>在卷积神经网络中有一个重要的概念：深度，它是指一幅图像的通道数量，如：RGB图像的深度是3，灰度图像的深度是1等</strong><br><strong>在卷积神经网络中，有一个非常重要的特性：权值共享：</strong>  所谓的权值共享就是说，给一张输入图片，用一个filter去扫这张图，filter里面的数就叫权重，这张图每个位置是被同样的filter扫的，所以权重是一样的，也就是共享。</p></blockquote><p><strong>注意：特征提取之后，一般使用几个filter助手（卷积核）就会得到几个深度为1的feature map</strong></p><blockquote><p><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFreggiAC8-aAACAg54bzYo475.png" class="lazyload"><br>卷积不仅限于对原始输入的卷积。蓝色方块是在原始输入上进行卷积操作，使用了6个filter得到了6个提取特征图。绿色方块还能对蓝色方块进行卷积操作，使用了10个filter得到了10个特征图。每一个filter的深度必须与上一层输入的深度相等。</p></blockquote><p><strong>更加直观理解卷积：</strong>   </p><blockquote><p><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFreggiATHJ7AAEstloH4_M280.png" class="lazyload"><br>以上图为例：<br>第一次卷积可以提取出低层次的特征。<br>第二次卷积可以提取出中层次的特征。<br>第三次卷积可以提取出高层次的特征。<br>特征是不断进行提取和压缩的，最终能得到比较高层次特征，简言之就是对原式特征一步又一步的浓缩，最终得到的特征更可靠。利用最后一层特征可以做各种任务：比如分类、回归等。</p></blockquote><h3 id="1-2-卷积的计算流程："><a href="#1-2-卷积的计算流程：" class="headerlink" title="1.2 卷积的计算流程："></a>1.2 <strong>卷积的计算流程：</strong></h3><blockquote><p><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFreggiAVJYtAAEv0s5MlhM898.png" class="lazyload"><br>左区域的三个大矩阵是原式图像的输入，RGB三个通道用三个矩阵表示，大小为7x7x3。<br>Filter W0表示1个filter助手，尺寸为3*3，深度为3（三个矩阵）；Filter W1也表示1个filter助手。因为卷积中我们用了2个filter，因此该卷积层结果的输出深度为2（绿色矩阵有2个）。<br>Bias b0是Filter W0的偏置项，Bias b1是Filter W1的偏置项。<br>OutPut是卷积后的输出，尺寸为3x3，深度为2。</p></blockquote><p><strong>计算过程：</strong></p><blockquote><p>输入是固定的，filter是指定的，因此计算就是如何得到绿色矩阵。<br>第一步，在输入矩阵上有一个和filter相同尺寸的滑窗，然后输入矩阵的在滑窗里的部分与filter矩阵对应位置相乘：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191118163546.png" class="lazyload"><br>第二步，将3个矩阵产生的结果求和，并加上偏置项，即0+2+0+1=3，因此就得到了输出矩阵的左上角的3：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFreggqAMAUIAAAur4t_qLQ857.png" class="lazyload"><br>第三步，让每一个filter都执行这样的操作，便可得到第一个元素：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFreggqAbb1DAABnl3M4AWY167.png" class="lazyload"><br>第四步，滑动窗口2个步长，重复之前步骤进行计算<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFreggqAUl7yAACokZwIXaM214.png" class="lazyload"><br>第五步，最终可以得到，在2个filter下，卷积后生成的深度为2的输出结果：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFreggqAPt54AAAfaKfUS8U979.png" class="lazyload"></p></blockquote><p><strong>思考：</strong></p><blockquote><ul><li>为什么每次滑动是2个格子？   </li></ul><p><em>滑动的步长叫stride记为S。S越小，提取的特征越多，但是S一般不取1，主要考虑时间效率的问题。S也不能太大，否则会漏掉图像上的信息。</em></p><ul><li>由于filter的边长大于S，会造成每次移动滑窗后有交集部分，交集部分意味着多次提取特征，尤其表现在图像的中间区域提取次数较多，边缘部分提取次数较少，怎么办？    </li></ul><p><em>一般方法是在图像外围加一圈0，细心的同学可能已经注意到了，在演示案例中已经加上这一圈0了，即+pad 1。 +pad n表示加n圈0.</em></p><ul><li>一次卷积后的输出特征图的尺寸是多少呢？<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFregguAJvoGAAATqFaF_Pk601.png" class="lazyload"><br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFreggyAVvcCAACg_W9CZgQ877.png" class="lazyload"><br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFreggyAWtpLAADAYQTV2bk952.png" class="lazyload"></li></ul></blockquote><p>==<strong>注意：在一层卷积操作里可以有多个filter，他们是尺寸必须相同。</strong>==</p><h3 id="1-3-卷积神经网络的组成："><a href="#1-3-卷积神经网络的组成：" class="headerlink" title="1.3 卷积神经网络的组成："></a>1.3 <strong>卷积神经网络的组成：</strong></h3><blockquote><p><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFreggyAFTuVAAEZZ59r0Cs173.png" class="lazyload"><br>卷积——激活——卷积——激活——池化——……——池化——全连接——分类或回归</p></blockquote><h3 id="1-4-前向传播与反向传播"><a href="#1-4-前向传播与反向传播" class="headerlink" title="1.4 前向传播与反向传播"></a>1.4 <strong>前向传播与反向传播</strong></h3><h4 id="1-4-1-前向传播"><a href="#1-4-1-前向传播" class="headerlink" title="1.4.1 前向传播"></a>1.4.1 前向传播</h4><blockquote><p><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFregg2ATy5SAAEQUsv9WF8019.png" class="lazyload">   </p></blockquote><h4 id="1-4-2-反向传播"><a href="#1-4-2-反向传播" class="headerlink" title="1.4.2 反向传播"></a>1.4.2 反向传播</h4><h4 id="1-4-3-训练一个CGGNet需要的内存开销"><a href="#1-4-3-训练一个CGGNet需要的内存开销" class="headerlink" title="1.4.3 训练一个CGGNet需要的内存开销"></a>1.4.3 训练一个CGGNet需要的内存开销</h4><blockquote><p><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFregg-AEan1AAMj4rvJat4359.png" class="lazyload"></p></blockquote><h3 id="1-2-残差网络-Residual-Network"><a href="#1-2-残差网络-Residual-Network" class="headerlink" title="1.2 残差网络(Residual Network)"></a>1.2 <a id="残差网络"><a href="https://baike.baidu.com/item/%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C/22701838?fr=aladdin" target="_blank" rel="noopener">残差网络</a></a>(Residual Network)</h3><p>论文出处：<a href="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article//pdf/Deep_Residual_Learning_for_Image_Recognition.pdf" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition.pdf</a></p><blockquote><p>残差网络是由来自Microsoft Research的4位学者提出的卷积神经网络，在2015年的ImageNet大规模视觉识别竞赛（ImageNet Large Scale Visual Recognition Challenge, ILSVRC）中获得了图像分类和物体识别的优胜。 残差网络的特点是容易优化，并且能够通过增加相当的深度来提高准确率。其内部的残差块使用了跳跃连接，缓解了在深度神经网络中增加深度带来的梯度消失问题</p></blockquote><blockquote><p>我们都知道增加网络的宽度和深度可以很好的提高网络的性能，深的网络一般都比浅的的网络效果好，比如说一个深的网络A和一个浅的网络B，那A的性能至少都能跟B一样，为什么呢？因为就算我们把B的网络参数全部迁移到A的前面几层，而A后面的层只是做一个等价的映射，就达到了B网络的一样的效果。一个比较好的例子就是VGG，该网络就是在AlexNex的基础上通过增加网络深度大幅度提高了网络性能。<br>对于原来的网络，如果简单地增加深度，会导致<a href="#梯度消失">梯度弥散</a>或<a href="#梯度爆炸">梯度爆炸</a>。对于该问题的解决方法是正则化初始化和中间的正则化层（Batch Normalization），这样的话可以训练几十层的网络。<br>虽然通过上述方法能够训练了，但是又会出现另一个问题，就是退化问题，网络层数增加，但是在训练集上的准确率却饱和甚至下降了。这个不能解释为overfitting，因为overfit应该表现为在训练集上表现更好才对。退化问题说明了深度网络不能很简单地被很好地优化。作者通过实验：通过浅层网络等同映射构造深层模型，结果深层模型并没有比浅层网络有等同或更低的错误率，推断退化问题可能是因为深层的网络并不是那么好训练，也就是求解器很难去利用多层网络拟合同等函数。</p></blockquote><h3 id="1-3-梯度消失"><a href="#1-3-梯度消失" class="headerlink" title="1.3 梯度消失"></a>1.3 <a id="梯度消失">梯度消失</a></h3><p><strong>概念</strong><br>在神经网络中，当前面隐藏层的学习速率低于后面隐藏层的学习速率，即随着隐藏层数目的增加，分类准确率反而下降了。这种现象叫做消失的梯度问题<br><strong>梯度消失产生的原因</strong>   </p><blockquote><p><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191119094513.png" class="lazyload"></p></blockquote><h3 id="1-4-梯度爆炸"><a href="#1-4-梯度爆炸" class="headerlink" title="1.4 梯度爆炸"></a>1.4 <a id="梯度爆炸">梯度爆炸</a></h3><p>梯度爆炸是梯度消失（梯度弥散）的对立面</p><h3 id="1-5-梯度消失和梯度爆炸的解决方案"><a href="#1-5-梯度消失和梯度爆炸的解决方案" class="headerlink" title="1.5 梯度消失和梯度爆炸的解决方案"></a>1.5 梯度消失和梯度爆炸的解决方案</h3><blockquote><p><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/39a9707f892b4d39811a2d3ad0c67ff2.jpg" class="lazyload"><br>举个例子，对于一个含有三层隐藏层的简单神经网络来说，当梯度消失发生时，接近于输出层的隐藏层由于其梯度相对正常，所以权值更新时也就相对正常，但是当越靠近输入层时，由于梯度消失现象，会导致靠近输入层的隐藏层权值更新缓慢或者更新停滞。这就导致在训练时，只等价于后面几层的浅层网络的学习。</p></blockquote><p>==<strong>梯度消失和梯度爆炸本质上是一样的，都是因为网络层数太深而引发的梯度反向传播中的连乘效应。</strong>==<br><strong>解决方案：</strong></p><ul><li>换用<a href="#ReLU函数">Relu</a>、<a href="#LeakyReLU函数">LeakyRelu</a>、<a href="#ELU函数">Elu</a>等激活函数</li><li><a href="#残差网络">ResNet残差结构</a></li><li>BatchNormalization BN本质上是解决传播过程中的梯度问题</li><li>LSTM结构 LSTM不太容易发生梯度消失，主要原因在于LSTM内部复杂的“门（gates）”，具体看LSTM基本原理解析</li><li>预训练加finetunning 此方法来自Hinton在06年发表的论文上，其基本思想是每次训练一层隐藏层节点，将上一层隐藏层的输出作为输入，而本层的输出作为下一层的输入，这就是逐层预训练。 训练完成后，再对整个网络进行“微调（fine-tunning）”。 此方法相当于是找全局最优，然后整合起来寻找全局最优，但是现在基本都是直接拿imagenet的预训练模型直接进行finetunning。</li><li>梯度剪切、正则<br>这个方案主要是针对梯度爆炸提出的，其思想是设值一个剪切阈值，如果更新梯度时，梯度超过了这个阈值，那么就将其强制限制在这个范围之内。这样可以防止<a href="#梯度爆炸">梯度爆炸</a>。<br>另一种防止梯度爆炸的手段是采用权重正则化，正则化主要是通过对网络权重做正则来限制过拟合，但是根据正则项在损失函数中的形式可以看出，如果发生梯度爆炸，那么权值的范数就会变的非常大，反过来，通过限制正则化项的大小，也可以在一定程度上限制梯度爆炸的发生。</li></ul><hr><h3 id="2-卷积神经网络的实现"><a href="#2-卷积神经网络的实现" class="headerlink" title="2 卷积神经网络的实现"></a>2 卷积神经网络的实现</h3><p>下面B站上的一个视频：  </p><iframe src="//player.bilibili.com/player.html?aid=24673328&cid=41481052&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="700" height="480"> </iframe>       <p>视频2：   </p><iframe src="//player.bilibili.com/player.html?aid=39049499&cid=68618808&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="700" height="480"> </iframe><p>可以参考一下该博客：<a href="https://www.cnblogs.com/further-further-further/p/10430073.html" target="_blank" rel="noopener">卷积神经网络(CNN)详解与代码实现</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 基础知识 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdown语法中锚点的使用方法</title>
      <link href="/archor-for-markdown/"/>
      <url>/archor-for-markdown/</url>
      
        <content type="html"><![CDATA[<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">- </span>[<span class="string">测试</span>](<span class="link">#测试</span>)</span><br><span class="line"><span class="section">### &lt;a id="测试"&gt;测试&lt;/a&gt;</span></span><br></pre></td></tr></table></figure><ul><li><a href="#测试">测试</a><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a><a id="测试">测试</a></h3></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>学习计算机视觉，你必须了解的基础概念</title>
      <link href="/cv-concept-you-must-know/"/>
      <url>/cv-concept-you-must-know/</url>
      
        <content type="html"><![CDATA[<h4 id="1-图像的高频和低频成分"><a href="#1-图像的高频和低频成分" class="headerlink" title="1 图像的高频和低频成分"></a>1 图像的高频和低频成分</h4><blockquote><p>形象一点说：亮度或灰度变化激烈的地方对应高频成分，如边缘；变化不大的地方对于低频成分，如大片色块区画个直方图，大块区域是低频，小块或离散的是高频把图像看成二维函数，变化剧烈的地方就对应高频，反之低频。<br>举个通俗易懂的例子：<br>一幅图象，你戴上眼镜，盯紧了一个地方看到的是高频分量<br>摘掉眼镜，眯起眼睛，模模糊糊看到的就是低频分量。<br>图像的高低频是对图像各个位置之间强度变化的一种度量方法.<br>低频分量:主要对整副图像的强度的综合度量.<br>高频分量:主要是对图像边缘和轮廓的度量.<br>如果一副图像的各个位置的强度大小相等,则图像只存在低频分量,从图像的频谱图上看,只有一个主峰,且位于频率为零的位置.<br>如果一副图像的各个位置的强度变化剧烈,则图像不仅存在低频分量,同时也存在多种高频分量,从图像的频谱上看,不仅有一个主峰,同时也存在多个旁峰.<br>以上的现象可以通过对傅里叶变换的公式分析得出.<br>以下所说的积分是对x进行的.<br>exp(-jwx)的数值变化是均匀的,如果对exp(-jwx)进行积分,则积分值为零.如果对exp(-jwx)乘以一个加权函数f(x),则在对f(x)exp(-jwx)进行积分,积分值不一定为零.如果exp(-jwx)的取值为1时,则对f(x)exp(-jwx)积分,既为对f(x)积分,此时f(x)exp(-jwx)最大,既频谱中的主峰.如果f(x) 是常数则, 除w=0处f(x)exp(-jwx)的积分不为零外,在w不为零的其它处,f(x)exp(-jwx)的积分都为零.</p></blockquote><hr><h4 id="2-低通滤波"><a href="#2-低通滤波" class="headerlink" title="2 低通滤波"></a>2 <a href="https://baike.baidu.com/item/%E4%BD%8E%E9%80%9A%E6%BB%A4%E6%B3%A2/3506429?fr=aladdin" target="_blank" rel="noopener">低通滤波</a></h4><blockquote><p>低通滤波(Low-pass filter) 是一种过滤方式，规则为低频信号能正常通过，而超过设定临界值的高频信号则被阻隔、减弱。但是阻隔、减弱的幅度则会依据不同的频率以及不同的滤波程序（目的）而改变。它有的时候也被叫做高频去除过滤（high-cut filter）或者最高去除过滤（treble-cut filter)。低通过滤是高通过滤的对立。</p></blockquote><hr><h4 id="3-bounding-box"><a href="#3-bounding-box" class="headerlink" title="3 bounding-box"></a>3 <a href="https://blog.csdn.net/love1055259415/article/details/80041936" target="_blank" rel="noopener">bounding-box</a></h4><blockquote><p>如图所示，绿色的框为飞机的Ground Truth，红色的框是提取的Region Proposal。那么即便红色的框被分类器识别为飞机，但是由于红色的框定位不准(IoU&lt;0.5)，那么这张图相当于没有正确的检测出飞机。如果我们能对红色的框进行微调，使得经过微调后的窗口跟Ground Truth更接近，这样岂不是定位会更准确。确实，Bounding-box regression 就是用来微调这个窗口的。<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20161020131820060.png" class="lazyload"></p></blockquote><hr><h4 id="4-R-CNN"><a href="#4-R-CNN" class="headerlink" title="4 R-CNN"></a>4 <a href="https://blog.csdn.net/ture_dream/article/details/52896452" target="_blank" rel="noopener">R-CNN</a></h4><p>R-CNN的论文原文是《<a href="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pdf/Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation.pdf" target="_blank" rel="noopener">Rich feature hierarchies for accurate object detection and semantic segmentation</a>》全是英文，有兴趣的可以读一读<br>R-CNN是计算机视觉中目标检测算法的鼻祖，很多的目标检测算法都是基于R-CNN的改进，这里有一篇<a href="https://blog.csdn.net/ture_dream/article/details/52896452" target="_blank" rel="noopener">很好的博客</a>，介绍了R-CNN,Fast R-CNN,Faster R-CNN的一个工作原理<br><a href="https://space.bilibili.com/209599371?from=search&seid=7888318736309109130" target="_blank" rel="noopener">B站目标检测大牛</a><br><strong>关于R-CNN的一个入门视频</strong></p><iframe src="//player.bilibili.com/player.html?aid=24795835&cid=41764245&page=2" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="720" height="480"> </iframe><p><a id="R-CNN的工作原理"><strong>R-CNN的工作原理：</strong></a>   </p><blockquote><p>R-CNN利用<strong>网络</strong>将特征提取和特征分类合并到一起，大大提升了特征的提取效率。但是无论是<em>传统方式</em>还是R-CNN，<strong>目标检测和目标识别的最大区别就是需要提取候选区域</strong>（region proposals） R-CNN采用<strong>选择性搜索（selective search）</strong>算法，又称区域合并算法，selective search会将对图片暴力生成多个候选区域   </p></blockquote><p>R-CNN算法的计算过程：   </p><blockquote><ul><li>首先输入图像会被分为R个初始候选集，</li><li>然后通过贪心策略去计算相邻候选集之前的相似度，通过相似度的大小去合并候选集，直到产生目标个数的候选集,</li><li>候选集的相似度计算有多种方式，有颜色、纹理、而枳和吻合相似度计算。</li><li><strong>最后生成的L个Region Proposal与CNN相结合，这就是R-CNN名字的由来</strong>,    </li></ul></blockquote><p><em>R-CNN作者证明了在当前任务下SVM的分类效果要比神经网络分类器好。最后每个SNM分类器都会得到图像对于该类别的得分和置信度，置信度最高的类别为改图像区域对应的预测类别</em></p><p><a id="总结一下R-CNN存在的两个问题"><strong>总结一下R-CNN存在的两个问题：</strong></a></p><ul><li>R-CNN在生成了候选区域后，需要对每个区域进行统一尺寸的压缩或放大，当候选集的长与宽差别较大时强行压缩至比例为1:1时会使图像产生变形和丢失图像的原始特征</li><li>R-CNN生成了多个候选集后需要全部输入到CNN中，当生成了2000个候选集时，就需要对图片进行2000次单模型特征提取，这无疑是效率低下的</li></ul><p>针对上述的两个问题，Kaiming He等人提出了SSPNet（空间金字塔池化网络）来解决。<a href="https://crazyjums.github.io/2019/11/21/SSPNet/" target="_blank" rel="noopener">详细了解什么是SSPNet</a></p><hr><h4 id="5-IoU"><a href="#5-IoU" class="headerlink" title="5 IoU"></a>5 <a href="https://blog.csdn.net/u014061630/article/details/82818112" target="_blank" rel="noopener">IoU</a></h4><blockquote><p>IoU 的全称为交并比（Intersection over Union），通过这个名称我们大概可以猜到 IoU 的计算方法。IoU 计算的是 “预测的边框” 和 “真实的边框” 的交集和并集的比值。<br><img alt="IoU计算公式" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20180922220708895.png" class="lazyload"></p></blockquote><hr><h4 id="6-卷积"><a href="#6-卷积" class="headerlink" title="6 卷积"></a>6 卷积</h4><p>卷积在图像识别中的概念是提取一幅图像的特征，通常对一幅图像进行卷积会有一个卷积核，该卷积核是一个正方形矩阵。一般是奇数矩阵，这样做的目的是为了卷积核总是有一个中心。大部分情况使用的3x3或者5x5等</p><p><a href="https://crazyjums.github.io/2019/11/21/cnn/" target="_blank" rel="noopener">详细了解什么是卷积神经网络</a></p><hr><h4 id="7-池化-下采样（pooling）"><a href="#7-池化-下采样（pooling）" class="headerlink" title="7 池化/下采样（pooling）"></a>7 池化/下采样（pooling）</h4><p>上面介绍了卷积操作，卷积的目的是提取一幅图像的特征，也就是边缘部分。但是一幅图像往往很大，有的甚至几百万的像素，每一个像素对应一个参数，那就意味着会有几百万个参数，这对于计算机的内存处理来讲是一个很大的问题。那么为了减少参数，提升计算机的运行效率，这里提出一个pooling的概念，也就是较少一部分对图像影响较小的参数，从而使得计算机的运行效率能够提升。池化操作一般在卷积之后。  </p><blockquote><p><img alt="池化操作" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/pIYBAFreggyACO9FAABorvOb-GE402.png" class="lazyload"><br>如上图所示，池化就是对特征图进行特征压缩，池化也叫做下采样。选择原来某个区域的max或mean代替那个区域，整体就浓缩了</p></blockquote><p>pooling有很多种，这里<a href="https://blog.csdn.net/danieljianfeng/article/details/42433475" target="_blank" rel="noopener">介绍几种</a>：   </p><ul><li>一般池化（general pooling）</li><li>重叠池化（OverlappingPooling）</li><li>空金字塔池化（Spatial Pyramid Pooling）<br>还有一些池化，这篇<a href="https://blog.csdn.net/nwu_NBL/article/details/80901427" target="_blank" rel="noopener">博客</a>有介绍</li></ul><p><strong>pooling layer视频介绍</strong></p><iframe src="//player.bilibili.com/player.html?aid=16022575&cid=26141211&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="720" height="480"> </iframe><h5 id="7-1-General-pooling"><a href="#7-1-General-pooling" class="headerlink" title="7.1 General pooling"></a>7.1 General pooling</h5><blockquote><p>池化作用于图像中不重合的区域（这与卷积操作不同），过程如下图<br><img alt="一般池化" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/Pooling_schematic.gif" class="lazyload"><br>我们定义池化窗口的大小为sizeX，即下图中红色正方形的边长，定义两个相邻池化窗口的水平位移/竖直位移为stride。一般池化由于每一池化窗口都是不重复的，所以sizeX=stride。<br><img alt="步长等于尺寸" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20150105213214237.png" class="lazyload">   </p></blockquote><blockquote><p>最常见的池化操作为平均池化mean pooling和最大池化max pooling：   </p><ul><li>平均池化：计算图像区域的平均值作为该区域池化后的值。   </li><li>最大池化：选图像区域的最大值作为该区域池化后的值。</li></ul></blockquote><h5 id="7-2-Overlapping-pooling"><a href="#7-2-Overlapping-pooling" class="headerlink" title="7.2 Overlapping pooling"></a>7.2 Overlapping pooling</h5><blockquote><p>重叠池化正如其名字所说的，相邻池化窗口之间会有重叠区域，此时sizeX&gt;stride</p></blockquote><h5 id="7-3-Spatial-Pyramid-Pooling"><a href="#7-3-Spatial-Pyramid-Pooling" class="headerlink" title="7.3 Spatial Pyramid Pooling"></a>7.3 Spatial Pyramid Pooling</h5><blockquote><p>空间金字塔池化可以把任何尺度的图像的卷积特征转化成相同维度，这不仅可以让CNN处理任意尺度的图像，还能避免cropping和warping操作，导致一些信息的丢失，具有非常重要的意义</p></blockquote><blockquote><p>一般的CNN都需要输入图像的大小是固定的，这是因为全连接层的输入需要固定输入维度，但在卷积操作是没有对图像尺度有限制，所有作者提出了空间金字塔池化，先让图像进行卷积操作，然后转化成维度相同的特征输入到全连接层，这个可以把CNN扩展到任意大小的图像。<br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20150105213450046.png" class="lazyload"><br>空间金字塔池化的思想来自于Spatial Pyramid Model，它一个pooling变成了多个scale的pooling。用不同大小池化窗口作用于卷积特征，我们可以得到1X1,2X2,4X4的池化结果，由于conv5中共有256个过滤器，所以得到1个256维的特征，4个256个特征，以及16个256维的特征，然后把这21个256维特征链接起来输入全连接层，通过这种方式把不同大小的图像转化成相同维度的特征。<br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20150105213522578.png" class="lazyload">   </p></blockquote><h5 id="7-4-Rol-pooling"><a href="#7-4-Rol-pooling" class="headerlink" title="7.4 Rol pooling"></a>7.4 <a href="https://blog.csdn.net/auto1993/article/details/78514071" target="_blank" rel="noopener">Rol pooling</a></h5><p>Rol(Region of Interest)是图像中我们感兴趣的区域的意思，也可以理解为region proposal（候选区域）。<br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191118150551.png" class="lazyload"><br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191118150631.png" class="lazyload"><br>ROI pooling总结：<br>（1）用于目标检测任务；<br>（2）允许我们对CNN中的feature map进行reuse；<br>（3）可以显著加速training和testing速度；<br>（4）允许end-to-end的形式训练目标检测系统。   </p><hr><h4 id="8-RPN（Region-Proposal-Network）"><a href="#8-RPN（Region-Proposal-Network）" class="headerlink" title="8 RPN（Region Proposal Network）"></a>8 <a href="https://blog.csdn.net/ture_dream/article/details/52896452" target="_blank" rel="noopener">RPN</a>（Region Proposal Network）</h4><blockquote><p>目前最先进的目标检测网络需要先用区域建议(region proposal)算法推测目标位置，像SPPnet[7]和Fast R-CNN[5]这些网络已经减少了检测网络的运行时间，这时计算区域建议(region proposal)就成了瓶颈问题。本文中，我们介绍一种区域建议网络（Region Proposal Network, RPN），<strong>它和检测网络共享全图的卷积特征(共享卷积核)</strong>，使得区域建议几乎不花时间。<strong>RPN是一个全卷积网络</strong>，在每个位置同时预测目标边界和objectness得分。RPN是端到端训练的，生成高质量区域建议框，用于Fast R-CNN来检测。通过一种简单的交替运行优化方法，RPN和Fast R-CNN可以在训练时共享卷积特征。对于非常深的VGG-16模型[19]，我们的检测系统在GPU上的帧率为5fps（包含所有步骤），在PASCAL VOC 2007和PASCAL VOC 2012上实现了最高的目标检测准确率（2007是73.2%mAP，2012是70.4%mAP），每个图像用了300个建议框。<a href="https://github.com/ShaoqingRen/faster_rcnn" target="_blank" rel="noopener">代码</a>已公开</p></blockquote><hr><h4 id="9-梯度下降"><a href="#9-梯度下降" class="headerlink" title="9 梯度下降"></a>9 <a id="梯度下降"><a href="https://www.jianshu.com/p/c7e642877b0e" target="_blank" rel="noopener">梯度下降</a></a></h4><blockquote><p>百度百科解释：梯度下降是迭代法的一种,可以用于求解最小二乘问题(线性和非线性都可以)。在求解机器学习算法的模型参数，即无约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一，另一种常用的方法是最小二乘法。在求解损失函数的最小值时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数和模型参数值。反过来，如果我们需要求解损失函数的最大值，这时就需要用梯度上升法来迭代了。在机器学习中，基于基本的梯度下降法发展了两种梯度下降方法，分别为随机梯度下降法和批量梯度下降法</p></blockquote><p><a href="https://crazyjums.github.io/2019/11/21/gradient-descent" target="_blank" rel="noopener">详细了解什么是梯度下降</a></p><hr><h4 id="10-损失函数"><a href="#10-损失函数" class="headerlink" title="10 损失函数"></a>10 <a href="https://blog.csdn.net/qq_24753293/article/details/78788844" target="_blank" rel="noopener">损失函数</a></h4><blockquote><p>损失函数（loss function）或代价函数（cost function）是将随机事件或其有关随机变量的取值映射为非负实数以表示该随机事件的“风险”或“损失”的函数。在应用中，损失函数通常作为学习准则与优化问题相联系，即通过最小化损失函数求解和评估模型。</p></blockquote><p><strong>损失函数的作用：衡量模型模型预测的好坏</strong></p><blockquote><p>比如你做一个线性回归，实际值和你的 预测值肯定会有误差，那么我们找到一个函数表达这个误差就是损失函数  </p></blockquote><p>损失函数与鲁棒性的关系：   </p><blockquote><p>损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。</p></blockquote><p>常用的损失函数：<br>(1) 0-1损失函数(0-1 lossfunction):<br>L(Y,f(X))={1,0,Y≠f(X)Y=f(X)<br>(2)平方损失函数(quadraticloss function)<br>L(Y,f(X))=(Y−f(X))2<br>(3)绝对损失函数(absoluteloss function)<br>L(Y,f(X))=|Y−f(X)|<br>(4)对数损失函数(logarithmicloss function)或对数似然损失函数(log-likelihood loss function)<br>L(Y,P(Y|X))=−logP(Y|X)</p><hr><h4 id="11-激活函数"><a href="#11-激活函数" class="headerlink" title="11 激活函数"></a>11 <a href="https://baike.baidu.com/item/激活函数/2520792?fr=aladdin" target="_blank" rel="noopener">激活函数</a></h4><blockquote><p>实际上．激活函数也是在模拟神经元的特点。人体的祌经元不是接收到输入就会全部输出的，是当输入达到一定的阈值后，线性或非线性的将输入转化成输出，这也就是激活函数的原理,在人工神经网络中，<a href="https://blog.csdn.net/edogawachia/article/details/80043673" target="_blank" rel="noopener">激活函数</a>就在神经元的连接形式中，以非线性的映射关系而存在，是神经网络能表达复杂非线性关系的关键所在。</p></blockquote><h5 id="11-1-sigmoid函数"><a href="#11-1-sigmoid函数" class="headerlink" title="11.1 sigmoid函数"></a>11.1 <a href="https://www.jianshu.com/p/506595ec4b58" target="_blank" rel="noopener">sigmoid函数</a></h5><blockquote><p>Sigmoid函数是一个在生物学中常见的S型函数，也称为S型生长曲线。 在信息科学中，由于其单增以及反函数单增等性质，Sigmoid函数常被用作神经网络的激活函数，将变量映射到0,1之间<br>sigmoid公式如下：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/o_191114110431111.png" class="lazyload"><br>sigmoid函数图像如下：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/c9fcc3cec3fdfc03f23fbf16d73f8794a5c226dc.jpg" class="lazyload"></p></blockquote><p>sigmoid函数的Python实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line"> </span><br><span class="line">sigmoid_inputs = np.arange(<span class="number">-10</span>,<span class="number">10</span>,<span class="number">0.1</span>)</span><br><span class="line">sigmoid_outputs = sigmoid(sigmoid_inputs)</span><br><span class="line">print(<span class="string">"Sigmoid Function Input :: &#123;&#125;"</span>.format(sigmoid_inputs))</span><br><span class="line">print(<span class="string">"Sigmoid Function Output :: &#123;&#125;"</span>.format(sigmoid_outputs))</span><br><span class="line"> </span><br><span class="line">plt.plot(sigmoid_inputs,sigmoid_outputs)</span><br><span class="line">plt.xlabel(<span class="string">"Sigmoid Inputs"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Sigmoid Outputs"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h5 id="11-2-ReLU函数"><a href="#11-2-ReLU函数" class="headerlink" title="11.2 ReLU函数"></a>11.2 <a id="ReLU函数"><a href="https://www.cnblogs.com/adong7639/p/9213038.html" target="_blank" rel="noopener">ReLU函数</a></a></h5><blockquote><p>ReLU函数：为了避免sigmoid函数梯度趋于０产生的梯度饱和问题，线性整流函数（Rectified Linear Unit, ReLU),被提出并在卷积神经网络中取得了不错的效果。<br>当输入取值小于0时ReLU不会被激活，特别是在后向传播计算中梯度很容易变为0，这是ReLU函数本身存在的硬饱和，又会带来梯度消失的问题。而且ReLU函数的输出值是不存在负数的，这代表了ReLU也不是以0为均值的函数<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/d788d43f8794a4c25b5e4dd902f41bd5ac6e39c6.jpg" class="lazyload"><br>CNN中常用。对正数原样输出，负数直接置零。在正数不饱和，在负数硬饱和。<strong>ReLU计算上比sigmoid或者tanh更省计算量</strong>，因为不用exp，因而收敛较快。但是还是非zero-centered。<br>ReLU在负数区域被kill的现象叫做dead ReLU，这样的情况下，有人通过初始化的时候用一个稍微大于零的数比如0.01来初始化神经元，从而使得ReLU更偏向于激活而不是死掉，但是这个方法是否有效有争议。</p></blockquote><h5 id="11-3-LeakyReLU函数"><a href="#11-3-LeakyReLU函数" class="headerlink" title="11.3 LeakyReLU函数"></a>11.3 <a id="LeakyReLU函数">LeakyReLU函数</a></h5><blockquote><p>为了解决上述的dead ReLU现象。这里选择一个数，让负数区域不在饱和死掉。这里的斜率都是确定的。<img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/dfbsdfgsdfg.png" class="lazyload"></p></blockquote><h5 id="11-4-PReLU函数"><a href="#11-4-PReLU函数" class="headerlink" title="11.4 PReLU函数"></a>11.4 <a id="PReLU函数">PReLU函数</a></h5><blockquote><p>PReLU(Parametric Rectified Linear Unit)顾名思义：带参数的ReLU,<a href="https://blog.csdn.net/shuzfan/article/details/51345832#prelu%E6%BF%80%E6%B4%BB" target="_blank" rel="noopener">PReLU函数</a>是为了解决ReLU的硬饱和问题产生的激活函数，在LeakyReLU函数中，斜率是固定的，这里的PRelu函数的斜率a是不固定的一个值，这个值可以在运算过程中不算学习改变原来的值。<strong>计算量不是很大，因为不用计算exp</strong><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20160508143448263.png" class="lazyload"></p></blockquote><h5 id="11-5-ELU函数"><a href="#11-5-ELU函数" class="headerlink" title="11.5 ELU函数"></a>11.5 <a id="ELU函数">ELU函数</a></h5><blockquote><p>ELU函数是Sigmoid函数和ReLU函数的结合体，它的提出主要是为了解决ReLUＵ函数输入负值时陷入卡死的问题<img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20180422215147575.png" class="lazyload"><br>具有ReLU的优势，且输出均值接近零，实际上PReLU和LeakyReLU都有这一优点。有负数饱和区域，从而对噪声有一些鲁棒性。可以看做是介于ReLU和LeakyReLU之间的一个东西。当然，这个函数也需要计算exp，从而<strong>计算量上更大一些</strong>。<br>ELU的优点：<br>和PReLU一样，ELU也引入了可学习的斜率a，使得激活函数在负半段是存在输出值的。但是和PReLU不一样的是，当输入值小于０时ELU的结构为非线性单元，这使得ELU具有良好的鲁棒性和抗干扰能力，但是还是具有一定程度的软饱和性</p></blockquote><h5 id="11-6-tan-h-函数"><a href="#11-6-tan-h-函数" class="headerlink" title="11.6 tan(h)函数"></a>11.6 tan(h)函数</h5><blockquote><p>tanh是双曲函数中的一个，tanh()为双曲正切。在数学中，双曲正切“tanh”是由双曲正弦和双曲余弦这两种基本双曲函数推导而来。<br>tan(h)函数的公式为：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/5366d0160924ab188eed6a943dfae6cd7a890b9d.png" class="lazyload"><br>tan(h)函数的图像为：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/29381f30e924b8994bb77cac64061d950b7bf69f.png" class="lazyload"></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 基础知识 </tag>
            
            <tag> 概念解释 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手把手教你玩转hexo个人博客，自定义主题，博客发布，GitHub部署</title>
      <link href="/conclusion-hexo-1/"/>
      <url>/conclusion-hexo-1/</url>
      
        <content type="html"><![CDATA[<h3 id="1-总结"><a href="#1-总结" class="headerlink" title="1.总结"></a>1.总结</h3><p>最近几天一直在玩<a href="https://hexo.io/" target="_blank" rel="noopener">hexo</a>个人博客，因为一直就想弄一个这样的博客平台，一个是为了兴趣，还有一个就是为了找工作的时候能够让面试官觉得自己很牛逼（这里涉及到社会学知识点，下次有机会我们再谈），所以就花了一点时间，弄了一下，也发现了一些坑，这里和大家一起分享一下。</p><h3 id="2-开始搭建hexo平台"><a href="#2-开始搭建hexo平台" class="headerlink" title="2.开始搭建hexo平台"></a>2.开始搭建hexo平台</h3><h4 id="2-1-前提"><a href="#2-1-前提" class="headerlink" title="2.1 前提"></a>2.1 前提</h4><p>因为hexo是一个基于node.js开发的一个博客平台，可以将Markdown文件也就是以.md为扩展名的文件生成为静态文件，然后在自动将其部署到整个系统的其他固定页面（比如：tags,archives等）中。我们还可以将其部署到GitHub上，这样就实现了可以通过互联网访问的目的了，我们最终的目的也就是通过互联网访问。</p><ul><li>安装<a href="https://git-scm.com/downloads" target="_blank" rel="noopener">git</a> 建议大家的所有操作都在git控制台进行操作，git控制台的类似Linux的命令，但不是所有Linux命令都支持，基本命令都已使用，真的很好用。<strong>力荐</strong></li><li>安装<a href="https://nodejs.org/en/" target="_blank" rel="noopener">node.js</a><br>大家安装提示进行安装就可以，安装完成之后，我们才可以进行下面的操作</li></ul><h4 id="2-2-通过npm-node-package-manager-安装hexo"><a href="#2-2-通过npm-node-package-manager-安装hexo" class="headerlink" title="2.2 通过npm(node package manager)安装hexo"></a>2.2 通过npm(node package manager)安装hexo</h4><blockquote><p>npm install -g hexo-cli或者npm i -g hexo-cli或者npm<br>hexo可以支持代码简写：<br>hexo generate = hexo g  编译网页文件<br>hexo deploy = hexo d 部署到GitHub等平台<br>hexo server/start = hexo s 开启本地预览服务，访问地址：<a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a><br>这里是几个hexo主要用到的命令，其他的可以通过命令hexo –help查看</p></blockquote><h4 id="2-3-生成自己的hexo博客"><a href="#2-3-生成自己的hexo博客" class="headerlink" title="2.3 生成自己的hexo博客"></a>2.3 生成自己的hexo博客</h4><p>随便找一个目录，存放我们的个人博客所有的源代码，为了后期维护，大家尽量找一个空间大一些的盘进行文件存放<br>第一步：</p><blockquote><p>hexo init <folder> or hexo i <folder>  </folder></folder></p></blockquote><p><folder>是你的存放个人博客文件的文件夹的名字<br>比如：hexo i hexo-blog  那么系统会自动生成一个名为hexo-blog的文件夹，并且会配有相应的文件目录结构，如下所示：<br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article//20191118102100.png" class="lazyload">     </folder></p><p>第二步：</p><blockquote><p>hexo generate or hexo g  生成编译之后的静态网页文件</p></blockquote><p>第三步：</p><blockquote><p>hexo start/server or hexo s    </p></blockquote><p>第二步和第三步可以通过下面的一条语句执行：</p><blockquote><p>hexo s -g //但是这样做的话，是不会生成public/文件夹的，该文件夹是存放编译完之后的所有静态网页的文件夹</p></blockquote><p>第四步：<br>在浏览器中输入<a href="http://localhost:4000地址进行访问，访问效果如下：" target="_blank" rel="noopener">http://localhost:4000地址进行访问，访问效果如下：</a><br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article//20191118102814.png" class="lazyload">   </p><h4 id="2-4-修改hexo主题"><a href="#2-4-修改hexo主题" class="headerlink" title="2.4 修改hexo主题"></a>2.4 修改hexo主题</h4><p>通过git控制台，cd到我们的博客目录下，然后在<a href="https://hexo.io/themes/" target="_blank" rel="noopener">hexo themes</a>网站上找到自己喜欢的主题，使用git clone命令将其克隆到自己的博客目录下即可。这里以我的主题为例，我用的是基于<a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener">melody</a>的<a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener">butterfly</a><br>通过下面的命令克隆主题，该主题需要一个渲染插件，还得安装一下下面的插件，否则不会生效。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/Molunerfinn/hexo-theme-melody.git themes/melody</span><br><span class="line">$ npm install hexo-renderer-jade hexo-renderer-stylus</span><br></pre></td></tr></table></figure><p>如果想修改该主题的参数，进行自定义的话，可以参开这个<a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener">文档</a></p><h4 id="2-5-发布博客"><a href="#2-5-发布博客" class="headerlink" title="2.5 发布博客"></a>2.5 发布博客</h4><p>发布post博客，有如下命令：</p><blockquote><p>hexo new “title” 如：hexo new “my first post”</p></blockquote><p>创建完的post博客文件格式如下：<img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191118104655.png" class="lazyload"></p><p>下面这条命令是发布一个网页，不会在主页或者archives中显示的，类似于【主页】这么一个静态网页</p><blockquote><p>hexo new page “my first page” 如：hexo new page “tags”</p></blockquote><p>hexo中只有主页和archives是已经创建好的，其他的都是需要我们手动创建的，用的就是这条命令，创建完的文件如下：<img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191118104450.png" class="lazyload"></p><p>创建完post博客之后，我们通过Markdown编辑器编辑好，我们就可以发布到GitHub上，发布命令：</p><blockquote><p>hexo deploy or hexo d</p></blockquote><h5 id="2-5-1-如何写博客"><a href="#2-5-1-如何写博客" class="headerlink" title="2.5.1 如何写博客"></a>2.5.1 如何写博客</h5><p>博客的front master也就是上面的固定格式，我们可以通过一些参数进行修改，这里附上<a href="https://hexo.io/zh-cn/docs/writing" target="_blank" rel="noopener">官网</a>的一些修改意见。   </p><ul><li>tags: 标签修改</li><li>top_img: 置顶图片</li><li>cover: 博客封面</li><li>categories: 分类，我这里一直显现不了，所以大家看看你们的情况吧，书写规范类似tags</li></ul><h4 id="2-6-部署到GitHub"><a href="#2-6-部署到GitHub" class="headerlink" title="2.6 部署到GitHub"></a>2.6 部署到GitHub</h4><p>修改博客根目录下的_config.yml文件（<strong>注意：这里不是themes目录下的_config.yml文件</strong>）<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191118105240.png" class="lazyload"><br>安装上面的形式配置完自己的GitHub参数即可</p><ul><li>type: 这里写git 因为是通过GitHub部署</li><li>repo: 仓库的意思，写自己存放博客的仓库，必须是page版的</li><li>branch: 分支，一般是master，如果有变动的话，写自己的博客文件分支</li></ul><h3 id="3-hexo博客美化"><a href="#3-hexo博客美化" class="headerlink" title="3.hexo博客美化"></a>3.hexo博客美化</h3><h4 id="3-1-为hexo博客添加本地搜索引擎"><a href="#3-1-为hexo博客添加本地搜索引擎" class="headerlink" title="3.1 为hexo博客添加本地搜索引擎"></a>3.1 <a href="https://crazyjums.github.io/2019/11/16/hexo-search-function/" target="_blank" rel="noopener">为hexo博客添加本地搜索引擎</a></h4>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> 总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>硕士论文笔记</title>
      <link href="/note-master-1/"/>
      <url>/note-master-1/</url>
      
        <content type="html"><![CDATA[<h3 id="1-《智能交通图像识别系统的研究》from"><a href="#1-《智能交通图像识别系统的研究》from" class="headerlink" title="1.《智能交通图像识别系统的研究》from"></a>1.《智能交通图像识别系统的研究》<a href="https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD9904&filename=2003041026.nh&uid=WEEvREdxOWJmbC9oM1NjYkZCbDdrNXcwaGROd1Z6Qmo3emF5S1A3SnV3QjE=$R1yZ0H6jyaa0en3RxVUd8df-oHi7XMMDo7mtKT6mSmEvTuk11l2gFA!!&v=MzA1NzVUcldNMUZyQ1VSTE9lWitWdUZpSGhVN3ZCVjEyN0hiTzhIOUhPcVpFYlBJUjhlWDFMdXhZUzdEaDFUM3E=" target="_blank" rel="noopener">from</a></h3><h4 id="1-1人工神经网络进行字符识别"><a href="#1-1人工神经网络进行字符识别" class="headerlink" title="1.1人工神经网络进行字符识别"></a>1.1人工神经网络进行字符识别</h4><blockquote><p>主要有两种方法:<strong>一种方法</strong>是<strong>先对待识别字符进行特征提取</strong>,然后用所获得的特征来训练神经网络分类器。这种网络的识别效果与字符特征的提取有关,而字符的特征提取往往比较耗时。因此,字符特征的提取就成为研究的关键。文献四中使用由6个多层感知器构成的神经网络来进行车牌字符识别,在特征提取上提出二值线性变换方法以减少输入特征向量,另外改善网络结构以提高识别速度。另<strong>一种方法</strong>则充分利用神经网络的特点,直接把待处理图像输入网络,由网络自动实现特征提取直至识别。这种网络互连较多、待处理信息量大。</p></blockquote><p>神经网络在并行非线性处理及大容量计算方面存在着巨大潜力,<br>且神经元状态是二值的</p><h4 id="1-2图像预处理"><a href="#1-2图像预处理" class="headerlink" title="1.2图像预处理"></a>1.2图像预处理</h4><blockquote><p>预处理相当于对获取的原始图像数据进行整理加工、去伪存真的过程。由于原始图像信号中存在着许多噪声和畸变,一般要进行<strong>滤波、平滑、增强、复原、提取边缘、图像分割</strong>等预处理,以便提高图像质量,并<strong>为下一步特征提取提供必要的基础</strong>。</p></blockquote><p><strong>决策分类</strong><br>根据具体问题的性质,提出一个反映分类好坏的标准,从而找到最符合这一标准的分类方一法。  从数学观点来看,决策分类就是找出决策函数(边界函数)。</p><h5 id="1-2-1灰度图化"><a href="#1-2-1灰度图化" class="headerlink" title="1.2.1灰度图化"></a>1.2.1<a href="https://baike.baidu.com/item/%E7%81%B0%E5%BA%A6%E5%8C%96/3206969?fr=aladdin" target="_blank" rel="noopener">灰度图化</a></h5><blockquote><p>灰度化，在RGB模型中，如果R=G=B时，则彩色表示一种灰度颜色，其中R=G=B的值叫灰度值，因此，灰度图像每个像素只需一个字节存放灰度值（又称强度值、亮度值），灰度范围为0-255。一般有分量法<br>最大值法平均值法加权平均法四种方法对彩色图像进行灰度化。</p></blockquote><p><a href="https://blog.csdn.net/saltriver/article/details/79677116" target="_blank" rel="noopener">RGB图像如何转换成灰度图像</a></p><h6 id="1-2-1-1平均法"><a href="#1-2-1-1平均法" class="headerlink" title="1.2.1.1平均法"></a>1.2.1.1平均法</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">lenna = cv2.imread(<span class="string">"lenna.png"</span>)</span><br><span class="line">row, col, channel = lenna.shape</span><br><span class="line">lenna_gray = np.zeros((row, col))</span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> range(row):</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(col):</span><br><span class="line">        lenna_gray[r, l] = <span class="number">1</span> / <span class="number">3</span> * lenna[r, l, <span class="number">0</span>] + <span class="number">1</span> / <span class="number">3</span> * lenna[r, l, <span class="number">1</span>] + <span class="number">1</span> / <span class="number">3</span> * lenna[r, l, <span class="number">2</span>]</span><br><span class="line">cv2.imshow(<span class="string">"lenna_gray"</span>, lenna_gray.astype(<span class="string">"uint8"</span>))</span><br><span class="line">cv2.waitKey()</span><br></pre></td></tr></table></figure><h6 id="1-2-1-2最大最小平均法"><a href="#1-2-1-2最大最小平均法" class="headerlink" title="1.2.1.2最大最小平均法"></a>1.2.1.2最大最小平均法</h6><blockquote><p>取同一个像素位置的RGB中亮度最大的和最小的进行平均</p></blockquote><h6 id="1-2-1-3加权平均法"><a href="#1-2-1-3加权平均法" class="headerlink" title="1.2.1.3加权平均法"></a>1.2.1.3加权平均法</h6><blockquote><p>I(x,y) = 0.3 * I_R(x,y) +0.59 * I_G(x,y)+ 0.11 * I_B(x,y)<br>这是最流行的方法。几个加权系数0.3,0.59,0.11是根据人的亮度感知系统调节出来的参数，是个广泛使用的标准化参数。</p></blockquote><h6 id="1-2-1-4二值图像"><a href="#1-2-1-4二值图像" class="headerlink" title="1.2.1.4二值图像"></a>1.2.1.4二值图像</h6><blockquote><p>图像二值化（ Image Binarization）就是将图像上的像素点的灰度值设置为0或255，也就是将整个图像呈现出明显的黑白效果的过程。<br>在数字图像处理中，二值图像占有非常重要的地位，图像的二值化使图像中数据量大为减少，从而能凸显出目标的轮廓。</p></blockquote><h6 id="1-2-1-4反转图像"><a href="#1-2-1-4反转图像" class="headerlink" title="1.2.1.4反转图像"></a>1.2.1.4反转图像</h6><blockquote><p>反转图像也很简单：s = 255-r。反转图像特别适用于<strong>增强暗色图像中的白色或灰色</strong>细节</p></blockquote><h5 id="1-2-2中值滤波"><a href="#1-2-2中值滤波" class="headerlink" title="1.2.2中值滤波"></a>1.2.2中值滤波</h5><blockquote><p><strong>中值滤波法</strong>是一种非线性平滑技术，它将每一像素点的灰度值设置为该点某邻域窗口内的所有像素点灰度值的中值.<br>中值滤波是基于排序统计理论的一种能有效抑制噪声的非线性信号处理技术，中值滤波的基本原理是把数字图像或数字序列中一点的值用该点的一个邻域中各点值的中值代替，让周围的像素值接近的真实值，从而消除孤立的噪声点。方法是用某种结构的二维滑动模板，将板内像素按照像素值的大小进行排序，生成单调上升（或下降）的为二维数据序列。二维中值滤波输出为g（x,y）=med{f(x-k,y-l),(k,l∈W)} ，其中，f(x,y)，g(x,y)分别为原始图像和处理后图像。W为二维模板，通常为3<em>3，5</em>5区域，也可以是不同的的形状，如线状，圆形，十字形，圆环形等。</p></blockquote><p><strong>中值滤波对于消除孤立点和线段的干扰十分有用,特别是对于二进噪声尤为有效,对于消除高斯噪声则效果不佳</strong></p><h5 id="1-2-3边缘检测"><a href="#1-2-3边缘检测" class="headerlink" title="1.2.3边缘检测"></a>1.2.3<a href="https://blog.csdn.net/tercel_zhang/article/details/79538317" target="_blank" rel="noopener">边缘检测</a></h5><blockquote><p>边缘检测是图像处理和计算机视觉中的基本问题，边缘检测的目的是标识数字图像中亮度变化明显的点。图像属性中的显著变化通常反映了属性的重要事件和变化。 这些包括（i）深度上的不连续、（ii）表面方向不连续、（iii）物质属性变化和（iv）场景照明变化。 边缘检测是图像处理和计算机视觉中，尤其是特征提取中的一个研究领域。</p></blockquote><h6 id="1-2-3-1检测方法"><a href="#1-2-3-1检测方法" class="headerlink" title="1.2.3.1检测方法"></a>1.2.3.1检测方法</h6><p>有许多用于边缘检测的方法, 他们大致可分为两类：<strong>**基于搜索</strong>和基于<strong>零交叉</strong>。<br>基于搜索的边缘检测方法首先计算边缘强度， 通常用一阶导数表示， 例如梯度模，然后，用计算估计边缘的局部方向， 通常采用梯度的方向，并利用此方向找到局部梯度模的最大值。<br>基于零交叉的方法找到由图像得到的二阶导数的零交叉点来定位边缘。 通常用拉普拉斯算子或非线性微分方程的零交叉点。<br>滤波做为边缘检测的预处理通常是必要的，通常采用高斯滤波。<br>已发表的边缘检测方法应用计算边界强度的度量，这与平滑滤波有本质的不同。 正如许多边缘检测方法依赖于图像梯度的计算，他们用不同种类的滤波器来估计x-方向和y-方向的梯度。</p><h4 id="1-3车牌定位"><a href="#1-3车牌定位" class="headerlink" title="1.3车牌定位"></a>1.3车牌定位</h4><blockquote><p>车牌定位的主要方法可分为五种!:①直线边缘检测;②基于域值迭代的方法;③基于神经网络的车牌定位方法;④基于灰度的检测方法;均基于彩色图像的车牌分割方`法。</p></blockquote><p>利用BP神经网络在灰度图像中提取车牌。具体步骤为:先收集一定数量的车牌样本,用BP算法对其进行训练,达到一定正确率后,训练结束,得到一个对牌照敏感的神经网络,提取牌照时,对输入图像进行预处理,然后利用训练出的神经网络来搜索车牌。</p><h4 id="1-4改进之处"><a href="#1-4改进之处" class="headerlink" title="1.4改进之处"></a>1.4改进之处</h4><p>本轮文提出的有待改进的地方：</p><ul><li>目前的车牌号码自动识别系统只能处理单个车牌的汽车图像,对于一幅图像中多个车牌的识别则无能为力,</li><li>如何消除外界因素的干扰仍然是闯红灯系统需要解决的一个问题。</li></ul><h3 id="2-《基于卷积神经网络的无人机侦察图像识别》from"><a href="#2-《基于卷积神经网络的无人机侦察图像识别》from" class="headerlink" title="2.《基于卷积神经网络的无人机侦察图像识别》from"></a>2.《基于卷积神经网络的无人机侦察图像识别》<a href="https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201902&filename=1019042269.nh&v=MjUxODFyQ1VSTE9lWnVkdEZ5bmdVYnZLVkYyNkY3TzhITlBLcHBFYlBJUjhlWDFMdXhZUzdEaDFUM3FUcldNMUY=" target="_blank" rel="noopener">from</a></h3><h4 id="2-1特征降维"><a href="#2-1特征降维" class="headerlink" title="2.1特征降维"></a>2.1特征降维</h4><blockquote><p><a href="https://blog.csdn.net/qq_41455420/article/details/79859622" target="_blank" rel="noopener">特征降维</a>，有时候也称之为特征抽取（用于降维的特征选择方法）或数据压缩，因为现实生活中产生的数据是越来越多，数据压缩技术可以帮助我们对数据进行存储和分析。<br>特征降维是无监督学习的另一个应用，目的有 2：（1）我们会经常在实际项目中遭遇特征维度非常之高的训练样本，而往往又无法借助自己的领域知识人工构建有效特征；（2）在数据表现方面，我们无法用肉眼观测超过三个维度的特征。因此，特征降维不仅仅重构了有效的低纬度特征，同时也为数据展现提供了可能。在特征降维技术中 PCA 主成分分析是最为经典和实用的特征降维技术，在图像识别方面表现的也很突出。</p></blockquote><h4 id="2-2灰度共生矩阵"><a href="#2-2灰度共生矩阵" class="headerlink" title="2.2灰度共生矩阵"></a>2.2灰度共生矩阵</h4><blockquote><p><a href="https://baike.baidu.com/item/%E7%81%B0%E5%BA%A6%E5%85%B1%E7%94%9F%E7%9F%A9%E9%98%B5/1498946?fr=aladdin" target="_blank" rel="noopener">灰度共生矩阵</a>，指的是一种通过研究灰度的空间相关特性来描述纹理的常用方法。  1973年Harali width=”480” height=”720” 等人提出了用灰度共生矩阵来描述纹理特征。<br>由于纹理是由灰度分布在空间位置上反复出现而形成的，因而在图像空间中相隔某距离的两像素之间会存在一定的灰度关系，即图像中灰度的空间相关特性。</p></blockquote><h4 id="2-3特征抽取"><a href="#2-3特征抽取" class="headerlink" title="2.3特征抽取"></a>2.3特征抽取</h4><blockquote><p>特征抽取是将已有的特征变换成新的特征子集的方式，特征变换的方式多种多样，其中线性组合方式最受欢迎。线性组合不仅计算简单，并且解释性强，比如说主成分分析PCA。PCA通过线性变换的方式，将高维的特征映射到了低维空间。特征通过PCA降维后，特征子集可以一定程度的表示原始特征集［1４］，但是特征子集在用于特征分类里效果不一定最好，另一种更好的降维方法是线性判别分析(LDA)。</p></blockquote><h4 id="2-4激活函数"><a href="#2-4激活函数" class="headerlink" title="2.4激活函数"></a>2.4<a href="https://baike.baidu.com/item/激活函数/2520792?fr=aladdin" target="_blank" rel="noopener">激活函数</a></h4><blockquote><p>实际上．激活函数也是在模拟神经元的特点。人体的祌经元不是接收到输入就会全部输出的，是当输入达到一定的阈值后，线性或非线性的将输入转化成输出，这也就是激活函数的原理,在人工神经网络中，<a href="https://blog.csdn.net/edogawachia/article/details/80043673" target="_blank" rel="noopener">激活函数</a>就在神经元的连接形式中，以非线性的映射关系而存在，是神经网络能表达复杂非线性关系的关键所在。</p></blockquote><h5 id="2-4-1sigmoid函数"><a href="#2-4-1sigmoid函数" class="headerlink" title="2.4.1sigmoid函数"></a>2.4.1<a href="https://www.jianshu.com/p/506595ec4b58" target="_blank" rel="noopener">sigmoid函数</a></h5><blockquote><p>Sigmoid函数是一个在生物学中常见的S型函数，也称为S型生长曲线。 在信息科学中，由于其单增以及反函数单增等性质，Sigmoid函数常被用作神经网络的激活函数，将变量映射到0,1之间<br>sigmoid公式如下：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/o_191114110431111.png" class="lazyload"><br>sigmoid函数图像如下：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/c9fcc3cec3fdfc03f23fbf16d73f8794a5c226dc.png" class="lazyload"></p></blockquote><p>sigmoid函数的Python实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line"> </span><br><span class="line">sigmoid_inputs = np.arange(<span class="number">-10</span>,<span class="number">10</span>,<span class="number">0.1</span>)</span><br><span class="line">sigmoid_outputs = sigmoid(sigmoid_inputs)</span><br><span class="line">print(<span class="string">"Sigmoid Function Input :: &#123;&#125;"</span>.format(sigmoid_inputs))</span><br><span class="line">print(<span class="string">"Sigmoid Function Output :: &#123;&#125;"</span>.format(sigmoid_outputs))</span><br><span class="line"> </span><br><span class="line">plt.plot(sigmoid_inputs,sigmoid_outputs)</span><br><span class="line">plt.xlabel(<span class="string">"Sigmoid Inputs"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Sigmoid Outputs"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h5 id="2-4-2ReLU函数"><a href="#2-4-2ReLU函数" class="headerlink" title="2.4.2ReLU函数"></a>2.4.2<a href="https://www.cnblogs.com/adong7639/p/9213038.html" target="_blank" rel="noopener">ReLU函数</a></h5><blockquote><p>ReLU函数：为了避免sigmoid函数梯度趋于0产生的梯度饱和问题，线性整流函数（Rectified Linear Unit, ReLU),被提出并在卷积神经网络中取得了不错的效果。<br>当输入取值小于0时ReLU不会被激活，特别是在后向传播计算中梯度很容易变为0，这是ReLU函数本身存在的硬饱和，又会带来梯度消失的问题。而且ReLU函数的输出值是不存在负数的，这代表了ReLU也不是以0为均值的函数<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/d788d43f8794a4c25b5e4dd902f41bd5ac6e39c6.png" class="lazyload"><br>CNN中常用。对正数原样输出，负数直接置零。在正数不饱和，在负数硬饱和。<strong>ReLU计算上比sigmoid或者tanh更省计算量</strong>，因为不用exp，因而收敛较快。但是还是非zero-centered。<br>ReLU在负数区域被kill的现象叫做dead ReLU，这样的情况下，有人通过初始化的时候用一个稍微大于零的数比如0.01来初始化神经元，从而使得ReLU更偏向于激活而不是死掉，但是这个方法是否有效有争议。</p></blockquote><h5 id="2-4-3LeakyReLU函数"><a href="#2-4-3LeakyReLU函数" class="headerlink" title="2.4.3LeakyReLU函数"></a>2.4.3LeakyReLU函数</h5><blockquote><p>为了解决上述的dead ReLU现象。这里选择一个数，让负数区域不在饱和死掉。这里的斜率都是确定的。<img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20180422215128864.png" class="lazyload"></p></blockquote><h5 id="2-4-4PReLU函数"><a href="#2-4-4PReLU函数" class="headerlink" title="2.4.4PReLU函数"></a>2.4.4PReLU函数</h5><blockquote><p>PReLU(Parametric Rectified Linear Unit)顾名思义：带参数的ReLU,<a href="https://blog.csdn.net/shuzfan/article/details/51345832#prelu%E6%BF%80%E6%B4%BB" target="_blank" rel="noopener">PReLU函数</a>是为了解决ReLU的硬饱和问题产生的激活函数，在LeakyReLU函数中，斜率是固定的，这里的PRelu函数的斜率a是不固定的一个值，这个值可以在运算过程中不算学习改变原来的值。<strong>计算量不是很大，因为不用计算exp</strong><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20160508143448263.jpg" class="lazyload"></p></blockquote><h5 id="2-4-5ELU函数"><a href="#2-4-5ELU函数" class="headerlink" title="2.4.5ELU函数"></a>2.4.5ELU函数</h5><blockquote><p>ELU函数是Sigmoid函数和ReLU函数的结合体，它的提出主要是为了解决ReLUＵ函数输入负值时陷入卡死的问题<img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20180422215147575.png" class="lazyload"><br>具有ReLU的优势，且输出均值接近零，实际上PReLU和LeakyReLU都有这一优点。有负数饱和区域，从而对噪声有一些鲁棒性。可以看做是介于ReLU和LeakyReLU之间的一个东西。当然，这个函数也需要计算exp，从而<strong>计算量上更大一些</strong>。<br>ELU的优点：<br>和PReLU一样，ELU也引入了可学习的斜率a，使得激活函数在负半段是存在输出值的。但是和PReLU不一样的是，当输入值小于0时ELU的结构为非线性单元，这使得ELU具有良好的鲁棒性和抗干扰能力，但是还是具有一定程度的软饱和性</p></blockquote><h4 id="2-5卷积神经网络"><a href="#2-5卷积神经网络" class="headerlink" title="2.5卷积神经网络"></a>2.5卷积神经网络</h4><blockquote><p><a href="https://blog.csdn.net/weixin_41417982/article/details/81412076" target="_blank" rel="noopener">一篇好的介绍卷积神经网络的博客</a></p></blockquote><h5 id="2-5-1池化层（pooling）"><a href="#2-5-1池化层（pooling）" class="headerlink" title="2.5.1池化层（pooling）"></a>2.5.1池化层（pooling）</h5><blockquote><p>当p=1时池化层所采用的方式是均值池化，而p=∞池化层则采用了最大池化操作。池化层和卷积层一样，也会通过非线性的激活函数来连接池化单元。按模型的泛化能力来看，随机池化的效果要好于最大池化和均值池化，其中均值池化的泛化能力最差<br><strong>池化的目的：</strong><br>最直接的目的，就是降低了下一层待处理的数据量。比如说，当卷积层的输出大小是32×32时，如果池化层过滤器的大小为2×2时，那么经过池化层处理后，输出数据的大小为16×16，也就是说现有的数据量一下子减少到池化前的1/4。当池化层最直接的目的达到了，那么它的间接目的也达到了：减少了参数数量，从而可以预防网络过拟合。</p></blockquote><h5 id="2-5-1全连接层"><a href="#2-5-1全连接层" class="headerlink" title="2.5.1全连接层"></a>2.5.1全连接层</h5><blockquote><p><a href="https://baike.baidu.com/item/%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82/22689531?fr=aladdin" target="_blank" rel="noopener"><strong>全连接层</strong></a>在卷积层和池化层之后，全连接层的神经元与所有输入神经元全部相连，这和多层感知机的结构是一样的。通常情况下卷积神经网络会有一到多个全连接层，他们每层之间也是全部相连，直到最后一层全连接层和输出层连接。卷积祌经网络的卷积层和池化层会提取图像的局部信息或区域信息，而全连接层会破坏原始数据的空间结构性，所以CNN采用了卷积池化在前，全连接在后的网络结构。利用全连接层将卷积和池化得到的高维局部特征整合，生成出可以提供给输出层的分类特征，所以全连接层和输出层的组合可以看做是CNN的分类器。<br><strong>全连接层概念：</strong><br>全连接层的每一个结点都与上一层的所有结点相连，用来把前边提取到的特征综合起来。由于其全相连的特性，一般全连接层的参数也是最多的。例如在<a href="https://www.cnblogs.com/lfri/p/10493408.html" target="_blank" rel="noopener">VGG16</a>中，第一个全连接层FC1有4096个节点，上一层POOL2是7<em>7</em>512 = 25088个节点，则该传输需要4096*25088个权值，需要耗很大的内存。</p></blockquote><h4 id="2-6卷积神经网络的训练方法"><a href="#2-6卷积神经网络的训练方法" class="headerlink" title="2.6卷积神经网络的训练方法"></a>2.6卷积神经网络的训练方法</h4><blockquote><p>CNN的训练方法是通过前向传播计算出的样本值与样本的真实比较并计算出损失，再通过反向传播算法调整网络参数结构以最小化损失的有监督学习方法。CNN的优势在于，不需要用无监督学习的方式对网络进行初始化，直接进行有监督学习即可，因为CNN会在训练之前将整体的网络参数通过小随机数初始化。但是通常情况下为了减少网络的学习时间，会将CNN的网络结构按照当前的任务环境或者利用之前相同网络的模型的参数进行初始化。<br>所以CNN的训练分为前向传播和反向传播两个阶段，前向传播在上文的网络结构介绍中己经详细说明，输入层到卷积层的传递、卷积核卷积操作、激活函数计算值、池化操作和全连接计算等等都是属于前向传播。他们通过网络结构的参数将输入值计算为预测值，再将预测值交给BP算法去进行反向传播更新网络结构参数。反向传播算法是经典卷积祌经网络训练方式的核心，在反向传播阶段中，BP算法会与基于梯度的最优化算法相结合。卷积神经网络的误差或者损失会传递到网络各层，在每层网络通过计算梯度的方式迭代更新网络参数并逐层链式计算。<br>当反向传递到输入层时，才会重新开始前向传播计算，直到网络收敛或者达到了迭代轮数。</p></blockquote><h5 id="2-6-1最小均方误差"><a href="#2-6-1最小均方误差" class="headerlink" title="2.6.1最小均方误差"></a>2.6.1最小均方误差</h5><blockquote><p>最小均方差是损失函数的常见形式，在浅层网络中运用较多，能有效地衡量预测值和实际值之间的误差。均方差的计算方式简单，也容易让人理解，所以在较多模型中作为损失函数的一种简单形式</p></blockquote><h5 id="2-6-2最小分类误差"><a href="#2-6-2最小分类误差" class="headerlink" title="2.6.2最小分类误差"></a>2.6.2最小分类误差</h5><blockquote></blockquote><h4 id="2-7基于卷积神经网络的目标检测算法"><a href="#2-7基于卷积神经网络的目标检测算法" class="headerlink" title="2.7基于卷积神经网络的目标检测算法"></a>2.7基于卷积神经网络的目标检测算法</h4><blockquote><p>卷积神经网络对于图像特征的提取能力远远超过人为设计的目标特征提取，这是近年来卷积神经网络在图像领域飞速发展的关键</p></blockquote><h5 id="2-7-1R-CNN"><a href="#2-7-1R-CNN" class="headerlink" title="2.7.1R-CNN"></a>2.7.1R-CNN</h5><blockquote><p><a href="https://www.jianshu.com/p/381ffa6e525a" target="_blank" rel="noopener">一篇好的解析R-CNN的博客</a><br><a href="https://baike.baidu.com/item/AlexNet/22689612?fr=aladdin" target="_blank" rel="noopener">关于AlexNet</a><br>R-CNN网络于2014被Girshi width=”480” height=”720” 等人在论文中被提出，R-CNN的出现标志了目标检测任务从传统方式过渡到了深度学习阶段。<strong>在此之前的十多年内工业级的目标检测几乎都是采用了人工提取图像特征算子例如HOG和SIFT，再将特征输入到分类器进行识别的方式。传统的方式尽管在许多领域取得了不错的效果，但是很难有进一步的提升</strong>。当任务的场景变换时，又不得不去挖掘和发现一些新的特征，目标检测的相关研究进展十分缓慢。R-CNN在VOC2012上直接超越了之前传统方式检测识别最好结果的30%，这代表了CNN从目标识别到目标检测的领域跨越。   </p></blockquote><h6 id="2-7-1-1R-CNN工作原理"><a href="#2-7-1-1R-CNN工作原理" class="headerlink" title="2.7.1.1R-CNN工作原理"></a>2.7.1.1R-CNN工作原理</h6><blockquote><p>R-CNN利用网络将特征提取和特征分类合并到一起，大大提升了特征的提取效率。但是无论是传统方式还是R-CNN，目标检测和目标识别的最大区别就是需要提取候选区域（region proposals）<br>R-CNN采用选择性搜索（selective search）算法，又称区域合并算法，selective search会将对图片暴力生成多个候选区域<br>R-CNN算法的计算过程：<br>首先输入图像会被分为R个初始候选集，然后通过贪心策略去计算相邻候选集之前的相似度，通过相似度的大小去合并候选集，直到产生目标个数的候选集。候选集的相似度计算有多种方式，有颜色、纹理、而枳和吻合相似度计算。最后生成的L个Region Proposal与CNN相结合，这就是R-CNN名字的由来。<br>R-CNN作者证明了在当前任务下SVM的分类效果要比神经网络分类器好。最后每个SNM分类器都会得到图像对于该类别的得分和置信度，置信度最高的类别为改图像区域对应的预测类别。</p></blockquote><h5 id="2-7-2金字塔池化网络"><a href="#2-7-2金字塔池化网络" class="headerlink" title="2.7.2金字塔池化网络"></a>2.7.2金字塔池化网络</h5><blockquote><p><a href="https://blog.csdn.net/wsp_1138886114/article/details/81778202" target="_blank" rel="noopener"><strong>金字塔池化网络</strong></a>(Spatial Pyramid Pooling Network)是为了解决R-CNN遗留问题诞生出来的网络模型。回顾一下R-CNN网络，首先R-CNN在生成了候选区域后，需要对每个区域进行统一尺寸的压缩或放大，当候选集的长与宽差别较大时强行压缩至比例为1会使图像产生变形和丢失图像的原始特征，SPPNet提出了…种解决方案可以不用压缩图像候选集而直接做为网络输入。另 外一点是R-CNN生成了多个候选集后需要全部输入到CNN中，当生成了2000个候选集时，就需要对图片进行2000次单模型特征提取，这无疑是效率低下的，同样SPPNet也完美解决了这个问题<br><strong>SPPNet的解决方案：</strong></p><ul><li>SPPNet网络结构图如下所示，在输入时直接输入整张图像，只需要对整张图像做一次卷积操作，同时会生成整张图像的候选集特征映射(Reature Map)，这样候选集对应的特征阁可以直接传递到下－层，这样…来对图像进行2000次的计算就变成了1次，大大增加了网络的效率。</li><li>SPPNet中另一关键模块就是金字塔池化层（Spatial Pyramid Pooling Layer），这一层的设计思路是通过池化操作将任意尺寸的输入都转换成固定大小输出，因为在池化层中只要池化的核结构不变，输入的维度就不会变化。Kaiming He等人正是利用了池化输出固定的原理避免了原始R-CNN模型中需要缩放图片候选集的操作   </li></ul><p><strong>SPPNet在R-CNN拥有的区域提取、卷积层、池化层、全连接层、SVM分 类器和Bounding-Box回归网络结构基础上，加入了候选集特征图映射和SPP Pooling层。将R-CNN网络的预测速度提升了数十倍，极大地优化了网络的计算 法复杂度</strong><br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20180817153030153.png" class="lazyload"></p></blockquote><h5 id="2-7-3Fast-R-CNN"><a href="#2-7-3Fast-R-CNN" class="headerlink" title="2.7.3Fast R-CNN"></a>2.7.3Fast R-CNN</h5><blockquote><p>虽然SPPNet网路对R-CNN进行了改进，且效率有提升，但是R-CNN和SPPNet同时还是存在一些缺陷：==<em>网络模型分开训练会产生大量的中间计算量和缓存特征，同时各个模型的独立加大了在线训练的难度</em>==。针对R-CNN和SPPNet两个算法的共同缺陷，Girshi width=”480” height=”720” 提出的Fast R-CNN算法对上述缺陷进行了一些改进。<br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/o_1911140113383940902-7569280b566d0e58.png" class="lazyload"><br>上图是Fast R-CNN的结构图，相比于R-CNN，Fast R-CNN有如下几点改进之处：</p><ul><li>加入了Feature Map，在这里Fast R-CNN和SPPNet的思路是一样的，利用候选集和特征图的映 射来对图像只做一次卷积就能得到所有候选集的特征图。</li><li>卷积后连接Rol Pooling Layer,Fast R-CNN借鉴了SPPNet的池化固定输出维度的思路，是SSP Pooling Layer的精简版，同样也不需要对候选集的尺寸进行缩放。</li><li>分类器和Bounding-Box Regression合并为Multi-Task结构。这是Fast R-CNN相比于SPPNet和R-CNN模型独立的重要改进，Fast R-CNN将<a href="https://baike.baidu.com/item/softmax%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/22689563?fr=aladdin" target="_blank" rel="noopener">Softmax</a>作为网络的分类器，并将全连接输出的一部分输入到了Bounding-Box Regression中。不用像R-CNN一样将CNN、SVM分类器和Bounding-Box Regression中分开成独立的三部分，模型的在线预测成为了可能。  </li></ul></blockquote><blockquote><p>++在R-CNN中全连接层的计算特别耗时，Fast R-CNN对全连接层采用了SVD分解，全连接层拆分为两个简单公式计算，加快了计算速度。++</p></blockquote><blockquote><p>综上所述，Fast R-CNN在结合SPPNet的思想下针对R-CNN<strong>候选集统一尺度</strong>、<strong>候选集依次卷积</strong>和<strong>模型结构独立</strong>等问题下提出了诸多改进方式，并沿用了R-CNN的大部分结构。<strong>Fast R-CNN仅在运算速度上超越了R-CNN</strong>，模型<strong>的预测效果</strong>也得到了<strong>不少的提升</strong>。但是Fast R-CNN还是保留了一些<strong>缺陷</strong>，在<a href="https://blog.csdn.net/liuxiaoheng1992/article/details/81843363" target="_blank" rel="noopener"><strong>Faster R-CNN</strong></a>中针对在这些问题得到了改善，为了解决这一问题，Faster R-CNN于2016年被提出，通过引入RPN模块快速完成了proposal的生成</p></blockquote><blockquote><p><strong>注意：</strong>Fast R-CNN在对原始图像卷积后，会串行的对原图进行候选集提取并映射，到特征图上生成多个大小不同的特征图候选集，而Faster R-CNN在卷积之后特征图会并行的进入两个通道，一个是Fast R-CNN的Rol Pooling层，另一个就是Faster R-CNN中引入的RPN结构，所以Faster R-CNN可以看作是RPN和Fast R-CNN的组合模式 </p></blockquote><blockquote><p><strong>softmax逻辑回归函数：</strong><br><a href="https://baike.baidu.com/item/softmax%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/22689563?fr=aladdin" target="_blank" rel="noopener">Softmax</a>逻辑回归模型是logistic回归模型在多分类问题上的推广，在多分类问题中，类标签y可以取两个以上的值。 Softmax回归模型对于诸如MNIST手写数字分类等问题是很有用的，该问题的目的是辨识10个不同的单个数字。Softmax回归是有监督的，不过后面也会介绍它与深度学习无监督学习方法的结合。<br><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/d62a6059252dd42af3835f580f3b5bb5c8eab8bf.jpg" class="lazyload"></p></blockquote><h4 id="2-8对Faster-R-CNN目标检测算法的改进"><a href="#2-8对Faster-R-CNN目标检测算法的改进" class="headerlink" title="2.8对Faster R-CNN目标检测算法的改进"></a>2.8对Faster R-CNN目标检测算法的改进</h4><h5 id="2-8-1RPN网络"><a href="#2-8-1RPN网络" class="headerlink" title="2.8.1RPN网络"></a>2.8.1<a href="https://blog.csdn.net/qq_36269513/article/details/80421990" target="_blank" rel="noopener">RPN网络</a></h5><blockquote><p>区域提名网络（RegionProposalNetworks，RPN）是Faster R-CNN中的重要 结构，其主要功能是生成带有坐标的感兴趣区域框，和R－CNN或FastR－CNN中 候选集生成算法的作用是一样的。<br><strong>视频介绍RPN</strong></p></blockquote><iframe src="//player.bilibili.com/player.html?aid=29987414&cid=52249531&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="720" height="480"> </iframe><h5 id="2-8-2Fast-R-CNN-特征提取与-RolP"><a href="#2-8-2Fast-R-CNN-特征提取与-RolP" class="headerlink" title="2.8.2Fast R-CNN 特征提取与 RｏｌＰ"></a>2.8.2Fast R-CNN 特征提取与 RｏｌＰ</h5><blockquote><p>图像特征提取采用的卷积层是<a href="https://www.cnblogs.com/lfri/p/10493408.html" target="_blank" rel="noopener">VGG1６</a>， </p></blockquote><h5 id="2-8-3基于Faster-R-CNN的航拍图像分析"><a href="#2-8-3基于Faster-R-CNN的航拍图像分析" class="headerlink" title="2.8.3基于Faster R-CNN的航拍图像分析"></a>2.8.3基于Faster R-CNN的航拍图像分析</h5><blockquote><p>航拍图像实例的特点：实例多数处于相对位置不变化的状态<br>航拍图像中的一大难点：</p><ul><li>也是基于航拍图像的目标检测研究面临的第一大难点。 </li><li>由于航拍图像拍摄的距离不同，同一类别物体在 不冋图像中的差别会很人</li></ul></blockquote><h5 id="2-8-4基于改进Faster-R-CNN算法的目标检测"><a href="#2-8-4基于改进Faster-R-CNN算法的目标检测" class="headerlink" title="2.8.4基于改进Faster R-CNN算法的目标检测"></a>2.8.4基于改进Faster R-CNN算法的目标检测</h5><blockquote><p>从网络结构出发优化目标可主要分为 CNN特征提取层、RPN结构和Fast R-CNN并行的OHEM算法嵌入三部分。<br>Faster R-CNN中的特征提取采用的是VGG1６网络，<br><strong>改论文创新点：本论文 基于ResNet－101的卷积神经网络设计出了一版Faster R-CNN框架</strong></p></blockquote><h5 id="2-8-6RPN网络改进"><a href="#2-8-6RPN网络改进" class="headerlink" title="2.8.6RPN网络改进"></a>2.8.6RPN网络改进</h5><blockquote><p>RPN网络是Faster R-CNN区别于Fast R-CNN的核心，高精度、准确的 Proposal是网络训练和预测的关键。<br>方法：</p><ul><li>调整RPN中Anchors</li><li>修改Proposal输出阈值</li><li>正负采样调整<br>改进结果：通过对RPN网络的优化对小目标的检测有不错提升，但是训练和预测速度 下降不少，在这里并没有对计算性能进行过多的优化</li></ul></blockquote><h5 id="2-8-7OHEM算法模型嵌入"><a href="#2-8-7OHEM算法模型嵌入" class="headerlink" title="2.8.7OHEM算法模型嵌入"></a>2.8.7<a href="https://blog.csdn.net/u012426298/article/details/81773319" target="_blank" rel="noopener">OHEM</a>算法模型嵌入</h5><blockquote><p>OHEM（Online Hard Example Mining）算法在基于机器学习的任务中十分常见，通常用来解决正负样本不均衡的问题。</p></blockquote><h4 id="2-9本轮文的结构"><a href="#2-9本轮文的结构" class="headerlink" title="2.9本轮文的结构"></a>2.9本轮文的结构</h4><blockquote><p><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191118093651.png" class="lazyload"></p></blockquote><h4 id="2-10未来展望"><a href="#2-10未来展望" class="headerlink" title="2.10未来展望"></a>2.10未来展望</h4><blockquote><p><img alt data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/20191118093842.png" class="lazyload"></p></blockquote><h3 id="3-《智能交通图像识别系统的研究》from"><a href="#3-《智能交通图像识别系统的研究》from" class="headerlink" title="3.《智能交通图像识别系统的研究》from"></a>3.《智能交通图像识别系统的研究》from</h3><h4 id="3-1人工神经网络进行字符识别"><a href="#3-1人工神经网络进行字符识别" class="headerlink" title="3.1人工神经网络进行字符识别"></a>3.1人工神经网络进行字符识别</h4><blockquote><p>主要有两种方法:一种方法是先对待识别字符进行特征提取,然后用所获得的特征来训练神经网络分类器。这种网络的识别效果与字符特征的提取有关,而字符的特征提取往往比较耗时。因此,字符特征的提取就成为研究的关键。文献四中使用由6个多层感知器构成的神经网络来进行车牌字符识别,在特征提取上提出二值线性变换方法以减少输入特征向量,另外改善网络结构以提高识别速度。另一种方法则充分利用神经网络的特点,直接把待处理图像输入网络,由网络自动实现特征提取直至识别。这种网络互连较多、待处理信息量大。<br>神经网络在并行非线性处理及大容量计算方面存在着巨大潜力, 且神经元状态是二值的</p></blockquote><h4 id="3-2图像预处理"><a href="#3-2图像预处理" class="headerlink" title="3.2图像预处理"></a>3.2图像预处理</h4><blockquote><p>预处理相当于对获取的原始图像数据进行整理加工、去伪存真的过程。由于原始图像信号中存在着许多噪声和畸变,一般要进行滤波、平滑、增强、复原、提取边缘、图像分割等预处理,以便提高图像质量,并为下一步特征提取提供必要的基础。<br>决策分类<br>根据具体问题的性质,提出一个反映分类好坏的标准,从而找到最符合这一标准的分类方一法。 从数学观点来看,决策分类就是找出决策函数(边界函数)。</p></blockquote><h5 id="3-2-1灰度图化"><a href="#3-2-1灰度图化" class="headerlink" title="3.2.1灰度图化"></a>3.2.1灰度图化</h5><p>灰度化，在RGB模型中，如果R=G=B时，则彩色表示一种灰度颜色，其中R=G=B的值叫灰度值，因此，灰度图像每个像素只需一个字节存放灰度值（又称强度值、亮度值），灰度范围为0-255。一般有分量法 最大值法平均值法加权平均法四种方法对彩色图像进行灰度化。<br>RGB图像如何转换成灰度图像</p><h6 id="3-2-1-1平均法"><a href="#3-2-1-1平均法" class="headerlink" title="3.2.1.1平均法"></a>3.2.1.1平均法</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">lenna = cv2.imread(<span class="string">"lenna.png"</span>)</span><br><span class="line">row, col, channel = lenna.shape</span><br><span class="line">lenna_gray = np.zeros((row, col))</span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> range(row):</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(col):</span><br><span class="line">        lenna_gray[r, l] = <span class="number">1</span> / <span class="number">3</span> * lenna[r, l, <span class="number">0</span>] + <span class="number">1</span> / <span class="number">3</span> * lenna[r, l, <span class="number">1</span>] + <span class="number">1</span> / <span class="number">3</span> * lenna[r, l, <span class="number">2</span>]</span><br><span class="line">cv2.imshow(<span class="string">"lenna_gray"</span>, lenna_gray.astype(<span class="string">"uint8"</span>))</span><br><span class="line">cv2.waitKey()</span><br></pre></td></tr></table></figure><h6 id="3-2-1-2最大最小平均法"><a href="#3-2-1-2最大最小平均法" class="headerlink" title="3.2.1.2最大最小平均法"></a>3.2.1.2最大最小平均法</h6><blockquote><p>取同一个像素位置的RGB中亮度最大的和最小的进行平均</p></blockquote><h5 id="3-2-1-3加权平均法"><a href="#3-2-1-3加权平均法" class="headerlink" title="3.2.1.3加权平均法"></a>3.2.1.3加权平均法</h5><blockquote><p>I(x,y) = 0.3 * I_R(x,y) +0.59 * I_G(x,y)+ 0.11 * I_B(x,y) 这是最流行的方法。几个加权系数0.3,0.59,0.11是根据人的亮度感知系统调节出来的参数，是个广泛使用的标准化参数。</p></blockquote><h5 id="3-2-1-4二值图像"><a href="#3-2-1-4二值图像" class="headerlink" title="3.2.1.4二值图像"></a>3.2.1.4二值图像</h5><blockquote><p>图像二值化（ Image Binarization）就是将图像上的像素点的灰度值设置为0或255，也就是将整个图像呈现出明显的黑白效果的过程。 在数字图像处理中，二值图像占有非常重要的地位，图像的二值化使图像中数据量大为减少，从而能凸显出目标的轮廓。</p></blockquote><h5 id="3-2-1-5反转图像"><a href="#3-2-1-5反转图像" class="headerlink" title="3.2.1.5反转图像"></a>3.2.1.5反转图像</h5><blockquote><p>反转图像也很简单：s = 255-r。反转图像特别适用于增强暗色图像中的白色或灰色细节</p></blockquote><h4 id="3-2-2中值滤波"><a href="#3-2-2中值滤波" class="headerlink" title="3.2.2中值滤波"></a>3.2.2中值滤波</h4><blockquote><p>中值滤波法是一种非线性平滑技术，它将每一像素点的灰度值设置为该点某邻域窗口内的所有像素点灰度值的中值. 中值滤波是基于排序统计理论的一种能有效抑制噪声的非线性信号处理技术，中值滤波的基本原理是把数字图像或数字序列中一点的值用该点的一个邻域中各点值的中值代替，让周围的像素值接近的真实值，从而消除孤立的噪声点。方法是用某种结构的二维滑动模板，将板内像素按照像素值的大小进行排序，生成单调上升（或下降）的为二维数据序列。二维中值滤波输出为g（x,y）=med{f(x-k,y-l),(k,l∈W)} ，其中，f(x,y)，g(x,y)分别为原始图像和处理后图像。W为二维模板，通常为33，55区域，也可以是不同的的形状，如线状，圆形，十字形，圆环形等。<br>中值滤波对于消除孤立点和线段的干扰十分有用,特别是对于二进噪声尤为有效,对于消除高斯噪声则效果不佳</p></blockquote><h4 id="3-2-3边缘检测"><a href="#3-2-3边缘检测" class="headerlink" title="3.2.3边缘检测"></a>3.2.3边缘检测</h4><blockquote><p>边缘检测是图像处理和计算机视觉中的基本问题，边缘检测的目的是标识数字图像中亮度变化明显的点。图像属性中的显著变化通常反映了属性的重要事件和变化。 这些包括（i）深度上的不连续、（ii）表面方向不连续、（iii）物质属性变化和（iv）场景照明变化。 边缘检测是图像处理和计算机视觉中，尤其是特征提取中的一个研究领域。</p></blockquote><h5 id="3-2-3-1检测方法"><a href="#3-2-3-1检测方法" class="headerlink" title="3.2.3.1检测方法"></a>3.2.3.1检测方法</h5><blockquote><p>有许多用于边缘检测的方法, 他们大致可分为两类：基于搜索和基于零交叉**。 基于搜索的边缘检测方法首先计算边缘强度， 通常用一阶导数表示， 例如梯度模，然后，用计算估计边缘的局部方向， 通常采用梯度的方向，并利用此方向找到局部梯度模的最大值。 基于零交叉的方法找到由图像得到的二阶导数的零交叉点来定位边缘。 通常用拉普拉斯算子或非线性微分方程的零交叉点。 滤波做为边缘检测的预处理通常是必要的，通常采用高斯滤波。 已发表的边缘检测方法应用计算边界强度的度量，这与平滑滤波有本质的不同。 正如许多边缘检测方法依赖于图像梯度的计算，他们用不同种类的滤波器来估计x-方向和y-方向的梯度。</p></blockquote><h4 id="3-3车牌定位"><a href="#3-3车牌定位" class="headerlink" title="3.3车牌定位"></a>3.3车牌定位</h4><blockquote><p>车牌定位的主要方法可分为五种!:①直线边缘检测;②基于域值迭代的方法;③基于神经网络的车牌定位方法;④基于灰度的检测方法;均基于彩色图像的车牌分割方`法。<br>利用BP神经网络在灰度图像中提取车牌。具体步骤为:先收集一定数量的车牌样本,用BP算法对其进行训练,达到一定正确率后,训练结束,得到一个对牌照敏感的神经网络,提取牌照时,对输入图像进行预处理,然后利用训练出的神经网络来搜索车牌。</p></blockquote><h4 id="3-4改进之处"><a href="#3-4改进之处" class="headerlink" title="3.4改进之处"></a>3.4改进之处</h4><blockquote><p>本轮文提出的有待改进的地方：<br>目前的车牌号码自动识别系统只能处理单个车牌的汽车图像,对于一幅图像中多个车牌的识别则无能为力,<br>如何消除外界因素的干扰仍然是闯红灯系统需要解决的一个问题。</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 论文笔记 </tag>
            
            <tag> 航拍识别 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>视频test</title>
      <link href="/video-1/"/>
      <url>/video-1/</url>
      
        <content type="html"><![CDATA[<h3 id="1-video-demo"><a href="#1-video-demo" class="headerlink" title="1.video demo"></a>1.video demo</h3><p>这是一个视频demo，hexo可以通过GitHub实现视频播放功能，下面这段视频的Markdown代码如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;video id=&quot;video&quot; controls=&quot;&quot; preload=&quot;none&quot; poster=&quot;https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/IMG_2987.JPG&quot; width=&quot;720&quot; height=&quot;480&quot;&gt;</span><br><span class="line">      &lt;source id=&quot;mp4&quot; src=&quot;https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/videos/123.mp4&quot; type=&quot;video/mp4&quot;&gt;</span><br><span class="line">&lt;/video&gt;</span><br></pre></td></tr></table></figure><h3 id="2-注意"><a href="#2-注意" class="headerlink" title="2.注意"></a>2.注意</h3><blockquote><p><strong>在GitHub上的视频必须是小于20M的视频才可以，可以使用视频压缩技术对视频进行压缩</strong></p></blockquote><video id="video" controls="" preload="none" poster="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/IMG_2987.JPG" width="720" height="480">      <source id="mp4" src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/videos/123.mp4" type="video/mp4"></video><h3 id="3-引用B站上的视频"><a href="#3-引用B站上的视频" class="headerlink" title="3.引用B站上的视频"></a>3.引用<a href="https://www.bilibili.com/" target="_blank" rel="noopener">B站</a>上的视频</h3><p>下面的视频的引用代码如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;iframe src=&quot;//player.bilibili.com/player.html?aid=75534775&amp;cid=129216147&amp;page=1&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot; width=&quot;720&quot; height=&quot;480&quot;&gt; &lt;/iframe&gt;</span><br></pre></td></tr></table></figure><blockquote><p><strong>建议：</strong> 我们可以将我们自己的视频上传到B站然后下面的代码格式对自己的视频进行引用</p></blockquote><iframe src="//player.bilibili.com/player.html?aid=75534775&cid=129216147&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="720" height="480"> </iframe>]]></content>
      
      
      
        <tags>
            
            <tag> 玩艺 </tag>
            
            <tag> movie </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>你现在的能力和你需要达到的高度</title>
      <link href="/your-plan/"/>
      <url>/your-plan/</url>
      
        <content type="html"><![CDATA[<h3 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h3><h4 id="1-深度学习框架热度排名"><a href="#1-深度学习框架热度排名" class="headerlink" title="1.深度学习框架热度排名"></a>1.深度学习框架热度排名</h4><p><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/framework.png" class="lazyload"></p><h4 id="2-计算机视觉领域算法发展史"><a href="#2-计算机视觉领域算法发展史" class="headerlink" title="2.计算机视觉领域算法发展史"></a>2.计算机视觉领域算法发展史</h4><p><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/deep_learning_object_detection_history.png" class="lazyload"></p><h4 id="3-你应该具备的能力"><a href="#3-你应该具备的能力" class="headerlink" title="3.你应该具备的能力"></a>3.你应该具备的能力</h4><ul><li><strong>算法能力</strong><ul><li>机器学习-吴恩达，<a href="https://www.bilibili.com/video/av9912938" target="_blank" rel="noopener">course</a></li><li>卷积神经网络（CNN） 是计算机视觉的基础中的基础，一定得了解透彻，不能一知半解，<a href="https://blog.csdn.net/weixin_42451919/article/details/81381294" target="_blank" rel="noopener">blog</a>/<a href="https://www.bilibili.com/video/av36381900?from=search&seid=3318225737780585556" target="_blank" rel="noopener">course</a></li><li>R-CNN是计算机视觉算法鼻祖，先学透R-CNN，在学相关其他算法会好学很多。<a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="noopener">paper</a>/<a href="https://www.jianshu.com/p/381ffa6e525a" target="_blank" rel="noopener">blog</a></li></ul></li><li><strong>深度学习框架能力</strong><ul><li>pytorch(<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener">pytorch.org</a>)，<a href="https://www.bilibili.com/video/av15997678" target="_blank" rel="noopener">course</a></li><li>TensorFlow(<a href="http://www.tensorfly.cn/" target="_blank" rel="noopener">chinese community</a>)</li></ul></li><li><strong>编程能力</strong><ul><li>Python编程能力</li><li>MATLAB分析能力</li></ul></li></ul><h4 id="4-你已经具备的能力"><a href="#4-你已经具备的能力" class="headerlink" title="4.你已经具备的能力"></a>4.你已经具备的能力</h4><ul><li><strong>编程能力</strong><ul><li>Python编程能力（可以使用PurePython实现一些算法功能）</li><li>Java编程能力（了解Java编程规范，会使用Java实现一些后端功能）</li><li>HTML能力/CSS（可以编写静态网页）<a href="https://www.bilibili.com/video/av10298843" target="_blank" rel="noopener">course</a></li><li>JavaScript能力（了解的不是很多，需要加强）<a href="https://www.bilibili.com/video/av29885002" target="_blank" rel="noopener">course</a></li><li>git使用能力（仅会上传代码，不会追加代码，有待进一步加强）<a href="https://www.bilibili.com/video/av24441039?from=search&seid=10646578285914070658" target="_blank" rel="noopener">course</a>/<a href="http://www.uml.org.cn/pzgl/201902251.asp" target="_blank" rel="noopener">blog</a></li></ul></li><li>图像预处理能力<ul><li>数字图像处理<ul><li>图像增强</li><li>图像锐化</li><li>灰度变换</li><li>正交变换</li><li>图像降噪</li></ul></li></ul></li><li><strong>算法能力</strong><ul><li>暂无</li></ul></li><li><strong>深度学习框架能力</strong><ul><li>暂无</li></ul></li></ul><h4 id="5-关于你的研究方向"><a href="#5-关于你的研究方向" class="headerlink" title="5.关于你的研究方向"></a>5.关于你的研究方向</h4><ul><li><a href="https://baike.baidu.com/item/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/2803351?fr=aladdin#4" target="_blank" rel="noopener">计算机视觉</a>的<a href="http://www.elecfans.com/d/901496.html" target="_blank" rel="noopener">研究方向</a><ul><li><strong>目标检测</strong>(Object detection)</li><li>目标跟踪(Target tracking)</li><li>语义分割(Sentiment segmention)</li><li>生产对抗网络(Generated antagonistic network)</li><li>图像检索(Image retrieval)</li><li>图像增强(Image enhancement)</li><li>图像滤波与降噪(Image filtering and noise reduction)</li><li>三维重建(3D reconstruction)</li><li>风格化(stylized)</li><li>图像识别(image recognition)<ul><li><strong>航拍图像识别</strong>（识别航拍图像中的人，毕业论文可与应急救援相结合）</li><li>航拍公开数据集<a href="https://captain-whu.github.io/DOTA/dataset.html" target="_blank" rel="noopener">DOTA</a>，<a href="https://github.com/jessemelpolio/Faster_RCNN_for_DOTA" target="_blank" rel="noopener">Faster_RCNN_for_DOTA at github</a></li><li><a href="https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201902&filename=1019042269.nh&v=MjUxODFyQ1VSTE9lWnVkdEZ5bmdVYnZLVkYyNkY3TzhITlBLcHBFYlBJUjhlWDFMdXhZUzdEaDFUM3FUcldNMUY=" target="_blank" rel="noopener">《基于卷积神经网络的无人机侦察图像识别》</a>，北邮硕士论文，2019</li></ul></li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> plan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>教你如何用Markdown引用网易云音乐</title>
      <link href="/music-test/"/>
      <url>/music-test/</url>
      
        <content type="html"><![CDATA[<h3 id="1-固定长度"><a href="#1-固定长度" class="headerlink" title="1 固定长度"></a>1 固定长度</h3><p>复制下面的代码，到你的Markdown中，就可以实现音乐播放的功能，音乐源引用自网易云音乐。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">iframe</span> <span class="attr">frameborder</span>=<span class="string">"yes"</span> <span class="attr">border</span>=<span class="string">"100"</span> <span class="attr">marginwidth</span>=<span class="string">"4"</span> <span class="attr">marginheight</span>=<span class="string">"0"</span> <span class="attr">width</span>=<span class="string">333</span> <span class="attr">height</span>=<span class="string">86</span> <span class="attr">src</span>=<span class="string">"//music.163.com/outchain/player?type=2&amp;id=1295824647&amp;auto=1&amp;height=66"</span>&gt;</span><span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></span><br></pre></td></tr></table></figure><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=3932159&auto=1&height=66"></iframe> <p><strong>参数解释：</strong>  </p><ul><li>auto 1:自动播放 0:不自动播放</li><li>width 控制播放条的长度，默认是333px</li><li>height 控制播放条的高度，默认是86px(px是像素的单位)</li><li>src 歌曲的链接地址，可以在网页版的网易云平台搜索自己喜欢的歌曲查看，如下所示：<br><img alt="image" data-src="https://cdn.jsdelivr.net/gh/crazyjums/crazyjums.github.io@master/images/article/1232314fdgdfsg.png" class="lazyload"></li></ul><h3 id="2-自适应长度"><a href="#2-自适应长度" class="headerlink" title="2 自适应长度"></a>2 自适应长度</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">iframe</span> <span class="attr">frameborder</span>=<span class="string">"no"</span> <span class="attr">border</span>=<span class="string">"1"</span> <span class="attr">marginwidth</span>=<span class="string">"0"</span> <span class="attr">marginheight</span>=<span class="string">"0"</span> <span class="attr">width</span>=<span class="string">100%</span> <span class="attr">height</span>=<span class="string">86</span> <span class="attr">src</span>=<span class="string">"//music.163.com/outchain/player?type=2&amp;id=1295824647&amp;auto=0&amp;height=66"</span>&gt;</span><span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></span><br></pre></td></tr></table></figure><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="100%" height="86" src="//music.163.com/outchain/player?type=2&id=1295824647&auto=0&height=66"></iframe>]]></content>
      
      
      
        <tags>
            
            <tag> 玩艺 </tag>
            
            <tag> music </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数字图像处理（dip）</title>
      <link href="/dip/"/>
      <url>/dip/</url>
      
        <content type="html"><![CDATA[<h2 id="学科：数字图像处理（Digital-Image-Processing-video）"><a href="#学科：数字图像处理（Digital-Image-Processing-video）" class="headerlink" title="学科：数字图像处理（Digital Image Processing -video）"></a>学科：<a href="[https://baike.baidu.com/item/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/5199259?fr=aladdin](https://baike.baidu.com/item/数字图像处理/5199259?fr=aladdin)">数字图像处理</a>（<a href="https://www.bilibili.com/video/av61178093/" target="_blank" rel="noopener">Digital Image Processing -video</a>）</h2><h2 id="作者：zhuhonggen"><a href="#作者：zhuhonggen" class="headerlink" title="作者：zhuhonggen"></a>作者：zhuhonggen</h2><p><img alt="作者微信公众号" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rBVBy82ZFdxLvnJGcqQT6QvhMib9OvDMtwPjSyKHWzQXtgDVdWafOcLA/0?wx_fmt=jpeg" class="lazyload"></p><hr><h1 id="计算机视觉入门基础"><a href="#计算机视觉入门基础" class="headerlink" title="计算机视觉入门基础"></a>计算机视觉入门基础</h1><h2 id="0概念介绍"><a href="#0概念介绍" class="headerlink" title="0概念介绍"></a>0概念介绍</h2><h3 id="0-1数字图像处理概念"><a href="#0-1数字图像处理概念" class="headerlink" title="0.1数字图像处理概念"></a>0.1数字图像处理概念</h3><h4 id="0-1-1图像的高频分量和低频分量"><a href="#0-1-1图像的高频分量和低频分量" class="headerlink" title="0.1.1图像的高频分量和低频分量"></a>0.1.1<a href="https://blog.csdn.net/Chaolei3/article/details/79443520" target="_blank" rel="noopener">图像的高频分量和低频分量</a></h4><blockquote><p>总得来说，低频分量（低频信号）代表着图像中亮度或者灰度值变化缓慢的区域，也就是图像中大片平坦的区域，描述了图像的主要部分。高频分量（高频信号）对应着图像变化剧烈的部分，也就是图像的边缘（轮廓）或者噪声以及细节部分。<br>之所以说噪声也对应着高频分量，是因为图像噪声在大部分情况下都是高频的。<br>低频分量：主要对整幅图像强度的综合度量。高频分量：主要是对图像边缘和轮廓的度量。而人眼对高频分量比较敏感。<br>我们试着用傅立叶变换站在另外一个角度观察图像，将图像从灰度分布转化到频率分布（频谱图）上去观察图像的特征。需要了解的是，图像进行二维傅立叶变换之后得到的频谱图，就是图像梯度的分布图。具体的，傅立叶频谱图上我们能看到明暗不一的亮点，实际是图像上某一点与邻域点差异的强弱，即梯度的大小。<br>所以说，如果一幅图像的各个位置的强度大小相等，则图像只存在低频分量。从图像的频谱图上看，只有一个主峰,且位于频率为零的位置.。需要提一句的是，图像的频谱图可以由傅里叶变换得到。<br>如果一幅图像的各个位置的强度变化剧烈，则图像不仅存在低频分量，同时也存在多种高频分量。从图像的频谱上看，不仅有一个主峰,同时也存在多个旁峰。可以这样理解：图像中的低频分量就是图像中梯度较小的部分，高频分量则相反。<br>从直方图上看，低频分量对应直方图内大块区域，而小块或者离散的区域就是高频分量。这说明低频分量占据了图像的主要部分。<br>从二维函数上理解，变化剧烈的地方就是高频分量，变化少的地方就是低频分量。</p></blockquote><h4 id="0-1-2采样定理"><a href="#0-1-2采样定理" class="headerlink" title="0.1.2采样定理"></a>0.1.2<a href="https://baike.baidu.com/item/%E9%87%87%E6%A0%B7%E5%AE%9A%E7%90%86/8599843?fr=aladdin" target="_blank" rel="noopener">采样定理</a></h4><blockquote><p>样定理是美国电信工程师H.奈奎斯特在1928年提出的，在数字信号处理领域中，采样定理是连续时间信号（通常称为“模拟信号”）和离散时间信号（通常称为“数字信号”）之间的基本桥梁。该定理说明采样频率与信号频谱之间的关系，是连续信号离散化的基本依据。 它为采样率建立了一个足够的条件，该采样率允许离散采样序列从有限带宽的连续时间信号中捕获所有信息。</p></blockquote><h5 id="0-1-2-1定理说明"><a href="#0-1-2-1定理说明" class="headerlink" title="0.1.2.1定理说明"></a>0.1.2.1定理说明</h5><blockquote><p>采样过程所应遵循的规律，又称取样定理、抽样定理。采样定理说明采样频率与信号频谱之间的关系，是连续信号离散化的基本依据。<br>在进行模拟/数字信号的转换过程中，当采样频率fs.max大于信号中最高频率fmax的2倍时(fs.max&gt;2fmax)，采样之后的数字信号完整地保留了原始信号中的信息，一般实际应用中保证采样频率为信号最高频率的2.56～4倍；采样定理又称奈奎斯特定理。<br>如果对信号的其它约束是已知的，则当不满足采样率标准时，完美重建仍然是可能的。 在某些情况下（当不满足采样率标准时），利用附加的约束允许近似重建。 这些重建的保真度可以使用Bochner定理来验证和量化。</p></blockquote><h4 id="0-1-3PCM编码"><a href="#0-1-3PCM编码" class="headerlink" title="0.1.3PCM编码"></a>0.1.3<a href="https://baike.baidu.com/item/pcm%E7%BC%96%E7%A0%81/10865033?fr=aladdin" target="_blank" rel="noopener">PCM编码</a></h4><blockquote><p>PCM（Pulse Code Modulation）脉冲编码调制是数字通信的编码方式之一。主要过程是将话音、图像等模拟信号每隔一定时间进行取样，使其离散化，同时将抽样值按分层单位四舍五入取整量化，同时将抽样值按一组二进制码来表示抽样脉冲的幅值。</p></blockquote><h4 id="0-1-4图像分辨率"><a href="#0-1-4图像分辨率" class="headerlink" title="0.1.4图像分辨率"></a>0.1.4<a href="https://baike.baidu.com/item/%E5%9B%BE%E5%83%8F%E5%88%86%E8%BE%A8%E7%8E%87/872374?fr=aladdin" target="_blank" rel="noopener">图像分辨率</a></h4><blockquote><p>图像分辨率指图像中存储的信息量，是每英寸图像内有多少个像素点，分辨率的单位为PPI(Pixels Per Inch)，通常叫做像素每英寸。图像分辨率一般被用于ps中，用来改变图像的清晰度。</p></blockquote><h5 id="0-1-4-1图像分辨率原理"><a href="#0-1-4-1图像分辨率原理" class="headerlink" title="0.1.4.1图像分辨率原理"></a>0.1.4.1图像分辨率原理</h5><blockquote><p>数码图像有两大类，一类是矢量图，也叫向量图；另一类是点阵图，也叫位图。矢量图比较简单，它是由大量数学方程式创建的，其图形是由线条和填充颜色的块面构成的，而不是由像素组成的，对这种图形进行放大和缩小，不会引起图形失真。<br>点阵图很复杂，是通过摄像机、数码相机和扫描仪等设备，利用扫描的方法获得，由像素组成的，是以每英寸的像素数（PPI）来衡量。点阵图具有精细的图像结构、丰富的灰度层次和广阔的颜色阶调。当然，矢量图经过图像软件的处理，也可以转换成点阵图。家庭影院所使用的图像，动画片的原图属于矢量图一类，但经过制作中的转化，已经和其他电影片一样，也属于点阵图一类了。</p></blockquote><h4 id="0-1-5显示分辨率"><a href="#0-1-5显示分辨率" class="headerlink" title="0.1.5显示分辨率"></a>0.1.5<a href="https://baike.baidu.com/item/%E6%98%BE%E7%A4%BA%E5%88%86%E8%BE%A8%E7%8E%87/3431933?fr=aladdin" target="_blank" rel="noopener">显示分辨率</a></h4><blockquote><p>显示分辨率是显示器在显示图像时的分辨率，分辨率是用点来衡量的，显示器上这个“点”就是指像素(pixel)。显示分辨率的数值是指整个显示器所有可视面积上水平像素和垂直像素的数量。例如800×600的分辨率，是指在整个屏幕上水平显示800个像素，垂直显示600个像素。</p></blockquote><h5 id="0-1-5-1清晰度和眼睛辨识度的关系"><a href="#0-1-5-1清晰度和眼睛辨识度的关系" class="headerlink" title="0.1.5.1清晰度和眼睛辨识度的关系"></a>0.1.5.1清晰度和眼睛辨识度的关系</h5><blockquote><p><img alt="视觉效果和绝对清晰度" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer4wE9l3mtiayiaSqldER20ae1U1k8Aqic8aQMoibic0rOvXApjibFvmO5sDBvwhOSymW8vfPFwdjOkuYClg/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="0-1-6像素深度"><a href="#0-1-6像素深度" class="headerlink" title="0.1.6像素深度"></a>0.1.6像素深度</h4><blockquote><p>像素深度是指存储每个像素所用的位数，也用它来度量图像的分辨率。像素深度决定彩色图像的每个像素可能有的颜色数，或者确定灰度图像的每个像素可能有的灰度级数。<br>例如，一幅彩色图像的每个像素用R，G，B三个分量表示，若每个分量用8位，那么一个像素共用24位表示，就说像素的深度为24，每个像素可以是16 777 216（2的24次方）种颜色中的一种。在这个意义上，往往把像素深度说成是图像深度。表示一个像素的位数越多，它能表达的颜色数目就越多，而它的深度就越深。</p></blockquote><h4 id="0-1-7位面数量"><a href="#0-1-7位面数量" class="headerlink" title="0.1.7位面数量"></a>0.1.7位面数量</h4><blockquote><p>一幅图像的位面数量相当于组成图像的像素矩阵维数。<br>灰度图像一个位面<br>彩色图像三个位面：红色分量、蓝色分量、绿色分量<br>假定图像尺寸、，每个像素所具有的离散灰度级数为，,那么存储这幅图像所需的位数以及所需的字节数如下：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer4wE9l3mtiayiaSqldER20ae14SYjTyy1Tm3PYJfg1K0CEnc61Q9muFFQuexE2HY7icN4uEKSFsL7erA/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="0-1-8邻域与邻接"><a href="#0-1-8邻域与邻接" class="headerlink" title="0.1.8邻域与邻接"></a>0.1.8邻域与邻接</h4><h5 id="0-1-8-1领域"><a href="#0-1-8-1领域" class="headerlink" title="0.1.8.1领域"></a>0.1.8.1领域</h5><blockquote><p>邻域：数字图像中，邻域分为4邻域和8邻域，4邻域就是某个（x,y）点的上下左右四个点，8邻域再加上左上右上左下右下四个点。如果p在q周围的8个点内，就是p在q的8邻域内。</p></blockquote><h6 id="0-1-8-1-1四邻域"><a href="#0-1-8-1-1四邻域" class="headerlink" title="0.1.8.1.1四邻域"></a>0.1.8.1.1四邻域</h6><blockquote><p><img alt="4邻域" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer4wE9l3mtiayiaSqldER20ae1bKNfk2OWZXln7rVezatbx5Sor4xrEdHAr3zJcXWTdttBAnicgOYDwKg/0?wx_fmt=png" class="lazyload"></p></blockquote><h6 id="0-1-8-1-2对角邻域"><a href="#0-1-8-1-2对角邻域" class="headerlink" title="0.1.8.1.2对角邻域"></a>0.1.8.1.2对角邻域</h6><blockquote><p><img alt="对角邻域" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer4wE9l3mtiayiaSqldER20ae1ibqo9j5aibUGTpzd4b7rubXqibUR2c53HnodUxE28t3r5AzZ9ypfm1CNg/0?wx_fmt=png" class="lazyload"></p></blockquote><h6 id="0-1-8-1-3八邻域"><a href="#0-1-8-1-3八邻域" class="headerlink" title="0.1.8.1.3八邻域"></a>0.1.8.1.3八邻域</h6><blockquote><p>4邻域和对角邻域的并集就是8邻域</p></blockquote><h5 id="0-1-8-2邻接"><a href="#0-1-8-2邻接" class="headerlink" title="0.1.8.2邻接"></a>0.1.8.2邻接</h5><blockquote><p>邻接：邻接算是包含了邻域，如果说p和q是邻接，那么p和q必须互在邻域内，而且这两个的像素还要都在同一个集合V1内。（什么叫都在集合V1内：假如集合V1包含{012345}，这五个数代表的是像素值，而p值为2，q值为6，那它们两个就不在同一个集合V1内，当然如果有个集合V2，它俩可能也在另一个集合V2内）数字图像中常见的邻接有三种，4邻接、8邻接和m邻接。如果p在q的4邻域内，且q和p的值都在V中，那么p和q是4邻接的，8邻接概念一样。m邻接（mixed，混合邻接）不太一样，如果q和p互在8邻域内，p和q都在V内，且q的4邻域和p的4邻域的共同覆盖的点不在V内，则p和q是m邻接的。m邻接是为了消除8邻接的二义性而引进的。比如有个3*3矩阵{0,1，1；0,1,0；0,0,1}，假设对于V={1}的集合而言，如果两个点能构成邻接，就算有一条路可以通过，那么右上角的1走到右下角的1，如果按照8邻接有两条路，而按照m邻接，只有一条路，这就是m邻接提出的意义。</p></blockquote><h6 id="0-1-8-2-1四-邻接"><a href="#0-1-8-2-1四-邻接" class="headerlink" title="0.1.8.2.1四-邻接"></a>0.1.8.2.1四-邻接</h6><blockquote><ul><li>2个像素p和q在V中取值；</li><li>且q在中p的4邻域中<br><img alt="4-邻接" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer4wE9l3mtiayiaSqldER20ae13XNEC0oRQRCqnWUpWg7jRGyAf5tJsDUgUqAPFfjvdylNncUuaRSFlw/0?wx_fmt=png" class="lazyload"></li></ul></blockquote><h6 id="0-1-8-2-2八-邻域"><a href="#0-1-8-2-2八-邻域" class="headerlink" title="0.1.8.2.2八-邻域"></a>0.1.8.2.2八-邻域</h6><blockquote><ul><li>2个像素p和q在V中取值；</li><li>且q在中p的8邻域中<br><img alt="8-邻域" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer4wE9l3mtiayiaSqldER20ae1j8PAsJ7ibtuAOaiaQuXfmflMHX4WOC8iahvPb2r7Y4ePvTrQW1Le5Zwjg/0?wx_fmt=png" class="lazyload"></li></ul></blockquote><h6 id="0-1-8-2-3四-邻接和八-邻接的关系"><a href="#0-1-8-2-3四-邻接和八-邻接的关系" class="headerlink" title="0.1.8.2.3四-邻接和八-邻接的关系"></a>0.1.8.2.3四-邻接和八-邻接的关系</h6><blockquote><p>2个像素p和q在V中取值且满足下列条件之一<br>   1.q在中p的4-邻域中<br>   2.q在中p的对角邻域中且集合N(4)(p)和N(4)(q)是空集<br><img alt="4和8邻接的关系" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer4wE9l3mtiayiaSqldER20ae1dW9AibqwlcEo5wgAUhTnDe96PTqsRRs6GNoGvSj18tq26ykFur4JSxw/0?wx_fmt=png" class="lazyload"><br> <strong>实质：</strong><br> 当像素间同时存在4-邻接和8-邻接时，优先采用4-邻接，屏蔽两个和统一像素间存在4-邻接的像素之间的8-邻接。</p></blockquote><h6 id="0-1-8-2-2-3m-邻接（混合邻接）"><a href="#0-1-8-2-2-3m-邻接（混合邻接）" class="headerlink" title="0.1.8.2.2.3m-邻接（混合邻接）"></a>0.1.8.2.2.3m-邻接（混合邻接）</h6><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rE8U6LpS2RzWexVu1agtX8WwUy4m9eLlMXZD3eXMa5aicB1oQavjbnSQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rTxKERFicjhmFE35qaRLhP7k1eU3NbDhYOcdsictcgcXlnDW7JicaBCcLg/0?wx_fmt=png" class="lazyload"><br>实质：当像素间同时存在4-邻接和8-邻接时，优先采用4-邻接，屏蔽两个和统一像素间存在4-邻接的像素之间的8-邻接。</p></blockquote><h4 id="0-1-9连通性"><a href="#0-1-9连通性" class="headerlink" title="0.1.9连通性"></a>0.1.9连通性</h4><h5 id="0-1-9-1通路"><a href="#0-1-9-1通路" class="headerlink" title="0.1.9.1通路"></a>0.1.9.1通路</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rEG5QUmvEKqpdQ0085EiaWOB5GmEYgzJdaxXLgqGiblUBVyE8BCibRetYQ/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="0-1-9-2连通"><a href="#0-1-9-2连通" class="headerlink" title="0.1.9.2连通"></a>0.1.9.2连通</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rsPPxO4D0DDGmK1cabQib1KemktllpeTYEA6FISBHCMdROuX9OdhaY0w/0?wx_fmt=png" class="lazyload"><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rp80EzTNAOTuvX2JhDeU1iay1cgE223YgaDibOKIJXEHW1vJ3sj9KRmIQ/0?wx_fmt=png" class="lazyload"><br>实例：像素s和t间（上图）<br>4-连通：不存在<br>8-连通：2条<br>m-连通：1条</p></blockquote><h4 id="0-1-10距离度量"><a href="#0-1-10距离度量" class="headerlink" title="0.1.10距离度量"></a>0.1.10距离度量</h4><h5 id="0-1-10-1距离"><a href="#0-1-10-1距离" class="headerlink" title="0.1.10.1距离"></a>0.1.10.1距离</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rWXQp7PuadcTCTkHsRZO3PoPNng1rTroCr6f4qic0wk2eJmP2TMKGZKA/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="0-1-10-2欧氏距离"><a href="#0-1-10-2欧氏距离" class="headerlink" title="0.1.10.2欧氏距离"></a>0.1.10.2欧氏距离</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7ry1oic2TMHDQlictuhUibIo8QyxbhGbBCiaicGsicyoIZmoPyI1wuUI44b1pA/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="0-1-10-3城市距离"><a href="#0-1-10-3城市距离" class="headerlink" title="0.1.10.3城市距离"></a>0.1.10.3城市距离</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rJruicqZdG795cZeHulgBHQOsHn2l9hBAib0HF7ib98SyuxIWZBSpqoGxw/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="0-1-11数字图像格式"><a href="#0-1-11数字图像格式" class="headerlink" title="0.1.11数字图像格式"></a>0.1.11数字图像格式</h4><h5 id="0-1-11-1矢量图"><a href="#0-1-11-1矢量图" class="headerlink" title="0.1.11.1矢量图"></a>0.1.11.1矢量图</h5><blockquote><p>用数学公式描述的图像，用一系列绘图指令表示图像；图像中每个形状都用一个完整的公式描述，称为一个对象。<br>优点：<br>A．文件数据量很小；<br>B．图像质量与分辨率无关；<br>无论图像放大或缩小多少倍，总是以显示设备允许的最大清晰度显示。计算机计算与显示图像时，往往能看到画图的过程。<br>缺点：<br>A．不易制作色调丰富或色彩变化太多的图像；<br>B．绘出来的图像不是很逼真；<br>C．不易在不同的软件间交换文件。</p></blockquote><h5 id="0-1-11-2位图"><a href="#0-1-11-2位图" class="headerlink" title="0.1.11.2位图"></a>0.1.11.2位图</h5><blockquote><p>通过像素点表示图像，每个像素具有颜色属性和位置属性。<br>优点：<br>A．显示速度快；<br>B．真实世界的图像可以通过扫描仪、数码相机、摄像机等设备方便的转化为点位图<br>缺点：<br>A．存储和传输时数据量比较大；<br>B．缩放、旋转时算法复杂且容易失真</p></blockquote><h6 id="0-1-11-2-1线画稿-Line-Art"><a href="#0-1-11-2-1线画稿-Line-Art" class="headerlink" title="0.1.11.2.1线画稿(Line Art)"></a>0.1.11.2.1线画稿(Line Art)</h6><blockquote><p>只有黑白两种颜色。适合于由黑白两色构成而没有灰度阴影的图像。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7ralP8Ia0BzaCibib64O8fHGFd3ib7ib8Y9evibNKvBX9A6npuv9AQ3HFTJBw/0?wx_fmt=png" class="lazyload"></p></blockquote><h6 id="0-1-11-2灰度图像-GrayScale"><a href="#0-1-11-2灰度图像-GrayScale" class="headerlink" title="0.1.11.2灰度图像(GrayScale)"></a>0.1.11.2灰度图像(GrayScale)</h6><blockquote><p>从技术上说，就是具有从黑到白的若干种灰度的单色图像。<br>若灰度图像像素的灰度级用8bit表示，则每个像素都是介于黑色和白色之间的256(28=256)种灰度种的一种.<br>通常所说的黑白图片，其实包含了黑白之间的所有灰度色调。</p></blockquote><h6 id="0-1-11-3索引颜色图像-Index-Color"><a href="#0-1-11-3索引颜色图像-Index-Color" class="headerlink" title="0.1.11.3索引颜色图像(Index Color)"></a>0.1.11.3索引颜色图像(Index Color)</h6><blockquote><p>索引颜色通常也称为映射颜色。在这种模式下，颜色是一组预先定义的、有限的颜色。<br>索引颜色的图像最多只能显示256中颜色。<br>索引颜色图像在图像文件里定义索引颜色。打开该文件时，构成该图像具有颜色的索引值就被读入程序里，然后根据索引值找到最终的颜色。</p></blockquote><h6 id="0-1-11-4真彩色图像-True-Color-24位图"><a href="#0-1-11-4真彩色图像-True-Color-24位图" class="headerlink" title="0.1.11.4真彩色图像(True Color)-24位图"></a>0.1.11.4真彩色图像(True Color)-24位图</h6><blockquote><p>自然界中几乎所有颜色都可以有红、绿、蓝（R、G、B）组合而成。<br>真彩色图像中，每一个像素由红、绿和蓝三个字节组成，每个字节为8bit，表示0到255之间的不同的亮度值。<br>256×256×256，能表示约1670万种颜色。<br>颜色深度为每个像素24位的数字图像是目前所能获取、浏览和保存的颜色信息最丰富的彩色图像，由于它所表达的颜色远远超出了人眼所能辨别的范围，故将其称为“真彩色”。<br>真彩色图并不是说一幅图包含了所有的颜色，而是说它具有所有颜色的能力，即最多可以包含所有的颜色。<br><strong>常见RGB颜色：</strong><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rqO34xyqcK6ASR7eHkIn1fJRwBle8RiarSicFUiay3Js9XLniaY6mxaP6WQ/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="0-1-12图像文件格式"><a href="#0-1-12图像文件格式" class="headerlink" title="0.1.12图像文件格式"></a>0.1.12图像文件格式</h4><blockquote><p>图像文件的格式，即图像文件的数据构成。<br>一般每种图像文件均有一个文件头，在文件头之后是图像数据。<br>文件头：一般包含文件类型、文件制作者、制作时间、版本号、文件大小等内容。内容由制作该图像文件的公司决定<br>图像数据：各种图像文件的制作还涉及到图像文件的压缩方式和存储效率等。<br>数字图像有多种存储格式，每种格式一般由不同的开发商支持。随着信息技术的发展和图像应用领域的不断拓宽，还会出现新的图像格式。<br>图像文件格式体系<br>1.互联网用：GIF、JPG、PNG<br>2.印刷用：TIF、JPG、TAG、PCX<br>3.国际标准：TIF、JPG</p></blockquote><h5 id="0-1-12-1BMP格式"><a href="#0-1-12-1BMP格式" class="headerlink" title="0.1.12.1BMP格式"></a>0.1.12.1<strong>BMP</strong>格式</h5><h6 id="0-1-12-1-1位图文件头"><a href="#0-1-12-1-1位图文件头" class="headerlink" title="0.1.12.1.1位图文件头"></a>0.1.12.1.1位图文件头</h6><blockquote><p>位图文件图是一个结构，其定义如下：<img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rADsCwugYGDX5KFHQ87hTJ1SthvKCtNUQB0zwaDiarltwcZceuTvLKaQ/0?wx_fmt=png" class="lazyload">结构长度固定，为14个字节（WORD为无符号16位整数，DWORD为无符号32位整数）</p></blockquote><h6 id="0-1-12-1-2位图信息头"><a href="#0-1-12-1-2位图信息头" class="headerlink" title="0.1.12.1.2位图信息头"></a>0.1.12.1.2位图信息头</h6><blockquote><p>位图信息头是一个结构，其定义如下：<img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rmOvXFv8m46VklC0TepE9mGJaRTg48Td74iby6SKVor6jAiaTPrPjU38w/0?wx_fmt=png" class="lazyload">结构长度为40个字节（LONG为32位整数）</p></blockquote><h6 id="0-1-12-1-3调色板"><a href="#0-1-12-1-3调色板" class="headerlink" title="0.1.12.1.3调色板"></a>0.1.12.1.3调色板</h6><blockquote><p>实际上是一个数组，共有biClrUsed个元素。数组中每个元素的类型是是一个RGBQUAD结构，占4个字节。<img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rYQqEmQwgw2obmgR4rVToERAQS3vJibLrT3nBrUfVhick7feMLb9YGPcQ/0?wx_fmt=png" class="lazyload">真彩色图像不需要调色板，BITMAPINFOHEADER后直接是位图数据。</p></blockquote><h6 id="0-1-12-1-4实际的位图数据"><a href="#0-1-12-1-4实际的位图数据" class="headerlink" title="0.1.12.1.4实际的位图数据"></a>0.1.12.1.4实际的位图数据</h6><blockquote><p>真彩色图像，图像数据就是实际的R、G、B值，三个字节表示1个像素。<br>对于用到调色板的位图，图像数据就是该像素颜色在调色板中的索引值。<br>2色位图，用1位就可以表示该像素的颜色（一般0表示黑，1表示百=白），所以一个字节可以表示8个像素。<br>16色位图，用4位可以表示一个像素的颜色，所以一个字节可以表示2个像素。<br>256色位图，一个字节刚好可以表示1个像素。<br>下面两点需注意：<br>(1)每一行的字节数必须是4的整数倍，如果不是，则需要补齐。<br>(2)BMP文件的数据存放是从下到上，从左到右的。<br>从文件中最先读到的是图像最下面一行的左边第一个像素，然后是左边第二个像素，接下来是倒数第二行左边第一个像素，左边第二个像素。以此类推，最后得到的是最上面一行的最右边的一个像素。</p></blockquote><h6 id="0-1-12-1-5例子"><a href="#0-1-12-1-5例子" class="headerlink" title="0.1.12.1.5例子"></a>0.1.12.1.5例子</h6><p>例1：</p><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r8sZGnq7tNGj7l1T74C0ibyhSCbOaBmtprrqnVZauxkmeooFTHMfgYWw/0?wx_fmt=png" class="lazyload"><br>200×200×3×8bit,每个像素需要用3个字节 120k字节<br>图像中最多只有16中颜色。用一个表：表中的每一行记录一种颜色RGB值。当表示一个像素的颜色时，只需要指出该颜色是在第几行，即该颜色在表中的索引值。<br>表占用的字节为3(RGB) ×8(bit) ×16(颜色)=48字节<br>16种颜色可以用4bit表示，一个像素要用半个字节。整个图像要用200×200×0.5，约20k字节，约为前面的1/6。<br>RGB表，即调色板。</p></blockquote><p>例2：</p><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rJIwPC6TutoaPKMk1yDdRAn41CVm4IQCyemOWjyMRmFVs1nkzjXUrFQ/0?wx_fmt=png" class="lazyload">反色（invert）:就是形成底片效果。<br>反色的实际含义是将R、G、B值反转。<br>若颜色的量化级别是256，则新图的R、G、B值为255减去原图的R、G、B值。包括真彩图、带调色板的彩色图（伪彩色图）和灰度图。<br>真彩图：把反转后的R、G、B值写入新图即可。<br>带调色板彩色图：只需要将调色板中的颜色反转，形成新调色板，位图数据不动。<br>灰度图：直接反转。</p></blockquote><h3 id="0-2数学概念"><a href="#0-2数学概念" class="headerlink" title="0.2数学概念"></a>0.2数学概念</h3><h4 id="0-2-1算子"><a href="#0-2-1算子" class="headerlink" title="0.2.1算子"></a>0.2.1<a href="https://baike.baidu.com/item/%E7%AE%97%E5%AD%90/970194?fr=aladdin" target="_blank" rel="noopener">算子</a></h4><blockquote><p>算子是一个函数空间到函数空间上的映射O：X→X。广义上的算子可以推广到任何空间，如内积空间等。<br>广义的讲，对任何函数进行某一项操作都可以认为是一个算子，甚至包括求幂次，开方都可以认为是一个算子，只是有的算子我们用了一个符号来代替他所要进行的运算罢了，所以大家看到算子就不要纠结，他和 的 没区别，它甚至和加减乘除的基本运算符号都没有区别，只是他可以对单对象操作罢了(有的符号比如大于、小于号要对多对象操作)。又比如取概率P{X&lt;x}，概率是集合{X&lt;x}(他是属于实数集的子集)对[0,1]区间的一个映射，我们知道实数域和[0,1]区间是可以一一映射的(这个后面再说)，所以取概率符号P，我们认为也是一个算子，和微分，积分算子算子没区别。总而言之，算子就是映射，就是关系，就是变换。</p></blockquote><h4 id="0-2-2卷积"><a href="#0-2-2卷积" class="headerlink" title="0.2.2卷积"></a>0.2.2<a href="https://baike.baidu.com/item/%E5%8D%B7%E7%A7%AF/9411006?fr=aladdin" target="_blank" rel="noopener">卷积</a></h4><blockquote><p>在泛函分析中，卷积、旋积或摺积(英语：Convolution)是通过两个函数f 和g 生成第三个函数的一种数学算子，表征函数f 与g经过翻转和平移的重叠部分函数值乘积对重叠长度的积分。<br>如果将参加卷积的一个函数看作区间的指示函数，卷积还可以被看作是“滑动平均”的推广。</p></blockquote><h5 id="0-2-2-1定义"><a href="#0-2-2-1定义" class="headerlink" title="0.2.2.1定义"></a>0.2.2.1定义</h5><blockquote><p><img alt="卷积定义" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer4wE9l3mtiayiaSqldER20ae1QZq0Jk3sy7ro3xIaskaB5VN3farg1JdId0Xjuoyetw0icnaUhp5QKnQ/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="0-2-3平滑算子"><a href="#0-2-3平滑算子" class="headerlink" title="0.2.3平滑算子"></a>0.2.3平滑算子</h4><h4 id="0-2-4梯度算法（梯度下降）"><a href="#0-2-4梯度算法（梯度下降）" class="headerlink" title="0.2.4梯度算法（梯度下降）"></a>0.2.4梯度算法（<a href="https://baike.baidu.com/item/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/4864937?fr=aladdin" target="_blank" rel="noopener">梯度下降</a>）</h4><h5 id="0-2-4-1定义"><a href="#0-2-4-1定义" class="headerlink" title="0.2.4.1定义"></a>0.2.4.1定义</h5><blockquote><p>梯度下降是迭代法的一种,可以用于求解最小二乘问题(线性和非线性都可以)。在求解机器学习算法的模型参数，即无约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一，另一种常用的方法是最小二乘法。在求解损失函数的最小值时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数和模型参数值。反过来，如果我们需要求解损失函数的最大值，这时就需要用梯度上升法来迭代了。在机器学习中，基于基本的梯度下降法发展了两种梯度下降方法，分别为随机梯度下降法和批量梯度下降法。</p></blockquote><h5 id="0-2-4-2简介"><a href="#0-2-4-2简介" class="headerlink" title="0.2.4.2简介"></a>0.2.4.2简介</h5><blockquote><p><img alt data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer4wE9l3mtiayiaSqldER20ae1Ef1VA5GIXWhr8TiaF6xLpkvOpJPHTbdXMIDNwhIFTR6u5fib0TGLueWg/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="0-2-4-3缺点"><a href="#0-2-4-3缺点" class="headerlink" title="0.2.4.3缺点"></a>0.2.4.3缺点</h5><blockquote><ul><li>靠近极小值时收敛速度减慢。</li><li>直线搜索时可能会产生一些问题。</li><li>可能会“之字形”地下降。</li></ul></blockquote><h5 id="0-2-4-4求解过程"><a href="#0-2-4-4求解过程" class="headerlink" title="0.2.4.4求解过程"></a>0.2.4.4求解过程</h5><blockquote><p><img alt data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer4wE9l3mtiayiaSqldER20ae1nbnGicbGYu96LELUZj81bm4hu25dc8xd7BHzzKgQNNtD3OnYWAI58qA/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="0-2-5概率密度"><a href="#0-2-5概率密度" class="headerlink" title="0.2.5概率密度"></a>0.2.5<a href="https://blog.csdn.net/sigai_csdn/article/details/83586458" target="_blank" rel="noopener">概率密度</a></h4><blockquote><p>概率指事件随机发生的机率，对于均匀分布函数，概率密度等于一段区间(事件的取值范围)的概率除以该段区间的长度，它的值是非负的，可以很大也可以很小。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rSwU52HTTXDDMO4PmoE8EicfPXdvGUZwMoMCnGuc1ylTD8Vj52Ynp5cw/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="0-2-6分布函数"><a href="#0-2-6分布函数" class="headerlink" title="0.2.6分布函数"></a>0.2.6<a href="https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0/2439796?fr=aladdin" target="_blank" rel="noopener">分布函数</a></h4><blockquote><p>分布函数（英文Cumulative Distribution Function, 简称CDF），是概率统计中重要的函数，正是通过它，可用数学分析的方法来研究随机变量。分布函数是随机变量最重要的概率特征，分布函数可以完整地描述随机变量的统计规律，并且决定随机变量的一切其他概率特征。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rEoVS8IItEqvV6maMLrueJwjPb0sTEIHGg1oYhGLPtl8FXp4HicIULuQ/0?wx_fmt=png" class="lazyload"></p></blockquote><h2 id="1数字图像处理基础"><a href="#1数字图像处理基础" class="headerlink" title="1数字图像处理基础"></a>1数字图像处理基础</h2><h3 id="1-1直方图变化"><a href="#1-1直方图变化" class="headerlink" title="1.1直方图变化"></a>1.1直方图变化</h3><h4 id="1-1-1灰度直方图"><a href="#1-1-1灰度直方图" class="headerlink" title="1.1.1灰度直方图"></a>1.1.1灰度直方图</h4><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rsAqFmVm9Rg7BAtuvlx3ic58OeCJPgAbgib4o7VsnRyBrV9Q0VWTPeOUA/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rm5ftURKRiaHpsqysOb7EjL9mibPRiabD0JuRBIGcmuqkFGjib6FH8xE27A/0?wx_fmt=png" class="lazyload"><br>直方图性质<br>1.无空间信息；<br>2.直方图与图像一对多关系；<br>3.可叠加性（全图与子图像）<br><strong>直方图的作用：</strong><br>直方图反映了图像清晰程度。直方图均匀分布时，图像最清晰。<br>判断一幅图像是否清晰，查看是否合理的利用了全部被允许的灰度级。<br>一幅图像应该尽可能利用全部可能的灰度级。</p></blockquote><blockquote><p>中间灰度级像素多，动态范围小，图像对比度低。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rBDd8NRPGGHNouRicPZGrctibEPK7zZ3xG9SuaOhtNIEy20MeerGnNmXQ/0?wx_fmt=png" class="lazyload"></p></blockquote><blockquote><p>高灰度的像素占了绝大部分，图像偏亮。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rJ7U7RhrxILxylvQAC4WC5GjTDH198mNibFeAnVYExCJDcDEX1icsws9A/0?wx_fmt=png" class="lazyload"></p></blockquote><blockquote><p>过低、过高灰度级的像素占了绝大部分，对比度过大。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r1Os1g0t2m8m8cbKFD5xMibJ4V8SS82ceADXI3DCd9qz5TiadWZn3xvibQ/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="1-1-2直方图均衡化"><a href="#1-1-2直方图均衡化" class="headerlink" title="1.1.2直方图均衡化"></a>1.1.2直方图均衡化</h4><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rd76IrTV4ttic8HfSYb6hB2PY6YVbIQOb1c7G0vTBib3HSjIsIOLc8nIQ/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-1-2-1直方图均衡化灰度映射函数"><a href="#1-1-2-1直方图均衡化灰度映射函数" class="headerlink" title="1.1.2.1直方图均衡化灰度映射函数"></a>1.1.2.1直方图均衡化灰度映射函数</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rW3u4fmz8tBRTwmo9W7icn05b31chSskO1RsyApc5ZQ7LwMW0ibUK4fog/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rThPsvp88ZDCSCmftn1iacB2bDluWaw9Bp2afGAVHJUN3nAicPX0NJ94Q/0?wx_fmt=png" class="lazyload"><br><strong>步骤：</strong><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rx16yXjTWjI613ibm3r92IeYrbJhiaKlonhOKSfa8cIKoLrcNZ9ibZibXuw/0?wx_fmt=png" class="lazyload"></p></blockquote><blockquote><p><strong>例题：</strong><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rbca3PicibncFCSdwgZj2ppkojsSREqIgUa7SccibyicqY9D9S4gfoydxaw/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r8nUh2JJxSmb0BjOQcWFmQPhJkLxaczKaAwiamt8D97vabA6PZrDpoaw/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rRb0ywA2Ohb8nYUBf8xmJhDuwupQsYR3Dx1Vg630CluIP39pIvYTEiag/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r1rs2Xibr7uOmWjqxGIY76XPVYwrSakaiaZbXYaVusa97ewAD85ROOoPA/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7ruKBxk7Aq7CKvUS2nWd1PZjvjgyC9Lomqoa2M7hiaRk82nsP3QWNxyzA/0?wx_fmt=png" class="lazyload"><br>经过直方图处理后，出现了伪轮廓：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rmazAH0X7QDicXJ9icmKz3RGZoogBBBe9icRtjskO33AjChLKsibOvPRIZw/0?wx_fmt=png" class="lazyload"><br>直方图处理图像不适用的情况：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rBs0ictCicCzrqPgdCm4qPWjGlIzaEicJhkRaI0uXonNsoCVNl016QxPLQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rjyOyZqC60jue7J6ZHYbpONGpP1Doll3SdoDr7TuhBvJAGUa6YE3Fuw/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="1-1-3直方图规定化"><a href="#1-1-3直方图规定化" class="headerlink" title="1.1.3直方图规定化"></a>1.1.3直方图规定化</h4><blockquote><p>修改一幅图像的直方图，使得它与另一幅图像的直方图匹配或具有一种预先规定的函数形状。<br><strong>目标：</strong> <strong>突出感兴趣的灰度范围，使图像质量改善。</strong><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rO8bKgt8f96cUglDqkMmelMZAAghk1mHPX3bITfQjrHGKg9ErziblVhw/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rQltzMr45oUtEfyNNkAg1NqiaV9MnHusohnGlpoE954qgvALkQk1jZsQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rbzbZwbR83btrUP2DzxB1mNJNvqvf9uFZmOXJB4uVddAzVzE3oicrZyA/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7ra8IqHl1WKVIN309fD0yC9icqmGrDgUZibnfglVEodeH828TKQzAO12nQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rC11Mpk2tJnDMicDTye6XwIb4JerVdfBOByBW4TPrj2PRu6xuMxwDz0w/0?wx_fmt=png" class="lazyload"></p></blockquote><h3 id="1-2灰度变换"><a href="#1-2灰度变换" class="headerlink" title="1.2灰度变换"></a>1.2灰度变换</h3><blockquote><p><strong>定义：</strong><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r8KOmMHFMGRibE6FpKmWFpPWOFZRPlvANMCWYJ67ryBEB0tbS2gEa9yQ/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="1-2-1线性灰度变换"><a href="#1-2-1线性灰度变换" class="headerlink" title="1.2.1线性灰度变换"></a>1.2.1线性灰度变换</h4><blockquote><p><strong>定义：</strong><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rUhNpEncBJicOwYVFEhQVJJtp73S1cwbEibqYe90hQAd9xaFtG8HT59HQ/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-2-1-1加常数"><a href="#1-2-1-1加常数" class="headerlink" title="1.2.1.1加常数"></a>1.2.1.1加常数</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7ruhSc32MYibibyKDAVbpAOxXdQkulnzndFfcfzsibg8U8SuwweZ4ib04WDg/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rrrSlNQq2tTOXVKOJxcZeIwl0ZdA4YIJJGUPbLElQOEBCWib7fEtcJ8Q/0?wx_fmt=png" class="lazyload"><br>图像亮度增加：<img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rGFmIcZIZHzHDjicqoLxj1ThS3UT8Wicibia716Gp8Nvx0FhVcWqkeMgCicA/0?wx_fmt=png" class="lazyload"><br>图像亮度降低：<img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r2Jdkiam9YnibE2umJ3MmibK6bIWTJrzr4qJVWf1J8z10GUxtibd9mWKwtg/0?wx_fmt=png" class="lazyload"><br>对比度降低：<img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rwH0ib2qia3ciarf6Fx6QibrW5tOAcLVg1Y4v9qHRiay9wgVdqiahbUq2Ou0Q/0?wx_fmt=png" class="lazyload"><br>图像的反转公式：<img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7riaAOa8cAVfRBBmeic8iadCrPOYiaCOCu17j5mLbNvDpHICIsy4h1JT9aUw/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rYaL6X0FddMKxDK9brmIdMVCKv0Fvus372VG2ETzJJg8ibQyDqIS8wxg/0?wx_fmt=png" class="lazyload"><br>反转例子：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rNgOr9MKxMS7SVbicZpV8o71T5eUq4mgJv9crZlcPOLUl0pFYlNkDTlw/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-2-1-2乘常数"><a href="#1-2-1-2乘常数" class="headerlink" title="1.2.1.2乘常数"></a>1.2.1.2乘常数</h5><blockquote><p>公式：g(x,y)=C*f(x,y)<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r7LL3iahl67urH8CppgUGFUmBQGXIib6bbreNwfX3ibehZ223CWyKCgCUw/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rcIvbWRbT1XYviaBhpNRpaYHX8ODbkmxAhibQD6ibCUHcibxBwGKxSsnQGg/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r23djncLjVic7dxPTu0HCOWX8O6Y42I4lbvbGOialcQVsxvouArnwF0Sg/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rOZvpHaZQvBwW0ibdwvp1mFx8RQYrGhVR8nzgNDJVlJY83y0UgVJerMg/0?wx_fmt=png" class="lazyload"><br>线性灰度一般表达式：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rkh9yfVj9CYqgC9Z9qfDtKocFy0uuD1Hha9HPnwprzf47GsvaYKV5DQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rEhM3dhA39jvwrD3g3w24Kg8Dy3flUk8Cv8a3HFC4UHgqnuRDict975w/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="1-2-2-分段线性灰度变换"><a href="#1-2-2-分段线性灰度变换" class="headerlink" title="1.2.2 分段线性灰度变换"></a>1.2.2 分段线性灰度变换</h4><blockquote><p><strong>目的：将感兴趣的灰度范围线性拓展，相对抑制不感兴趣的灰度区域。</strong><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rOFoe29NYY8ia4zRIG6P3z4mMdJL2jCjyouaeNFlX4wf5C1UTGzZDWTA/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rxdpXCqeJZQuvy0h6AsRBXRcvibxYr6piaajU56qUXuxo6ZAgTXHvGUCw/0?wx_fmt=png" class="lazyload"><br>分段线性灰度变换例子：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rF6OHyYSiaGcxia8IXjcBSrccgcOIhU0nysbwTJbl6ZX0acMulDWxB4nw/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-2-2-1削波"><a href="#1-2-2-1削波" class="headerlink" title="1.2.2.1削波"></a>1.2.2.1削波</h5><blockquote><p><strong>削波(cliping)</strong> 可以看做是<strong>对比度拓展</strong>的一个特例。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7reZASibS2uKge0icWmmaWxQ24jUpicCRItvnqGOXFGgkE3jgew8tvxPRjQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7ryVIk5wWyXCe89SdC6iaEUKclppU3qXqBoLP5egmo79nhAtAO5kEQRuQ/0?wx_fmt=png" class="lazyload"><br>削波例子：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rZialJicqBdMK0N9buPyZPm3gjK8z1icOynOpKZu26j2XdAg83cMWKXz6Q/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-2-2-2阈值化"><a href="#1-2-2-2阈值化" class="headerlink" title="1.2.2.2阈值化"></a>1.2.2.2阈值化</h5><blockquote><p><strong>阈值化（thresholding）</strong> 可以看作是<strong>削波</strong>的一个特例。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7ryANhJicIEydwG6icxo3OgY62DoCY28icLXybx9tq5kDEE9Abvlln4jexg/0?wx_fmt=png" class="lazyload"><br>阈值化后的图像是<strong>黑白二值图</strong>。阈值化是<strong>灰度图像</strong>转<strong>二值图像</strong>的一种常用方法。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r0n5RK0WPZBRtMiahVjCkslGwpkicobGzibHgKsVdZam3o13CD9lIE4Peg/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rvBlCNl0KZBaYA3F5r3ibjmlMctNMPuBDvfXy7oYDUTiaibV7JSvaAVnMA/0?wx_fmt=png" class="lazyload"><br>阈值化处理后的结果，是一幅<strong>二值图像图</strong>。</p></blockquote><h5 id="1-2-2-3灰度窗口变换"><a href="#1-2-2-3灰度窗口变换" class="headerlink" title="1.2.2.3灰度窗口变换"></a>1.2.2.3灰度窗口变换</h5><blockquote><p>灰度窗口变换是将某一区间的<strong>灰度级</strong>和<strong>其它部分（背景）</strong> 分开。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rGEU0RtSK5B954pFexcRqA7D9ShUYeEVzF6pj2UXVqibucicC9JvHuOSw/0?wx_fmt=png" class="lazyload"><br>灰度窗口变换可以<strong>检测出在某一灰度窗口范围内的所有像素</strong>，是图像灰度分析中的一个有力工具。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7ribnyicicr7e6V19Rkl5NvKhy2FNLzej1WY7lDB4h2kKfFCC0YuwoPoKNg/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="1-2-3非线性灰度变换"><a href="#1-2-3非线性灰度变换" class="headerlink" title="1.2.3非线性灰度变换"></a>1.2.3非线性灰度变换</h4><h5 id="1-2-3-1对数变换"><a href="#1-2-3-1对数变换" class="headerlink" title="1.2.3.1对数变换"></a>1.2.3.1对数变换</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rLWq61oeNFRpaWibbcAlgPw0PvwTybDAv3TOCMFVngpK7QBGMhibpOOGA/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rtOdOJ66WdplUia0ayO37HPg8CwgNiacATMoehMIIapU8BecR9OwiaFzdA/0?wx_fmt=png" class="lazyload"><br>a,b,c是按需可以调整的参数。<br>低灰度区拓展，高灰度区压缩<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r6hIf9Bl8YWBggjA1EJwnIhs5AgicdSiawK2R5mdtZz7mpHRibgibn2faxQ/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-2-3-2指数变换"><a href="#1-2-3-2指数变换" class="headerlink" title="1.2.3.2指数变换"></a>1.2.3.2指数变换</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rZibcNGLvaOghZBHPbn6RNywu8BDQVZ0rjuCW4cszxaXLpGRbouZ0ndA/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rYEnzKyfVRVc1sxUVicfZz2OPuMibFVSDW0Xhfq1S4bRftk0Py2aKcDWQ/0?wx_fmt=png" class="lazyload"><br>a,b,c是按需可以调整的参数。<br>低灰度区压缩，高灰度区拓展<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rKDKbVen4fhuVA21wR70MxVhIWMibI185icd4UJKxFWnhuaBs0Iqtiakxw/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-2-3-3幂函数"><a href="#1-2-3-3幂函数" class="headerlink" title="1.2.3.3幂函数"></a>1.2.3.3幂函数</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rJHiaUE596C8JqgL2cQJZic141E2cySTCcXLaM15c8RDIPVEBicsDANBkA/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-2-3-4LUT-Look-Up-Table"><a href="#1-2-3-4LUT-Look-Up-Table" class="headerlink" title="1.2.3.4LUT(Look-Up-Table)"></a>1.2.3.4LUT(Look-Up-Table)</h5><blockquote><p>灰度级变换定义了输入像素值与输出像素之间的映射关系，通常通过<strong>查表</strong>实现。可用户自定义。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rDDhiaiaho3ognQX5y14LKs4gdT26OBicLPdNhHaFZphyehU731CJpTGrg/0?wx_fmt=png" class="lazyload"><br>组合使用：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r7fxvDkQpXjlibj9MzYXCSWl7pLY0yzSqK47QNtIThH2ex1ZkBwicDhkg/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rWYJJ8RVKTQXTbypMCYMV4IqDaWVoCXWKcol1uic46JoY7zQmXxUVp4w/0?wx_fmt=png" class="lazyload"></p></blockquote><h3 id="1-3图像运算"><a href="#1-3图像运算" class="headerlink" title="1.3图像运算"></a>1.3图像运算</h3><h4 id="1-3-1算术运算"><a href="#1-3-1算术运算" class="headerlink" title="1.3.1算术运算"></a>1.3.1算术运算</h4><blockquote><ul><li>加法、减法</li><li>乘法、除法</li></ul></blockquote><h5 id="1-3-1-1加法"><a href="#1-3-1-1加法" class="headerlink" title="1.3.1.1加法"></a>1.3.1.1加法</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r12aglLPOD3Eibho1H55WRxa0X7g4tMzgeic9VbATnXnfXhjsrpOHHwZw/0?wx_fmt=png" class="lazyload"><br>主要应用举例：<br>(1)去除“叠加性”噪声（多幅图像平均）<br>(2)生成图像叠加效果<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r1KXr9icUEnxJemwsbUD47O31kjsG29AES52TcDXGRB0SXMaDkIbvnBQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rv5kiaQsib3acMSIGqHfHDZicQwfYRxEUBr1p7fFhPmDqJK4w4fcQUcGhg/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-3-1-2减法"><a href="#1-3-1-2减法" class="headerlink" title="1.3.1.2减法"></a>1.3.1.2减法</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rfQlsONrJV81IcAtkD5mcSE20RDqwpgfibKMOZJXWkONLMLhqLyrg6BQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rIiaExwsv7NzA8yEl5ss968MxHlTRqOFcPd9yGTRdiajfZo5ozFJkSYNw/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7rVHDlRWK4RDLn5XtUQPR64zTUhnMu5WElrFic78y50jicib3x5iaLAicZkGw/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7re49wibiasFibMk2ciaWz0mJXm46lkGNgPFOw4FgjHYhm2NQtAbJJfHIIfQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7Arz2qUQp7S3Ysdc5CsF7r87bygfprA0piaJgIntzYiaWlia5uqWG8VO3D5dcZCwD72s6gP8cDQ4uGg/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-3-1-3乘法"><a href="#1-3-1-3乘法" class="headerlink" title="1.3.1.3乘法"></a>1.3.1.3乘法</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAWb3cb6O0ppSTUBxrXmpwibhY3iaGAjPiaed7IQWPyYnsf23OvSPyV0AYw/0?wx_fmt=png" class="lazyload"><br>主要应用举例：<br>(1)图像的<strong>局部显示</strong><br>(2)用<strong>二值蒙板图像</strong>与<strong>原图像</strong>做乘法<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAicPpoJwkey1nQBPNnenlICMU2l25OKw5QWGBwGDLsHyrcia8CicUeq1Uw/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAFtG5bJh4jMqdAQ5pf1GzicrEXO4HnaEoh5kWoiauZicwJVLC0smKFSuOA/0?wx_fmt=png" class="lazyload"><br><img alt="![enter description here](https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxA0f95iaCw7cQLejibZCZiaxOcBCVu57UoQ26tN5Yciafzp6YARKW9OykW4w/0?wx_fmt=png)" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxA0f95iaCw7cQLejibZCZiaxOcBCVu57UoQ26tN5Yciafzp6YARKW9OykW4w/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="1-3-2逻辑运算"><a href="#1-3-2逻辑运算" class="headerlink" title="1.3.2逻辑运算"></a>1.3.2逻辑运算</h4><blockquote><ul><li>与</li><li>或、异或</li></ul></blockquote><h5 id="1-3-2-1异或运算"><a href="#1-3-2-1异或运算" class="headerlink" title="1.3.2.1异或运算"></a>1.3.2.1异或运算</h5><blockquote><p>公式：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxA9C4N1GMiaV9adQAYDawNzcgEAO5cugXZWB8NkZ7Vnk4MJuRTRB0szCw/0?wx_fmt=png" class="lazyload"><br><strong>只有同时为0时才为0，否则都为1</strong><br>主要应用举例：<br>(1)获得相交子图像<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAZ4VZTcFgw5mMgufZsXudWNOarzKQMfWiadvtUsckaBrsMHPdT2fURtA/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-3-2-2或运算"><a href="#1-3-2-2或运算" class="headerlink" title="1.3.2.2或运算"></a>1.3.2.2或运算</h5><blockquote><p>公式：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxA4qiaC5ibv1C2wfTXXfh6kAicCtBzMicUBrZR60OSNDftsibd28TFOvEFUAQ/0?wx_fmt=png" class="lazyload">主要应用举例：<br>(1)合并子图像<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxANib50Bib8ygEIat7TBSjfY02NEAqY9TxJdUbVwoibKNia9oiaAA90G2ewqQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxA9A3skiavKTRstxsuugnic9TOqviaDNsQMRia2PvuAUbHJwW2oKSIUnWpSA/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-3-2-3与运算"><a href="#1-3-2-3与运算" class="headerlink" title="1.3.2.3与运算"></a>1.3.2.3与运算</h5><blockquote><p>公式：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAGBWNT4M49osiaj5Zw2Pg8icxWIbO9b7YKiaR0qrZ5ZVJunp18meYTW7qQ/0?wx_fmt=png" class="lazyload"><br>主要应用举例：<br>(1)求两个子图像的相交子图<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAME7ZaQ51Aiafib4Y3LWqFZsXW57vFyE8vEpUHNeic87cVeCkNXlqHNh9Q/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAzFibAwgZhRnOx7iazhwmSwwyZyibGFMRPckYwBlWNXYnicEtcCYMWaf2Bg/0?wx_fmt=png" class="lazyload"><br>比较运算：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAp7ebe0AXP41K4REtH7ibFhu7Ke2t5J6vxPjY59icxCRSx3yJd865gw8A/0?wx_fmt=png" class="lazyload"><br>上图从左到右执行平均、最大值、最小值、Clear if &gt;、Clear if =、Clear if &lt;操作。</p></blockquote><h3 id="1-4几何运算"><a href="#1-4几何运算" class="headerlink" title="1.4几何运算"></a>1.4几何运算</h3><blockquote><p>图像生成过程中，由于系统本身具有非线性或拍摄角度不同，会使生成的图像产生几何失真。几何失真一般分为系统失真和非系统失真，系统失真是有规律的、能预测的；非系统失真则是随机的。<br>例如：<br>(1)镜头畸变；<br>(2)遥感图像校正；<br>(3)图像配准（配准：同一目标两幅图像间的空间对准。）<br>几何变换不改变像素值，仅改变像素所在位置！<br>几何变换可以改变图像中物体之间的空间关系。这种运算可以看成是图像内的各物体在图像内移动的过程。例如，物体的转动、扭曲、倾斜、拉伸等，都是几何运算的结果。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAtzcO1eERz9gh9vib1TNHNbO3F18OxAqBhYVjAIzN16ZGKsc4EUbH2qQ/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="1-4-1基本几何变换定义"><a href="#1-4-1基本几何变换定义" class="headerlink" title="1.4.1基本几何变换定义"></a>1.4.1基本几何变换定义</h4><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxANsab78JArYJzRTVicDOKI9iclWulmrDQeCWicymCbGBImicw44IWspAjXA/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="1-4-2常用的基本几何变换"><a href="#1-4-2常用的基本几何变换" class="headerlink" title="1.4.2常用的基本几何变换"></a>1.4.2常用的基本几何变换</h4><h5 id="1-4-2-1平移变换"><a href="#1-4-2-1平移变换" class="headerlink" title="1.4.2.1平移变换"></a>1.4.2.1平移变换</h5><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxA0UZ0iawhfD6365kcCqPVSRDhyRh0c0IW4S49Z2S8sOMK2IWNcXwxYlw/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxATRzwNY6ibfLLGsT7FbFcl0QqcsT6IzZvXVs21pUHct7Zhg6GoRS5wbA/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAdpjvJ4C6tLR2S8v01ApJgBvBria0K8j7LQ5eDPk4qwScyicFL93hSCZg/0?wx_fmt=png" class="lazyload"><br>移出的部分被截断，文件大小不会改变，新点的值统一设成(0)或(255)<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxApN1d5P5nwibY3w8fyG0L5z18n9a5kcPywbBIXU3dj5gicYia3J7opqZxw/0?wx_fmt=png" class="lazyload"><br>拓展画布，文件大小改变</p></blockquote><h5 id="1-4-2-2镜像变换"><a href="#1-4-2-2镜像变换" class="headerlink" title="1.4.2.2镜像变换"></a>1.4.2.2镜像变换</h5><blockquote><p>包括水平镜像和垂直镜像两种。<br><strong>a、水平镜像</strong><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAtqv8XicYibibj1rLaFLXRGAHbQBueUGUCdo772aUoDkRLOGAe1WbPo6tw/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxA5b1THWO810Q2M2czxqKYTOf06icSExpdBxAOuPjUld9w14t05ViaJlwA/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAOCyrky80ibhiclicrus6Uh4jIZJ3Nezn9lIoGvXBM7lokSVFDpQTcJd5w/0?wx_fmt=png" class="lazyload"><br><strong>b、垂直图像</strong><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAtKMnB3oelM61KBVbrXOZJtv85KNsn5a0g1R1r9G5UiacbdY7wiaXFntA/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxASbFQXF3PFtr7ROE8TevsfsIkeicuicGT6LH94JS5h040bGiaAsYecDOyw/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAQ16LEuZRDK7ZDmucesYicbEODFPK4icLtIykwv4nICHXUbPZPnaS3pkw/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAaz0C7ibvhN08Mia0KwJeOLDicTcU8dqkxXTppPPB92icBOXKENgVl6C3Ww/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-4-2-3旋转变换"><a href="#1-4-2-3旋转变换" class="headerlink" title="1.4.2.3旋转变换"></a>1.4.2.3旋转变换</h5><blockquote><p>绕原点旋转-α度<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxA0vsLbKrG2ntdACpgibysKrIWnI1uqKvr2xAVUu8PCUE33uVJiaSmibgNQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAicFpibyYVVbgdfpc0yHwKAmJqk3gu5ibekgoYrP1ZwQcgx22kMmicy98AQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAv8NNHP1z1h1m4oohwibgxRfbk3SDMcRiaLH9uBzvN93nbpPzuuCmEZicg/0?wx_fmt=png" class="lazyload"><br>通常的做法是以图像的中心为圆心旋转<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAOgjYvHZnn5jkcnXF7VDeO119AnI3fTfjeG64rom79icT39bgzMP2YBg/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAa5KUfdnibJLCaDxX9Iw1J5BCVW61lQsae5LvjPUW9MHJI62niaJPicgibg/0?wx_fmt=png" class="lazyload"><br><strong>旋转出现的问题：</strong><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAtsicbKpNDvebvUDHOsia8bJd4lRFEJZZvZBib2SjJlfrOcdVAiaZFsjxyQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxA2gNia3yhMUd8AbhXh1RMibncvYtWWwNKwb057H6DIKyk7icyiajbJj6XBg/0?wx_fmt=png" class="lazyload"><br><strong>原因：</strong><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAeWhYmibSluiaf55g83JtWa2KjuP3gickiaNQaTicdqBCBo9mbphyYh3Rgng/0?wx_fmt=png" class="lazyload"><br>图像旋转后，出现了两个问题：<br>1)像素的排列不是完全按照原有的相邻关系。相邻像素之间只有8个方向。<br>2)会出现许多的空洞点。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAjCsfVic07TR9IXI7BfW57z3EibpKDbVSTcibEJTAQHvr7C2oiav923sZIw/0?wx_fmt=png" class="lazyload"><br>图像旋转出现的两个问题，本质都是因为像素值的填充不连续的。<br>采用插值填充的方法解决</p></blockquote><h5 id="1-4-2-4放缩变换"><a href="#1-4-2-4放缩变换" class="headerlink" title="1.4.2.4放缩变换"></a>1.4.2.4放缩变换</h5><blockquote><p>公式：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAVNpVxLiapf8yibjD9jIEsNa6IvyBNfiauLWEkDd4xkRpsV3zEb4FZt3Tw/0?wx_fmt=png" class="lazyload"><br>a.缩小<br>图像缩小实际上就是对原有的多个数据进行抽取，获得期望缩小尺寸的数据，并且尽量保持原有的特征不丢失。<br>最简单的方法就是等间隔地选取数据。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxANYEOWfcrbOwSsjog7icgcGWl5entKQ6YmQcy8YK9Zwb8abArM3uDepg/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAGoqlNELCVXv0ZrgqDJ6YIIm2G4awMum5Rq42ZfgbiayvWeUickV7REibA/0?wx_fmt=png" class="lazyload"><br>图像缩小后承载的信息量减小，所以画布可相应缩小。<br>b.放大<br>图像放大从字面上看，是图像缩小的逆操作，但是，从信息处理的角度来看，则难易程度完全不一样。<br>图像缩小是从多个信息中选出所需要的信息，而图像放大则是需要对多出的空位填入适当的新值，是信息的统计。<br>放大最简单的思想是，如果需要将原图像方法k倍，则将原图像中的每个像素值，填在新图像中对应的k*k大小字块中。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxA3KPcVD3AwRLBDcptdTHIvk5x5tLoKrkjbe0wA0JiayibHGNPu0znUVgg/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxADpWWC4aFjqEtZiaxWoe71cEiawD5ImU8DCSoty56uaTSicjRMhEGqd4Pw/0?wx_fmt=png" class="lazyload"><br>放大倍数太大，会出现马赛克效应。</p></blockquote><h5 id="1-4-2-5拉伸变换"><a href="#1-4-2-5拉伸变换" class="headerlink" title="1.4.2.5拉伸变换"></a>1.4.2.5拉伸变换</h5><blockquote><p>公式：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAJnicd2QZes9gCsQFqmTb4jA7m5v4yo9XVexuwBDmWVzOXibWGKKD3Gxg/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAqhcSsUAWff437A6bRl84iaJLJPBYroDkVvaMA2TiahbkxuL901s6ubhw/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="1-4-3灰度级插值"><a href="#1-4-3灰度级插值" class="headerlink" title="1.4.3灰度级插值"></a>1.4.3灰度级插值</h4><blockquote><p>旋转与放大图像时，产生了新的像素（漏点）。采用插值法，即利用邻域的像素来估计新的像素值。</p></blockquote><h5 id="1-4-3-1最近邻插值法"><a href="#1-4-3-1最近邻插值法" class="headerlink" title="1.4.3.1最近邻插值法"></a>1.4.3.1最近邻插值法</h5><blockquote><p>重复最临近点<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAjbmNZ4mVts3pmn6icyOFLjFMMsnb0ZDlNtGFt6JTNyibSUcKWZlxWgJg/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAQJF67NkMAN5PKdFDVhYGRgR8kZdLaiad96eziaqeMYjkIOicN29fBibmAQ/0?wx_fmt=png" class="lazyload"><br>方法倍数太大，出现马赛克效应。</p></blockquote><h5 id="1-4-3-2双线性插值"><a href="#1-4-3-2双线性插值" class="headerlink" title="1.4.3.2双线性插值"></a>1.4.3.2双线性插值</h5><blockquote><p>双线性插值是对最近邻的一种改进，即用线性内插方法，根据点的四个相邻点的灰度值，分别在x和y方向上进行两次插值，计算新值。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAKlo4lrF3jJt12SgicEENCg1aeicfia2TPeib8qQ2l8PVXtCic03d9iaBKr3Q/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxA8C9Z9gBuicZBgeh1l7JOXibebV2Kvq241U4wHbOvQQUXqtOeDhbp3o0Q/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAwXgv7bSjpaEj9hAQcYxlicAXecK6r53ONvrDXAPnTNicibzHX18uoJezA/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxA2YIW0grIpicibHPKGKgteIzN7GNG1BbjuGB2K6sr4FMstpbG1fiaiaqCkQ/0?wx_fmt=png" class="lazyload"></p></blockquote><h5 id="1-4-3-3高阶插值"><a href="#1-4-3-3高阶插值" class="headerlink" title="1.4.3.3高阶插值"></a>1.4.3.3高阶插值</h5><blockquote><p>三次立方插值<br>利用三次多项式s(x)来逼近理论上的最佳插值函数sin(x)/x，进行插值.<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAVoic9lghrN4IibbWCvGMh0OKJDwV2pEXtBUIrUMUnD9koCnxdNfMwQRg/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAPjUqCgQZUPiaN4TWTicomicWHhGM6qdJ9qdB1ufRCUw71icLEasCSLQC3w/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxARr4Sv4d1mfl8FOrKo1INFKs4g4SEbJicjSMficds5okxsg8dUEhibTwkQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxATa9hiaicwSe4QeK422GoUuLR1uBxMia1Nuly2DowNUbCawjKJAibgwsSmA/0?wx_fmt=png" class="lazyload"></p></blockquote><h2 id="2数字图像处理数学基础"><a href="#2数字图像处理数学基础" class="headerlink" title="2数字图像处理数学基础"></a>2数字图像处理数学基础</h2><h3 id="2-1线性系统理论"><a href="#2-1线性系统理论" class="headerlink" title="2.1线性系统理论"></a>2.1线性系统理论</h3><h4 id="2-1-1线性系统"><a href="#2-1-1线性系统" class="headerlink" title="2.1.1线性系统"></a>2.1.1线性系统</h4><blockquote><p>许多图像处理系统都可以用一个线性系统作为模型：<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxApXzac87FL0ibxkC0MXgQ1C3pXbF3DvdREqmZJaegibSQ1PzZedqBVpeA/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxArXNaBWBfnRHAB9eX6pAiayCo61pGJmL3muROa0WOQvaFEmIZxS8zQiaQ/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="2-1-2线性空间不变系统-Linear-Space-Invariant-LSI"><a href="#2-1-2线性空间不变系统-Linear-Space-Invariant-LSI" class="headerlink" title="2.1.2线性空间不变系统(Linear Space Invariant, LSI)"></a>2.1.2线性空间不变系统(Linear Space Invariant, LSI)</h4><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAkyWZK6Fay6Khv1t1vqibNfnQnMxZGX3fOGkzh1kfTD73O00HichYtTrQ/0?wx_fmt=png" class="lazyload"><br>如果系统响应与输入脉冲的中心位置无关，则该系统称为空间不变系统。<br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAYB9kPvzywWwmFRkXYgm0mxjPO9iaVp7xtm3iafBiaHiaIzDhyjSYnRk7HA/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="2-1-3卷积"><a href="#2-1-3卷积" class="headerlink" title="2.1.3卷积"></a>2.1.3卷积</h4><blockquote><p><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAWyt6PUMb8yWIw62DfprzzObrYBFpATA7IqYHgjqGpnLn4bhKGibtL5A/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxANRWxMjr30qcdK9MHwtXOuBujoRENrNHDvRc0zFdgSxn5ZkvV9ZAUkQ/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxAa3S9xgUY1WnnxrMaxZ1nSGEx8NSXEoMcibJ1xqWyOoB2FicCHwk6xRyg/0?wx_fmt=png" class="lazyload"><br><img alt="enter description here" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer7ubZW0Rpse3HEOYL6VkUxApPL2JElz7wnjGrHRypxNAUiaUTHUlY4vRYoibLUtGtMbExRdteFZXOCA/0?wx_fmt=png" class="lazyload"></p></blockquote><h2 id="1-正交变换"><a href="#1-正交变换" class="headerlink" title="1.正交变换"></a>1.正交变换</h2><h3 id="1-1正交变换"><a href="#1-1正交变换" class="headerlink" title="1.1正交变换"></a>1.1正交变换</h3><h4 id="1-1-1定义"><a href="#1-1-1定义" class="headerlink" title="1.1.1定义"></a>1.1.1定义</h4><p><img alt data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer6BP88nYMEBwvBo5DIBgq7qS96HTWvboxhIVP0k8uAxoF4Hv47eic0NibVb9yNzGXqmqWlsUuc7kLnQ/0?wx_fmt=png" class="lazyload"></p><h4 id="1-1-2正交矩阵"><a href="#1-1-2正交矩阵" class="headerlink" title="1.1.2正交矩阵"></a>1.1.2正交矩阵</h4><blockquote><p>定义：n级实矩阵A称为正交矩阵，如果A<em>A=E。(A</em>表示A的共轭转置，E是单位矩阵)  </p></blockquote><h4 id="1-1-3正交变换的性质"><a href="#1-1-3正交变换的性质" class="headerlink" title="1.1.3正交变换的性质"></a>1.1.3正交变换的性质</h4><p><img alt data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer6BP88nYMEBwvBo5DIBgq7qujuibz0vDSXvnjiaYTUicrGmH6hvlZJ6RSs6sHfBSvof0wkibibRJLZCWOA/0?wx_fmt=png" class="lazyload"></p><h4 id="1-1-4等价刻画"><a href="#1-1-4等价刻画" class="headerlink" title="1.1.4等价刻画"></a>1.1.4等价刻画</h4><p><img alt data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer6BP88nYMEBwvBo5DIBgq7qGDMzcpgpfreaIDoP6Vnu3B4OdkbW8SibxoFxNshfexJaZoCVN6gr7Jg/0?wx_fmt=png" class="lazyload"></p><h4 id="1-1-5正交变换分类"><a href="#1-1-5正交变换分类" class="headerlink" title="1.1.5正交变换分类"></a>1.1.5正交变换分类</h4><p><img alt data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer6BP88nYMEBwvBo5DIBgq7qsfdjlpfnq6KK4LEmO3k3F7iauFibyVdFOXyeibVKCSXIwwM5Ew2mk2XBQ/0?wx_fmt=png" class="lazyload"></p><h3 id="1-2傅立叶变换"><a href="#1-2傅立叶变换" class="headerlink" title="1.2傅立叶变换"></a>1.2<a href="https://baike.baidu.com/item/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/7119029?fromtitle=%E5%82%85%E7%AB%8B%E5%8F%B6%E5%8F%98%E6%8D%A2&fromid=3472079" target="_blank" rel="noopener">傅立叶变换</a></h3><h4 id="1-2-1概念"><a href="#1-2-1概念" class="headerlink" title="1.2.1概念"></a>1.2.1概念</h4><blockquote><p>傅立叶变换，表示能将满足一定条件的某个函数表示成三角函数（正弦和/或余弦函数）或者它们的积分的线性组合。在不同的研究领域，傅立叶变换具有多种不同的变体形式，如连续傅立叶变换和离散傅立叶变换。最初傅立叶分析是作为热过程的解析分析的工具被提出的。</p></blockquote><h4 id="1-2-2定义"><a href="#1-2-2定义" class="headerlink" title="1.2.2定义"></a>1.2.2定义</h4><p><img alt data-src="https://chuantu.xyz/t6/702/1572317923x1031866013.png" class="lazyload"></p><h4 id="1-2-3快速傅立叶变换（FFT）"><a href="#1-2-3快速傅立叶变换（FFT）" class="headerlink" title="1.2.3快速傅立叶变换（FFT）"></a>1.2.3<a href="https://baike.baidu.com/item/%E5%BF%AB%E9%80%9F%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/214957?fr=aladdin" target="_blank" rel="noopener">快速傅立叶变换</a>（FFT）</h4><h5 id="1-2-3-1概念"><a href="#1-2-3-1概念" class="headerlink" title="1.2.3.1概念"></a>1.2.3.1概念</h5><blockquote><p>快速傅里叶变换 (fast Fourier transform), 即利用计算机计算离散傅里叶变换（DFT)的高效、快速计算方法的统称，简称FFT。快速傅里叶变换是1965年由J.W.库利和T.W.图基提出的。采用这种算法能使计算机计算离散傅里叶变换所需要的乘法次数大为减少，特别是被变换的抽样点数N越多，FFT算法计算量的节省就越显著。</p></blockquote><h5 id="1-2-3-2基本思想"><a href="#1-2-3-2基本思想" class="headerlink" title="1.2.3.2基本思想"></a>1.2.3.2基本思想</h5><blockquote><p>FFT的基本思想是把原始的N点序列，依次分解成一系列的短序列。充分利用DFT计算式中指数因子 所具有的对称性质和周期性质，进而求出这些短序列相应的DFT并进行适当组合，达到删除重复计算，减少乘法运算和简化结构的目的。此后，在这思想基础上又开发了高基和分裂基等快速算法，随着数字技术的高速发展，1976年出现建立在数论和多项式理论基础上的维诺格勒傅里叶变换算法(WFTA）和素因子傅里叶变换算法。它们的共同特点是，当N是素数时，可以将DFT算转化为求循环卷积，从而更进一步减少乘法次数，提高速度。</p></blockquote><h3 id="1-3离散余弦变换-DCT"><a href="#1-3离散余弦变换-DCT" class="headerlink" title="1.3离散余弦变换(DCT)"></a>1.3<a href="https://www.jianshu.com/p/b923cd47ac4a" target="_blank" rel="noopener">离散余弦变换</a>(DCT)</h3><blockquote><p>离散余弦变换(DCT for Discrete Cosine Transform)是与傅里叶变换相关的一种变换，它类似于离散傅里叶变换(DFT for Discrete Fourier Transform),但是只使用实数。离散余弦变换相当于一个长度大概是它两倍的离散傅里叶变换，这个离散傅里叶变换是对一个实偶函数进行的（因为一个实偶函数的傅里叶变换仍然是一个实偶函数），在有些变形里面需要将输入或者输出的位置移动半个单位(DCT有8种标准类型，其中4种是常见的)。</p></blockquote><h4 id="1-3-1离散余弦变换应用"><a href="#1-3-1离散余弦变换应用" class="headerlink" title="1.3.1离散余弦变换应用"></a>1.3.1离散余弦变换应用</h4><blockquote><p>离散余弦变换，尤其是它的第二种类型，经常被信号处理和图像处理使用，用于对信号和图像(包括静止图像和运动图像)进行有损数据压缩。这是由于离散余弦变换具有很强的”能量集中”特性:大多数的自然信号(包括声音和图像)的能量都集中在离散余弦变换后的低频部分，而且当信号具有接近马尔科夫过程(Markov processes)的统计特性时，离散余弦变换的去相关性接近于K-L变换(Karhunen-Loève 变换–它具有最优的去相关性)的性能。<br>例如，在静止图像编码标准JPEG中，在运动图像编码标准MJPEG和MPEG的各个标准中都使用了离散余弦变换。在这些标准制中都使用了二维的第二种类型离散余弦变换，并将结果进行量化之后进行熵编码。这时对应第二种类型离散余弦变换中的n通常是8，并用该公式对每个8x8块的每行进行变换，然后每列进行变换。得到的是一个8x8的变换系数矩阵。其中(0,0)位置的元素就是直流分量，矩阵中的其他元素根据其位置表示不同频率的交流分量。<br>一个类似的变换, 改进的离散余弦变换被用在高级音频编码(AAC for Advanced Audio Coding)，Vorbis 和 MP3 音频压缩当中。<br>离散余弦变换也经常被用来使用谱方法来解偏微分方程，这时候离散余弦变换的不同的变量对应着数组两端不同的奇/偶边界条件。 </p></blockquote><h4 id="1-3-2matlab应用"><a href="#1-3-2matlab应用" class="headerlink" title="1.3.2matlab应用"></a>1.3.2matlab应用</h4><p><img alt="image" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer6pN9g3ibSe0rVRvEDAQ0MuG82jbia2qIOCXUyiakMbkG158XTWWBDZvicSwUI0Kst1nL8W2bpEYP69Og/0?wx_fmt=png" class="lazyload"></p><h4 id="1-3-3DCT性质"><a href="#1-3-3DCT性质" class="headerlink" title="1.3.3DCT性质"></a>1.3.3DCT性质</h4><p><img alt="image" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer6pN9g3ibSe0rVRvEDAQ0MuGENvXyTpibb2vxRN2UkBiaZJ4Njy3DL10IcYc7fgkFbib5wqEH3Wd3mEcg/0?wx_fmt=png" class="lazyload"></p><h3 id="1-4沃尔什变换"><a href="#1-4沃尔什变换" class="headerlink" title="1.4沃尔什变换"></a>1.4<a href="https://blog.csdn.net/grllery/article/details/89056484" target="_blank" rel="noopener">沃尔什变换</a></h3><blockquote><p>沃尔什变换（Walsh transform) 以沃尔什函数为基本函数的一种非正弦正交变换</p></blockquote><h4 id="1-4-1一维沃尔什变换"><a href="#1-4-1一维沃尔什变换" class="headerlink" title="1.4.1一维沃尔什变换"></a>1.4.1一维沃尔什变换</h4><p><img alt="image" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer6pN9g3ibSe0rVRvEDAQ0MuGSjKSQEsTyIvfBicwCdlhGnyGeEpqx5hhMuBeL99mPI0NkYUBas5Tdicw/0?wx_fmt=png" class="lazyload"></p><h5 id="1-4-1-1离散沃尔什变换"><a href="#1-4-1-1离散沃尔什变换" class="headerlink" title="1.4.1.1离散沃尔什变换"></a>1.4.1.1离散沃尔什变换</h5><p><img alt="image" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer6pN9g3ibSe0rVRvEDAQ0MuG9op0VPibVbfghQzkp7a6xCSjPPibBtY7hbEM9JGCQtBcgQeObKWDCMlA/0?wx_fmt=png" class="lazyload"></p><h5 id="1-4-1-2应用"><a href="#1-4-1-2应用" class="headerlink" title="1.4.1.2应用"></a>1.4.1.2应用</h5><p><img alt="image" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer6pN9g3ibSe0rVRvEDAQ0MuG4xYNrDqkArbdGQtveFibjly72AcibbdkuNGLkF3Av5Rqa6jNibJzlWrQg/0?wx_fmt=png" class="lazyload"></p><h4 id="1-4-2一维沃尔什反变换"><a href="#1-4-2一维沃尔什反变换" class="headerlink" title="1.4.2一维沃尔什反变换"></a>1.4.2一维沃尔什反变换</h4><p><img alt="image" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer6pN9g3ibSe0rVRvEDAQ0MuGSjKSQEsTyIvfBicwCdlhGnyGeEpqx5hhMuBeL99mPI0NkYUBas5Tdicw/0?wx_fmt=png" class="lazyload"></p><h3 id="1-5哈达玛变换"><a href="#1-5哈达玛变换" class="headerlink" title="1.5哈达玛变换"></a>1.5<a href="https://baike.baidu.com/item/%E5%93%88%E8%BE%BE%E7%8E%9B%E5%8F%98%E6%8D%A2/14679032?fr=aladdin" target="_blank" rel="noopener">哈达玛变换</a></h3><blockquote><p>哈达玛变换是遥感图像自动分类中一种常用的特征变换，是利用哈达玛矩阵作为变换矩阵新实施的遥感多光谱域变换<br><img alt="image" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer6pN9g3ibSe0rVRvEDAQ0MuGucVJ5DovR4x8oaWJHLobcm3yFTF7h3meqEBiasSfW3SiaPzkdOghhkYw/0?wx_fmt=png" class="lazyload"></p></blockquote><h4 id="1-5-1反变换"><a href="#1-5-1反变换" class="headerlink" title="1.5.1反变换"></a>1.5.1反变换</h4><p><img alt="image" data-src="https://mmbiz.qpic.cn/mmbiz_png/vAot1Iqrer6pN9g3ibSe0rVRvEDAQ0MuGUiaQD0zdiaKPpQtdFDndFOtzHjLwhumppCns0u0pogOPSvOhknwR0KlA/0?wx_fmt=png" class="lazyload"></p><h2 id="2-灰度变换"><a href="#2-灰度变换" class="headerlink" title="2.灰度变换"></a>2.<a href="https://baike.baidu.com/item/%E7%81%B0%E5%BA%A6%E5%8F%98%E6%8D%A2/20868243?fr=aladdin" target="_blank" rel="noopener">灰度变换</a></h2><p>一篇较好的关于灰度变换的博客<a href="https://www.cnblogs.com/laumians-notes/p/8629396.html" target="_blank" rel="noopener">more details</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机视觉 </tag>
            
            <tag> 基础知识 </tag>
            
            <tag> 数字图像处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为你的hexo个人博客添加本地搜索功能</title>
      <link href="/hexo-search-function/"/>
      <url>/hexo-search-function/</url>
      
        <content type="html"><![CDATA[<h3 id="1-下载安装包"><a href="#1-下载安装包" class="headerlink" title="1.下载安装包"></a>1.下载安装包</h3><p>先下载安装下面的安装包，进入到对应的博客目录里面执行下面的语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-search --save</span><br></pre></td></tr></table></figure><h3 id="2-配置themes下面的配置文件-config-yml"><a href="#2-配置themes下面的配置文件-config-yml" class="headerlink" title="2.配置themes下面的配置文件_config.yml"></a>2.配置themes下面的配置文件_config.yml</h3><p>将enable选项改为true 很重要，否则不会有效果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">local_search:</span><br><span class="line">  enable: true # 将false改为true</span><br><span class="line">  labels:</span><br><span class="line">    input_placeholder: Search for Posts</span><br><span class="line">    hits_empty: &quot;We didn&apos;t find any results for the search: $&#123;query&#125;&quot; # if there are no result</span><br></pre></td></tr></table></figure><h3 id="3-重新启动本地服务器"><a href="#3-重新启动本地服务器" class="headerlink" title="3.重新启动本地服务器"></a>3.重新启动本地服务器</h3><blockquote><p>hexo clean<br>hexo s -g //相当于 hexo g和hexo s一起执行</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> 本地搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/hello-world/"/>
      <url>/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
