<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>时间序列算法综述 | CrazyJums</title><meta name="description" content="时间序列预测的顺序 时间序列的正式定义如下：它是一系列在相同时间间隔内测量到的数据点。时间序列的特殊性是：该序列中的每个数据点都与先前的数据点相关。知乎问答：利用Auto ARIMA构建高性能时间序列模型（附Python和R代码）|source article #参考文献常见Markdown公式代码《时间序列分析》-作者：詹姆斯·D·汉密尔顿（James D.Hamilton）预测：方法与实践 1"><meta name="keywords" content="deep learning"><meta name="author" content="CrazyJums"><meta name="copyright" content="CrazyJums"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://jums.club/images/favicon_64.ico"><link rel="canonical" href="http://jums.club/time-series-forecasting-algorithm/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin="crossorigin"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="preconnect" href="//zz.bdstatic.com"/><meta name="msvalidate.01" content="88688A1E5B9FE1F1F5EDAA94C73CD07D"/><meta name="baidu-site-verification" content="yiOH4yHRf0eeVuko"/><meta name="360-site-verification" content="d182b3f28525f2db83acfaaf6e696dba"/><meta property="og:type" content="article"><meta property="og:title" content="时间序列算法综述"><meta property="og:url" content="http://jums.club/time-series-forecasting-algorithm/"><meta property="og:site_name" content="CrazyJums"><meta property="og:description" content="时间序列预测的顺序 时间序列的正式定义如下：它是一系列在相同时间间隔内测量到的数据点。时间序列的特殊性是：该序列中的每个数据点都与先前的数据点相关。知乎问答：利用Auto ARIMA构建高性能时间序列模型（附Python和R代码）|source article #参考文献常见Markdown公式代码《时间序列分析》-作者：詹姆斯·D·汉密尔顿（James D.Hamilton）预测：方法与实践 1"><meta property="og:image" content="https://jums.club/images/article/abe1eea3ca79fc28-c577ebdcb0f3dbcc-12b18d568f3a18bbb0e7ba20055a1039.jpg"><meta property="article:published_time" content="2020-03-03T05:42:18.000Z"><meta property="article:modified_time" content="2021-09-22T01:48:22.885Z"><meta name="twitter:card" content="summary"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="prev" title="预测算法简介" href="http://jums.club/prediction-algorithm/"><link rel="next" title="如何在github上写博客" href="http://jums.club/write-blog-via-github/"><script async="async" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(adsbygoogle = window.adsbygoogle || []).push({
  google_ad_client: '9335780214',
  enable_page_level_ads: 'true'
});</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?109416411ccef2c884dd6e0306467b1d";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-153513094-1', 'auto');
ga('send', 'pageview');
</script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: true,
  copyright: {"languages":{"author":"Author: CrazyJums","link":"Link: ","source":"Source: CrazyJums","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: true,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: true    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><script data-ad-client="ca-pub-7924394983086399" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><meta name="generator" content="Hexo 5.4.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://jums.club/images/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">226</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">62</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/leetcode/"><i class="fa-fw fa fa-code"></i><span> LeetCode</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fa fa-comments"></i><span> Comments</span></a></div><div class="menus_item"><a class="site-page" href="/kbooks/"><i class="fa-fw fa fa-book"></i><span> Kbooks</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/media/"><i class="fa-fw fa fa-play"></i><span> Media</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-user"></i><span> About</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E7%9A%84%E9%A1%BA%E5%BA%8F"><span class="toc-number">1.</span> <span class="toc-text">时间序列预测的顺序</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">1.1.</span> <span class="toc-text">#参考文献</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%85%B6%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%9A%84%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">1 其中常见的时间序列预测算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-%E6%9C%B4%E7%B4%A0%E9%A2%84%E6%B5%8B%E6%B3%95%EF%BC%88%E4%B8%80%E6%AC%A1%E6%8C%87%E6%95%B0%E5%B9%B3%E6%BB%91%EF%BC%89"><span class="toc-number">2.1.</span> <span class="toc-text">1.1 朴素预测法（一次指数平滑）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-%E7%AE%80%E5%8D%95%E5%B9%B3%E5%9D%87%E6%B3%95"><span class="toc-number">2.2.</span> <span class="toc-text">1.2 简单平均法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-%E7%A7%BB%E5%8A%A8%E5%B9%B3%E5%9D%87%E6%B3%95"><span class="toc-number">2.3.</span> <span class="toc-text">1.3 移动平均法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-%E5%8A%A0%E6%9D%83%E7%A7%BB%E5%8A%A8%E5%B9%B3%E5%9D%87%E6%B3%95"><span class="toc-number">2.4.</span> <span class="toc-text">1.4 加权移动平均法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-%E7%AE%80%E5%8D%95%E6%8C%87%E6%95%B0%E5%B9%B3%E5%9D%87%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">1.5 简单指数平均法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-6-%E9%9C%8D%E5%B0%94%E7%89%B9%EF%BC%88Holt%EF%BC%89%E7%BA%BF%E6%80%A7%E8%B6%8B%E5%8A%BF%E9%A2%84%E6%B5%8B"><span class="toc-number">3.1.</span> <span class="toc-text">1.6 霍尔特（Holt）线性趋势预测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-7-%E9%9C%8D%E5%B0%94%E7%89%B9-%E6%B8%A9%E7%89%B9%E6%96%AF%EF%BC%88Holt-Winters%EF%BC%89%E6%96%B9%E6%B3%95%EF%BC%88%E4%B8%89%E6%AC%A1%E6%8C%87%E6%95%B0%E5%B9%B3%E6%BB%91%EF%BC%89"><span class="toc-number">3.2.</span> <span class="toc-text">1.7 霍尔特-温特斯（Holt Winters）方法（三次指数平滑）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8C%87%E6%95%B0%E5%B9%B3%E6%BB%91%E6%B3%95"><span class="toc-number">3.2.1.</span> <span class="toc-text">指数平滑法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%AE%97%E6%B3%95%E4%B8%AD%E7%94%A8%E5%88%B0%E7%9A%84%E5%90%84%E7%A7%8D%E6%8C%87%E6%A0%87%E4%BB%8B%E7%BB%8D-link"><span class="toc-number">4.</span> <span class="toc-text">2 算法中用到的各种指标介绍|link</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-MSE-%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE-mean-square-error"><span class="toc-number">4.1.</span> <span class="toc-text">2.1 MSE-均方误差(mean square error)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-RMSE-%E5%9D%87%E6%96%B9%E6%A0%B9%E8%AF%AF%E5%B7%AE-root-mean-square-error"><span class="toc-number">4.2.</span> <span class="toc-text">2.2 RMSE-均方根误差(root mean square error)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-MAE-%E5%B9%B3%E5%9D%87%E7%BB%9D%E5%AF%B9%E8%AF%AF%E5%B7%AE-mean-absolute-error"><span class="toc-number">4.3.</span> <span class="toc-text">2.3 MAE-平均绝对误差(mean absolute error)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-R-Squared"><span class="toc-number">4.4.</span> <span class="toc-text">2.4 R Squared</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">5.</span> <span class="toc-text">3 循环神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%881%EF%BC%89-%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95"><span class="toc-number">5.1.</span> <span class="toc-text">（1） 梯度爆炸的解决方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%882%EF%BC%89-%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95"><span class="toc-number">5.2.</span> <span class="toc-text">（2） 梯度消失的解决办法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C"><span class="toc-number">5.3.</span> <span class="toc-text">3.1 长短时记忆网络</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%881%EF%BC%89LSTM%E4%BB%8B%E7%BB%8D"><span class="toc-number">5.3.1.</span> <span class="toc-text">（1）LSTM介绍</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%882%EF%BC%89LSTM%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%E4%BB%8B%E7%BB%8D"><span class="toc-number">5.3.2.</span> <span class="toc-text">（2）LSTM的优缺点介绍</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-GRU"><span class="toc-number">5.4.</span> <span class="toc-text">3.2 GRU</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%881%EF%BC%89GRU%E7%9A%84%E7%BB%93%E6%9E%84%E4%BB%8B%E7%BB%8D"><span class="toc-number">5.4.1.</span> <span class="toc-text">（1）GRU的结构介绍</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%882%EF%BC%89GRU%E5%92%8CLSTM%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">5.4.2.</span> <span class="toc-text">（2）GRU和LSTM的关系</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RNN%E7%9A%84%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">5.5.</span> <span class="toc-text">RNN的参考文献</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%A5%87%E5%BC%82%E8%B0%B1%E5%88%86%E6%9E%90%EF%BC%88SSA%EF%BC%89"><span class="toc-number">6.</span> <span class="toc-text">4 奇异谱分析（SSA）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E8%87%AA%E5%9B%9E%E5%BD%92%E7%A7%BB%E5%8A%A8%E5%B9%B3%E5%9D%87%EF%BC%88ARMA%EF%BC%89"><span class="toc-number">7.</span> <span class="toc-text">5 自回归移动平均（ARMA）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%B9%B3%E7%A8%B3%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B%EF%BC%9F"><span class="toc-number">7.1.</span> <span class="toc-text">什么是平稳随机过程？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ARMA%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">7.2.</span> <span class="toc-text">#ARMA参考文献</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%B7%AE%E5%88%86%E8%87%AA%E5%9B%9E%E5%BD%92%E7%A7%BB%E5%8A%A8%E5%B9%B3%E5%9D%87%EF%BC%88ARIMA%EF%BC%89"><span class="toc-number">8.</span> <span class="toc-text">6 差分自回归移动平均（ARIMA）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E5%9B%9E%E5%BD%92%EF%BC%88SVR%EF%BC%89"><span class="toc-number">9.</span> <span class="toc-text">7 支持向量回归（SVR）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E4%B8%89%E6%AC%A1%E6%8C%87%E6%95%B0%E5%B9%B3%E6%BB%91"><span class="toc-number">10.</span> <span class="toc-text">8 三次指数平滑</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AB%E2%80%9C%E6%8C%87%E6%95%B0%E5%B9%B3%E6%BB%91%E2%80%9D%EF%BC%9F"><span class="toc-number">10.1.</span> <span class="toc-text">8.1 为什么叫“指数平滑”？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2-%E7%AE%97%E6%B3%95%E4%BC%98%E7%82%B9"><span class="toc-number">10.2.</span> <span class="toc-text">8.2 算法优点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%89%E6%AC%A1%E6%8C%87%E6%95%B0%E5%B9%B3%E6%BB%91%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">10.3.</span> <span class="toc-text">#三次指数平滑参考文献</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%99%BD%E5%99%AA%E5%A3%B0%EF%BC%9F"><span class="toc-number">10.4.</span> <span class="toc-text">什么是白噪声？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0%E5%92%8C%E8%B6%85%E5%8F%82%E6%95%B0%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">10.5.</span> <span class="toc-text">机器学习模型中的参数和超参数的区别？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E8%AE%AD%E7%BB%83%E9%9B%86%E3%80%81%E6%A0%A1%E9%AA%8C%E9%9B%86%E3%80%81%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="toc-number">10.6.</span> <span class="toc-text">机器学习模型中的训练集、校验集、测试集</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E6%9C%80%E5%90%8E"><span class="toc-number">11.</span> <span class="toc-text">写在最后</span></a></li></ol></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://jums.club/images/article/abe1eea3ca79fc28-c577ebdcb0f3dbcc-12b18d568f3a18bbb0e7ba20055a1039.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">CrazyJums</a></span><span class="pull-right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/leetcode/"><i class="fa-fw fa fa-code"></i><span> LeetCode</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fa fa-comments"></i><span> Comments</span></a></div><div class="menus_item"><a class="site-page" href="/kbooks/"><i class="fa-fw fa fa-book"></i><span> Kbooks</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/media/"><i class="fa-fw fa fa-play"></i><span> Media</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-user"></i><span> About</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">时间序列算法综述</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="Created 2020-03-03 13:42:18"><i class="far fa-calendar-alt fa-fw"></i> Created 2020-03-03</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="Updated 2021-09-22 09:48:22"><i class="fas fa-history fa-fw"></i> Updated 2021-09-22</span></time></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta__icon"></i><span>Word count:</span><span class="word-count">4k</span><span class="post-meta__separator">|</span><i class="far fa-clock fa-fw post-meta__icon"></i><span>Reading time: 12 min</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="far fa-eye fa-fw post-meta__icon"></i><span>Post View:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h3 id="时间序列预测的顺序"><a href="#时间序列预测的顺序" class="headerlink" title="时间序列预测的顺序"></a>时间序列预测的顺序</h3><p><img src= "/img/loading.gif" data-src="https://jums.club/images/article/147.png" alt="image"></p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>时间序列的正式定义如下：它是一系列在相同时间间隔内测量到的数据点。<br>时间序列的特殊性是：该序列中的每个数据点都与先前的数据点相关。<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/49746642">知乎问答：利用Auto ARIMA构建高性能时间序列模型（附Python和R代码）</a>|<a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2018/02/time-series-forecasting-methods/">source article</a></p>
<h4 id="参考文献"><a href="#参考文献" class="headerlink" title="#参考文献"></a>#参考文献</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/jyfu2_12/article/details/79207643">常见Markdown公式代码</a><br><a target="_blank" rel="noopener" href="https://item.jd.com/12475341.html">《时间序列分析》-作者：詹姆斯·D·汉密尔顿（James D.Hamilton）</a><br><a target="_blank" rel="noopener" href="https://otexts.com/fppcn/holt-winters.html">预测：方法与实践</a></p>
<h3 id="1-其中常见的时间序列预测算法"><a href="#1-其中常见的时间序列预测算法" class="headerlink" title="1 其中常见的时间序列预测算法"></a>1 其中常见的时间序列预测算法</h3><h4 id="1-1-朴素预测法（一次指数平滑）"><a href="#1-1-朴素预测法（一次指数平滑）" class="headerlink" title="1.1 朴素预测法（一次指数平滑）"></a>1.1 朴素预测法（一次指数平滑）</h4><p>概念：利用前一时刻的数据，作为下一时刻数据的预测值，公式如下：</p>
<p>$X_{t+1} = X_i$</p>
<p>缺点：那么预测出来的结果会是一条平行线，因为预测结果都是之前的最后一个时刻的值。如下所示：<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/v2-91cc0429042526c71934287553bbd36e_hd.jpg" alt="image"></p>
<h4 id="1-2-简单平均法"><a href="#1-2-简单平均法" class="headerlink" title="1.2 简单平均法"></a>1.2 简单平均法</h4><p>概念：该方法是将之前的所有历史数据进行平均，不再是简单的利用最后一个时刻的数据作为预测值，图像是一条斜线，公式如下：</p>
<p>$X_{t+1} = \frac{1}{N} \sum^N_{i=1} X_i  $ </p>
<p>where:<code>N</code>表示所有的历史数据的总数.<br>优点：不像“朴素预测法”那样，直接是一条平行线，该算法中将历史数据也考虑进去；<br>缺点：但是这些历史数据有些不一定都是有用，所以也会产生一定的误差<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/v2-25e9516f144807a45e483cdd9f1f6fbd_hd.jpg" alt="image"></p>
<h4 id="1-3-移动平均法"><a href="#1-3-移动平均法" class="headerlink" title="1.3 移动平均法"></a>1.3 移动平均法</h4><p>概念：取前n个历史数据的平均，作为下一次的预测结果值，公式如下：</p>
<p>$X_{t+1} = \frac {1}{n} \sum^n_i X_i$</p>
<p>where:<code>n</code>表示前<code>n</code>个数据的数据总数<br>优点：在<code>朴素预测法</code>和<code>简单平均法</code>的基础上进行改进，使得预测结果更加符合实际<br>缺点：最接近下一时刻的数据与下一时刻的真实数据明显更加接近，没有考虑权重<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/v2-eac4ad5b9cc86106750147f88a1a3a42_hd.jpg" alt="image"></p>
<h4 id="1-4-加权移动平均法"><a href="#1-4-加权移动平均法" class="headerlink" title="1.4 加权移动平均法"></a>1.4 加权移动平均法</h4><p>概念：在移动平均法的基础上，对前n个数据给予不同的权重，那么对下一时刻的预测结果将更加接近真实值，公式如下：</p>
<p>$X_{t+1} = \frac {1}{n} \sum^n_i X_i \cdot W_i$</p>
<p>where:W表示每个数据点的权重<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/v2-ac1f9544d26d5d966573a5a8679875fd_hd.jpg" alt="image"></p>
<h3 id="1-5-简单指数平均法"><a href="#1-5-简单指数平均法" class="headerlink" title="1.5 简单指数平均法"></a>1.5 简单指数平均法</h3><p>概念：在该方法中，同样取前n个数据的平均同时加权重，但是更近期的观测结果会被赋予更大的权重，公式如下：</p>
<p>$X_{t+1} = \frac {1}{n} \sum^n_i X_i \cdot W_i 且W_i&gt;W_{i-1}$</p>
<p><img src= "/img/loading.gif" data-src="https://jums.club/images/article/v2-49baf17e7e9ade3bfd3a0b8b8d4b9864_hd.jpg" alt="image"></p>
<h4 id="1-6-霍尔特（Holt）线性趋势预测"><a href="#1-6-霍尔特（Holt）线性趋势预测" class="headerlink" title="1.6 霍尔特（Holt）线性趋势预测"></a>1.6 霍尔特（Holt）线性趋势预测</h4><p>概念：在之前的基础上，该方法加入了数据集的趋势，也就是数据的整体上涨或下跌等。<br>优点：该方法能够按照一定的趋势去预测，而不是盲目的预测，结果更具说服性<br>缺点：该方法只考虑了趋势性（上涨或下跌），但是没有考虑数据的季节性，也就是数据集的周期性。<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/v2-6a278b4ba9c50cbd6db292dd4e7372df_hd.jpg" alt="image"></p>
<h4 id="1-7-霍尔特-温特斯（Holt-Winters）方法（三次指数平滑）"><a href="#1-7-霍尔特-温特斯（Holt-Winters）方法（三次指数平滑）" class="headerlink" title="1.7 霍尔特-温特斯（Holt Winters）方法（三次指数平滑）"></a>1.7 霍尔特-温特斯（Holt Winters）方法（三次指数平滑）</h4><p>概念：该方法在霍尔特线性趋势预测的基础上了，加入了季节性，也就是说，该方法同时具有趋势性和季节性。</p>
<p><img src= "/img/loading.gif" data-src="https://jums.club/images/article/v2-a6d012dfeeadb4d9074789067871f42a_hd.jpg" alt="image"></p>
<h5 id="指数平滑法"><a href="#指数平滑法" class="headerlink" title="指数平滑法"></a><a target="_blank" rel="noopener" href="https://blog.csdn.net/anshuai_aw1/article/details/82499095">指数平滑法</a></h5><blockquote>
<p>指数平滑法有几种不同形式：一次指数平滑法针对没有趋势和季节性的序列，二次指数平滑法针对有趋势但没有季节性的序列，三次指数平滑法针对有趋势也有季节性的序列。“Holt-Winters”有时特指三次指数平滑法。</p>
</blockquote>
<h3 id="2-算法中用到的各种指标介绍-link"><a href="#2-算法中用到的各种指标介绍-link" class="headerlink" title="2 算法中用到的各种指标介绍|link"></a>2 算法中用到的各种指标介绍|<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/9ee85fdad150">link</a></h3><h4 id="2-1-MSE-均方误差-mean-square-error"><a href="#2-1-MSE-均方误差-mean-square-error" class="headerlink" title="2.1 MSE-均方误差(mean square error)"></a>2.1 MSE-均方误差(mean square error)</h4><p><img src= "/img/loading.gif" data-src="https://jums.club/images/article/148.png" alt="image"><br>这里的y是测试集上的。<br>用 真实值-预测值 然后平方之后求和平均。</p>
<h4 id="2-2-RMSE-均方根误差-root-mean-square-error"><a href="#2-2-RMSE-均方根误差-root-mean-square-error" class="headerlink" title="2.2 RMSE-均方根误差(root mean square error)"></a>2.2 RMSE-均方根误差(root mean square error)</h4><p><img src= "/img/loading.gif" data-src="https://jums.club/images/article/149.png" alt="image"></p>
<blockquote>
<p>例如：要做房价预测，每平方是万元（真贵），我们预测结果也是万元。那么差值的平方单位应该是 千万级别的。那我们不太好描述自己做的模型效果。怎么说呢？我们的模型误差是 多少千万？。。。。。。于是干脆就开个根号就好了。我们误差的结果就跟我们数据是一个级别的可，在描述模型的时候就说，我们模型的误差是多少万元。</p>
</blockquote>
<h4 id="2-3-MAE-平均绝对误差-mean-absolute-error"><a href="#2-3-MAE-平均绝对误差-mean-absolute-error" class="headerlink" title="2.3 MAE-平均绝对误差(mean absolute error)"></a>2.3 MAE-平均绝对误差(mean absolute error)</h4><p><img src= "/img/loading.gif" data-src="https://jums.club/images/article/150.png" alt="image"></p>
<h4 id="2-4-R-Squared"><a href="#2-4-R-Squared" class="headerlink" title="2.4 R Squared"></a>2.4 R Squared</h4><p>为了能够让模型有一个标准的衡量标准，这里引入R方的概念。</p>
<blockquote>
<p>比如说预测房价 那么误差单位就是万元。数子可能是3，4，5之类的。那么预测身高就可能是0.1，0.6之类的。没有什么可读性，到底多少才算好呢？不知道，那要根据模型的应用场景来。<br>看看分类算法的衡量标准就是正确率，而正确率又在0～1之间，最高百分之百。最低0。很直观，而且不同模型一样的。那么线性回归有没有这样的衡量标准呢？答案是有的。<br>那就是R Squared也就R方</p>
</blockquote>
<p>公式：<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/151.png" alt="image"><br>其中分子是Residual(残差) Sum of Squares 分母是 Total Sum of Squares</p>
<p>慢慢解释。其实这个很简单：</p>
<ul>
<li>上面分子就是我们训练出的模型预测的所有误差。</li>
<li>下面分母就是不管什么我们猜的结果就是y的平均数。（瞎猜的误差）</li>
</ul>
<p>结果如下：</p>
<ul>
<li>如果结果是0，就说明我们的模型跟瞎猜差不多。</li>
<li>如果结果是1。就说明我们模型无错误。</li>
<li>如果结果是0-1之间的数，就是我们模型的好坏程度。</li>
<li>如果结果是负数。说明我们的模型还不如瞎猜。（其实导致这种情况说明我们的数据其实没有啥线性关系）</li>
</ul>
<p>公式的分子分母同时处以m，得：<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/152.png" alt="image"></p>
<p>那么分子便成了MSE，分母就是方差，有如下：<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/153.png" alt="image"></p>
<blockquote>
<p>补充：什么是方差？<br><strong>方差</strong>（英语：Variance），<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/應用數學">应用数学</a>里的专有名词。在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/概率论">概率论</a>和<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/统计学">统计学</a>中，一个<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/随机变量">随机变量</a>的<strong>方差</strong>描述的是它的离散程度，也就是该变量离其<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/期望值">期望值</a>的距离。一个实随机变量的方差也称为它的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/矩_(數學)">二阶矩</a>或二阶<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/主動差">中心矩</a>，恰巧也是它的二阶累积量。这里把复杂说白了，就是将各个误差之平方（而非取绝对值，使之肯定为正数），相加之后再除以总数，透过这样的方式来算出各个数据分布、零散（相对中心点）的程度。继续延伸的话，方差的正<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/平方根">平方根</a>称为该随机变量的<strong><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/标准差">标准差</a></strong>（此为相对各个数据点间），方差除以<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/期望值">期望值</a>归一化的值叫<strong>分散指数</strong>，标准差除以<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/期望值">期望值</a>归一化的值叫<strong>变异系数</strong>。</p>
</blockquote>
<h3 id="3-循环神经网络"><a href="#3-循环神经网络" class="headerlink" title="3 循环神经网络"></a>3 循环神经网络</h3><p>循环神经网络（Recurrent Neural Network）是一种基于序列结构数据的神经网络模型，在处理时间序列数据时，具有一定的优势。在RNN模型中，下一层的隐含层的输入是前一层隐含层的输入，这样做的目的就是为了能够“记住”整个序列的数据，从而能够对一些有时间顺序的数据进行处理。但是RNN也有缺点，缺点也由于其“优势”所导致的，在利用BPTT（Back Propagation Through Time，基于时间的反向传播）算法优化参数时，可能会遇到梯度消失（或者说梯度弥散）或者梯度爆炸的问题。由于BPTT的本质也是采用逐层梯度下降，然而梯度下降也就是求偏导数，如果每层的偏导数都小于1，那么就会出现梯度消失；反之，如果每层的偏导数大于1，那么就会出现梯度爆炸。<br><strong>公式如下：</strong><br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/1187314-20190829170635207-1732920092.png" alt="image"><br><strong>RNN的结构如下：</strong><br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/154.png" alt="image"></p>
<h4 id="（1）-梯度爆炸的解决方法"><a href="#（1）-梯度爆炸的解决方法" class="headerlink" title="（1） 梯度爆炸的解决方法"></a>（1） 梯度爆炸的解决方法</h4><ul>
<li>重新设计网络结构</li>
<li>使用激活函数（ReLU函数等）</li>
<li>使用权重正则化</li>
<li>使用梯度剪枝</li>
<li>LSTM</li>
</ul>
<h4 id="（2）-梯度消失的解决办法"><a href="#（2）-梯度消失的解决办法" class="headerlink" title="（2） 梯度消失的解决办法"></a>（2） 梯度消失的解决办法</h4><p>由于梯度消失的问题比较棘手，不像梯度爆炸那样比较容易解决，需要对原网络进行改进，在此基础上，有诞生了</p>
<ul>
<li>GRU（Gate Recurrent Unit），门循环单元</li>
<li>LSTM（Long Short Term Memory）,长短时记忆网络。</li>
</ul>
<h4 id="3-1-长短时记忆网络"><a href="#3-1-长短时记忆网络" class="headerlink" title="3.1 长短时记忆网络"></a>3.1 长短时记忆网络</h4><p>为了解决基础RNN中出现的梯度消失和梯度爆炸问题，LSTM（Long Short Term Memory）于1997年被提出，且能很好的解决RNN中的梯度消失和梯度爆炸问题。</p>
<h5 id="（1）LSTM介绍"><a href="#（1）LSTM介绍" class="headerlink" title="（1）LSTM介绍"></a>（1）LSTM介绍</h5><blockquote>
<p>概念：</p>
<ul>
<li>一个LSTM Cell是由3个门限结构和1个状态向量传输线组成的，门限分别是遗忘门，传入门，输出门；</li>
<li>其中状态向量传输线负责长程记忆，因为它只做了一些简单的线性操作；3个门限负责短期记忆的选择，因为门限设置可以对输入向量做删除或者添加操作;   </li>
</ul>
</blockquote>
<p>下图是RNN和LSTM的结构图比较，右侧为LSTM：<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/v2-e4f9851cad426dfe4ab1c76209546827_r.jpg" alt="image">   </p>
<p>左侧：<br>其中$x^t$表示的是当前t时刻的输入， $h^{t-1}$表示的是上一时刻的隐含层输出值， $h^t$表示的是t时刻隐含层状态，  $y^t$表示的是当前$t$时刻的输出值，Naive表示的是普通的RNN。</p>
<p><strong>LSTM中的参数介绍：</strong><br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/v2-15c5eb554f843ec492579c6d87e1497b_r.jpg" alt="image"><br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/v2-d044fd0087e1df5d2a1089b441db9970_hd.jpg" alt="image">   </p>
<p><strong>LSTM的内部结构：</strong><br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/v2-556c74f0e025a47fea05dc0f76ea775d_hd.jpg" alt="image">   </p>
<p><strong>多层LSTM的连接结构：</strong><br><strong>以下是一个LSTM cell结构图：</strong><br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/776149-20180419171148265-132667484.png" alt="image"></p>
<p>1）遗忘门<br>遗忘门是通过一个sigmoid函数来实现，“0”表示决绝任何输入，“1”表示接受所有输入<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/776149-20180419180212604-282221791.png" alt="image">   </p>
<p>2）输入门（选择记忆）<br>输入门有两部分组成，一部分是由sigmoid函数来决定哪些信息需要更新，一部分由tanh函数来生成一个备选的用来更新的内容；然后再将这两部分进行向量点乘。<br>作用：决定让多少<strong>新的信</strong>息加入到cell状态中来<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/776149-20180419180455006-1062571156.png" alt="image">   </p>
<p>3）输出门<br>该部分同样由两部分构成，一部分由sigmoid函数决定哪些信息需要输出，接着，另一部分是把一个状态向量通过一个tanh层（tanh函数），然后把tanh的状态输出和由sigmoid函数计算出来的权重相乘。这就得到了最后的结果。<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/776149-20180419181357739-45985178.png" alt="image"></p>
<p>4）状态更新<br>首先由旧的状态和遗忘门的输出相乘，把一些不想保留的信息忘掉，然后加上<strong>输入门的输出，这部分信息就是我们想要新添加的内容</strong></p>
<h5 id="（2）LSTM的优缺点介绍"><a href="#（2）LSTM的优缺点介绍" class="headerlink" title="（2）LSTM的优缺点介绍"></a>（2）LSTM的优缺点介绍</h5><ul>
<li>优点<ul>
<li>解决了RNN中的梯度消失和梯度爆炸问题</li>
</ul>
</li>
<li>缺点<ul>
<li>计算速度较慢</li>
</ul>
</li>
</ul>
<h4 id="3-2-GRU"><a href="#3-2-GRU" class="headerlink" title="3.2 GRU"></a>3.2 GRU</h4><p>针对LSTM的缺点（计算速度偏慢），门控循环单元（Gate Recurrent Unit，GRU）在2014年被提出，在LSTM结构的基础上，GRU进行了改进。相比于LSTM，GRU减少了一个“门控单元”。在LSTM中有三个“门控单元”，分别是遗忘门、输入门、输出门来控制输入值、记忆值和输出值。而GRU中之后更新门(z)和重置门(r)两个“门控单元”，少了一个“门控单元”，其计算复杂度降低了，运行速度也提升了。</p>
<h5 id="（1）GRU的结构介绍"><a href="#（1）GRU的结构介绍" class="headerlink" title="（1）GRU的结构介绍"></a>（1）GRU的结构介绍</h5><p><strong>GRU的内部结构图：</strong><br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/1335117-20180727095108158-462781335.png" alt="image">   </p>
<p><strong>GRU的状态图：</strong><br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/v2-8134a00c243153bfd9fd2bcbe0844e9c_1200x500.jpg" alt="image">    </p>
<p><strong>GRU的两个门控：</strong><br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/v2-7fff5d817530dada1b279c7279d73b8a_hd.jpg" alt="image"><br>首先再次强调一下，门控信号（这里的z ）的范围为0~1。门控信号越接近1，代表”记忆“下来的数据越多；而越接近0则代表”遗忘“的越多。</p>
<h5 id="（2）GRU和LSTM的关系"><a href="#（2）GRU和LSTM的关系" class="headerlink" title="（2）GRU和LSTM的关系"></a>（2）GRU和LSTM的关系</h5><p>我们知道GRU也是RNN的一种，且GRU是LSTM的一个变种或者说是简化版，但是他们之间的关系其实是：GRU利用更新门(z)代替了LSTM中的遗忘门和输入门，更新门既可以进行“遗忘”也可以进行“选择记忆”，这一点由<strong>更新表达式</strong>可以看出。</p>
<h4 id="RNN的参考文献"><a href="#RNN的参考文献" class="headerlink" title="RNN的参考文献"></a>RNN的参考文献</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_32241189/article/details/80461635">深度学习之RNN(循环神经网络)</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/32481747">人人都能看懂的GRU</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/32085405">人人都能看懂的LSTM</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8b78ac379e3a">一文了解LSTM和GRU背后的秘密（绝对没有公式）</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/arachis/p/RNN.html">循环神经（LSTM）网络学习总结摘要</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/jason_cuijiahui/article/details/87517127">什么是白噪声？如何判断时间序列是白噪声？</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/SUSU0203/article/details/80051692">时间序列分析——自回归移动平均（ARMA）模型</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/junge-mike/p/9335054.html">时间序列模式（ARIMA）—Python实现</a></p>
<h3 id="4-奇异谱分析（SSA）"><a href="#4-奇异谱分析（SSA）" class="headerlink" title="4 奇异谱分析（SSA）"></a>4 奇异谱分析（SSA）</h3><p>奇异频谱分析（Singular spectral analysis，SSA）</p>
<h3 id="5-自回归移动平均（ARMA）"><a href="#5-自回归移动平均（ARMA）" class="headerlink" title="5 自回归移动平均（ARMA）"></a>5 自回归移动平均（ARMA）</h3><p>AR（p）,MA（q）<br>因为AR（p）,MA（q）,ARMA（p,q）都是平稳随机过程，对于有些时间序列数据不能很好的进行预测，比如有些数据在时间上具有季节性和或趋势性，像这样<strong>非平稳随机过程</strong>ARMA不能很好的预测，所以引入ARIMA（差分自回归移动平均），即在p,q两个参数的基础上，再加一个将时间序列变为平稳时所做的差分次数d。</p>
<blockquote>
<h4 id="什么是平稳随机过程？"><a href="#什么是平稳随机过程？" class="headerlink" title="什么是平稳随机过程？"></a>什么是平稳随机过程？</h4><p>平稳随机过程就是该随机过程的统计特性不随时间的推移而产生变化，因此其<strong>数学期望</strong>和<strong>方差</strong>都不变。</p>
</blockquote>
<h4 id="ARMA参考文献"><a href="#ARMA参考文献" class="headerlink" title="#ARMA参考文献"></a>#ARMA参考文献</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/x_i_y_u_e/article/details/47748479">AR,MA-&gt;ARMA-&gt;ARIMA</a>   </p>
<h3 id="6-差分自回归移动平均（ARIMA）"><a href="#6-差分自回归移动平均（ARIMA）" class="headerlink" title="6 差分自回归移动平均（ARIMA）"></a>6 差分自回归移动平均（ARIMA）</h3><p>差分自回归移动平均模型（Auto Regressive Integrated Moving Average  Model ,简称ARIMA）。|<a target="_blank" rel="noopener" href="https://wiki.mbalib.com/wiki/ARIMA">MBA智库-解释</a><br>AR是（Auto Regressive）自回归，p是自回归项；MA（Moving Average）是移动平均，q是移动平均项；d是时间序列成为平稳时所做的差分次数。<br>ARIMA模型的提出是为了解决ARMA模型不能预测非随机平稳过程的问题，ARIMA的<strong>思路</strong>是：现将给定的非平稳随机过程转换成平稳随机过程，然后再使用ARMA模型进行预测。</p>
<h3 id="7-支持向量回归（SVR）"><a href="#7-支持向量回归（SVR）" class="headerlink" title="7 支持向量回归（SVR）"></a>7 支持向量回归（SVR）</h3><p>支持向量回归（Support Vector Regression），SVM的英文全称是Support Vector Machines，中文叫支持向量机。支持向量机是我们用于分类的一种算法。支持向量也可以用于回归，所以叫支持向量回归。</p>
<h3 id="8-三次指数平滑"><a href="#8-三次指数平滑" class="headerlink" title="8 三次指数平滑"></a>8 三次指数平滑</h3><h4 id="8-1-为什么叫“指数平滑”？"><a href="#8-1-为什么叫“指数平滑”？" class="headerlink" title="8.1 为什么叫“指数平滑”？"></a>8.1 为什么叫“指数平滑”？</h4><p>先看公式：<br><img src= "/img/loading.gif" data-src="https://jums.club/images/article/120150vwlsv88wgehsta8g.jpg" alt="image"><br>从公式中可以看出，该算法对整个时间序列中的数据多进行了计算，但是时间越久远，其对下一时刻的影响越小，指数越大，其权重越小。</p>
<h4 id="8-2-算法优点"><a href="#8-2-算法优点" class="headerlink" title="8.2 算法优点"></a>8.2 算法优点</h4><p>该算法考虑了时间序列的趋势性和季节性。</p>
<h4 id="三次指数平滑参考文献"><a href="#三次指数平滑参考文献" class="headerlink" title="#三次指数平滑参考文献"></a>#三次指数平滑参考文献</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/hqr20627/article/details/79403876">时间序列挖掘-三次指数平滑法(Holt-Winters)</a>   </p>
<blockquote>
<h4 id="什么是白噪声？"><a href="#什么是白噪声？" class="headerlink" title="什么是白噪声？"></a>什么是白噪声？</h4><p>纯随机序列，也称为白噪声序列，序列的各项之间没有任何的关系， 序列在进行完全无序的随机波动， 可以终止对该序列的分析。<br>当时间序列预测模型的预测达到了白噪声时，那么该模型就类似于收敛了。</p>
</blockquote>
<blockquote>
<h4 id="机器学习模型中的参数和超参数的区别？"><a href="#机器学习模型中的参数和超参数的区别？" class="headerlink" title="机器学习模型中的参数和超参数的区别？"></a>机器学习模型中的参数和超参数的区别？</h4><p>参数：是模型内部的参数，是模型从历史数据中“学习”到的参数，比如W和b，其值可以通过数据估计然后模型训练得到<br>超参数：是不能从模型中得到的参数，可以理解为模型外的参数，其值不能从数据估计得到<br>参考文件：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/18730bed1b9d">机器学习中模型参数与超参数的区别</a></p>
</blockquote>
<blockquote>
<h4 id="机器学习模型中的训练集、校验集、测试集"><a href="#机器学习模型中的训练集、校验集、测试集" class="headerlink" title="机器学习模型中的训练集、校验集、测试集"></a>机器学习模型中的训练集、校验集、测试集</h4><ul>
<li>训练集：用于训练模型，找出最佳的w和b。</li>
<li>验证集：用以确定模型超参数，选出最优模型。</li>
<li>测试集：仅用于对训练好的最优函数进行性能评估。   </li>
</ul>
<p>参考文献：<a target="_blank" rel="noopener" href="https://blog.csdn.net/hohaizx/article/details/81013985">https://blog.csdn.net/hohaizx/article/details/81013985</a></p>
</blockquote>
<h3 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h3><p>欢迎大家关注鄙人的公众号【麦田里的守望者zhg】，让我们一起成长，谢谢。<br><img src= "/img/loading.gif" data-src="https://jums.club/images/wechataccount.jpg" alt="微信公众号"></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">CrazyJums</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://jums.club/time-series-forecasting-algorithm/">http://jums.club/time-series-forecasting-algorithm/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/deep-learning/">deep learning</a></div><div class="post_share"><div class="social-share" data-image="https://jums.club/images/article2/vue.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><button class="reward-button"><i class="fas fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="https://jums.club/images/wechatpay.jpg" alt="微信" onclick="window.open('https://jums.club/images/wechatpay.jpg')"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="https://jums.club/images/alipay.jpg" alt="支付宝" onclick="window.open('https://jums.club/images/alipay.jpg')"/><div class="post-qr-code__desc">支付宝</div></li></ul></div></button></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/prediction-algorithm/"><img class="prev-cover" data-src="https://jums.club/images/article/pIYBAFthILyAIttTAABC5ekxewg426.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">预测算法简介</div></div></a></div><div class="next-post pull-right"><a href="/write-blog-via-github/"><img class="next-cover" data-src="https://jums.club/images/article/github_coding.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">如何在github上写博客</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/AlexNet/" title="CNN典型模型：AlexNet"><img class="relatedPosts_cover" data-src="https://jums.club/images/article/AlexNet.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2019-11-21</div><div class="relatedPosts_title">CNN典型模型：AlexNet</div></div></a></div><div class="relatedPosts_item"><a href="/SSPNet/" title="关于SSPNet（空间金字塔池化网络），了解一下"><img class="relatedPosts_cover" data-src="https://jums.club/images/article/20150105213522578.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2019-11-21</div><div class="relatedPosts_title">关于SSPNet（空间金字塔池化网络），了解一下</div></div></a></div><div class="relatedPosts_item"><a href="/cnn/" title="关于卷积神经网络，了解一下"><img class="relatedPosts_cover" data-src="https://jums.club/images/article/48540923dd54564e223d3494bdde9c82d0584fc7.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2019-11-21</div><div class="relatedPosts_title">关于卷积神经网络，了解一下</div></div></a></div><div class="relatedPosts_item"><a href="/dip/" title="数字图像处理（dip）"><img class="relatedPosts_cover" data-src="https://jums.club/images/article/dip.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2019-11-16</div><div class="relatedPosts_title">数字图像处理（dip）</div></div></a></div><div class="relatedPosts_item"><a href="/gradient-descent/" title="关于深度学习中的梯度下降，了解一下"><img class="relatedPosts_cover" data-src="https://jums.club/images/article/1234352-6ae594f795406b8b.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2019-11-21</div><div class="relatedPosts_title">关于深度学习中的梯度下降，了解一下</div></div></a></div><div class="relatedPosts_item"><a href="/lstm-gru-rnn/" title="全面解析RNN,LSTM,Seq2Seq,Attention注意力机制"><img class="relatedPosts_cover" data-src="https://jums.club/images/article/v2-6340abe431febf6304bafe9ca16edaba_1440w.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-28</div><div class="relatedPosts_title">全面解析RNN,LSTM,Seq2Seq,Attention注意力机制</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var requestSetting = function (from,set) {
  var from = from
  var setting = set.split(',').filter(function(item){
  return from.indexOf(item) > -1
  });
  setting = setting.length == 0 ? from :setting;
  return setting
}

var guestInfo = requestSetting(['nick','mail','link'],'nick,mail,link')
var requiredFields = requestSetting(['nick','mail'],'false')

window.valine = new Valine({
  el:'#vcomment',
  appId: '2lPeEraOnOk7GF6ou1WWs6BP-gzGzoHsz',
  appKey: 'nXeW1bmcRE4TDrorjmdqj0ML',
  placeholder: 'Please leave your footprints',
  avatar: 'monsterid',
  meta: guestInfo,
  pageSize: '10',
  lang: 'en',
  recordIP: false,
  serverURLs: '',
  emojiCDN: '',
  emojiMaps: "",
  enableQQ: false,
  requiredFields: requiredFields
});</script></div></article></main><footer id="footer" style="background-image: url(https://jums.club/images/article/abe1eea3ca79fc28-c577ebdcb0f3dbcc-12b18d568f3a18bbb0e7ba20055a1039.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2022 By CrazyJums</div><div class="footer_custom_text">独立思考、不盲从、不撒谎</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font_plus" title="Increase Font Size"><i class="fas fa-plus"></i></button><button id="font_minus" title="Decrease Font Size"><i class="fas fa-minus"></i></button><button class="translate_chn_to_cht" id="translateLink" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="Setting"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="scroll_to_comment fas fa-comments"></i></a><button class="close" id="mobile-toc-button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script id="ribbon_piao" mobile="true" src="/js/third-party/piao.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="/js/search/local-search.js"></script><script>if (document.getElementsByClassName('mermaid').length) {
  loadScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js',function () {
    mermaid.initialize({
      theme: 'default',
  })
})
}</script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({{ JSON.stringify(config) }});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="{{ src }}">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>